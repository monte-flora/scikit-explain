<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>skexplain.main.explain_toolkit &mdash; Scikit-Explain latest documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >
            <a href="../../../index.html" class="icon icon-home"> Scikit-Explain
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../explain_toolkit.html">ExplainToolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ale.html">Accumulated Local Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pd.html">Partial Dependence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../feature_attributions.html">Feature Attributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../shap.html">SHAP-Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pimp.html">Permutation Importance</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #343131" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Scikit-Explain</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>skexplain.main.explain_toolkit</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for skexplain.main.explain_toolkit</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Literal</span>

<span class="c1"># Computation imports</span>
<span class="kn">from</span> <span class="nn">..common.attributes</span> <span class="kn">import</span> <span class="n">Attributes</span>
<span class="kn">from</span> <span class="nn">.local_explainer</span> <span class="kn">import</span> <span class="n">LocalExplainer</span>
<span class="kn">from</span> <span class="nn">.global_explainer</span> <span class="kn">import</span> <span class="n">GlobalExplainer</span>

<span class="c1"># Plotting imports</span>
<span class="kn">from</span> <span class="nn">..plot.plot_interpret_curves</span> <span class="kn">import</span> <span class="n">PlotInterpretCurves</span>
<span class="kn">from</span> <span class="nn">..plot.plot_permutation_importance</span> <span class="kn">import</span> <span class="n">PlotImportance</span>
<span class="kn">from</span> <span class="nn">..plot.plot_feature_contributions</span> <span class="kn">import</span> <span class="n">PlotFeatureContributions</span>
<span class="kn">from</span> <span class="nn">..plot.plot_2D</span> <span class="kn">import</span> <span class="n">PlotInterpret2D</span>
<span class="kn">from</span> <span class="nn">..plot._box_and_whisker</span> <span class="kn">import</span> <span class="n">box_and_whisker</span>
<span class="kn">from</span> <span class="nn">..plot._kde_2d</span> <span class="kn">import</span> <span class="n">PlotScatter</span>

<span class="kn">from</span> <span class="nn">..common.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">to_xarray</span><span class="p">,</span>
    <span class="n">determine_feature_dtype</span><span class="p">,</span>
    <span class="n">is_str</span><span class="p">,</span>
    <span class="n">is_list</span><span class="p">,</span>
    <span class="n">is_dataset</span><span class="p">,</span>
    <span class="n">is_dataframe</span><span class="p">,</span>
    <span class="n">is_tuple</span><span class="p">,</span>
    <span class="n">check_all_features_for_ale</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">..common.importance_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">retrieve_important_vars</span><span class="p">,</span>
    <span class="n">combine_top_features</span><span class="p">,</span>
    <span class="n">compute_importance</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">..common.contrib_utils</span> <span class="kn">import</span> <span class="n">get_indices_based_on_performance</span>


<span class="kn">from</span> <span class="nn">..common.io</span> <span class="kn">import</span> <span class="n">load_netcdf</span><span class="p">,</span> <span class="n">load_dataframe</span><span class="p">,</span> <span class="n">save_netcdf</span><span class="p">,</span> <span class="n">save_dataframe</span>


<div class="viewcode-block" id="ExplainToolkit"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit">[docs]</a><span class="k">class</span> <span class="nc">ExplainToolkit</span><span class="p">(</span><span class="n">Attributes</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    ExplainToolkit is the primary interface of scikit-explain. The modules contained within compute several</span>
<span class="sd">    explainability machine learning methods such as</span>

<span class="sd">    Feature importance:</span>

<span class="sd">        * `permutation_importance`</span>
<span class="sd">        * `ale_variance`</span>

<span class="sd">    Feature Attributions:</span>

<span class="sd">        - `ale`</span>
<span class="sd">        - `pd`</span>
<span class="sd">        - `ice`</span>
<span class="sd">        - `shap`</span>
<span class="sd">        - `local_contributions`</span>

<span class="sd">    Feature Interactions:</span>

<span class="sd">        - `interaction_strength`</span>
<span class="sd">        - `ale_variance`</span>
<span class="sd">        - `perm_based_interaction`</span>
<span class="sd">        - `friedman_h_stat`</span>
<span class="sd">        - `main_effect_complexity`</span>
<span class="sd">        - `ale`</span>
<span class="sd">        - `pd`</span>

<span class="sd">    Additionally, there are corresponding plotting modules for</span>
<span class="sd">    each method, which are designed to produce publication-quality graphics.</span>

<span class="sd">    .. note::</span>
<span class="sd">        ExplainToolkit is designed to work with estimators that implement predict or predict_proba.</span>

<span class="sd">    .. caution::</span>
<span class="sd">        ExplainToolkit is only designed to work with binary classification and regression problems.</span>
<span class="sd">        In future versions of skexplain, we hope to be compatiable with multi-class classification.</span>


<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>

<span class="sd">    estimators : list of tuples of (estimator name, fitted estimator)</span>
<span class="sd">        Tuple of (estimator name, fitted estimator object) or list thereof where the</span>
<span class="sd">        fitted estimator must implement ``predict`` or ``predict_proba``.</span>
<span class="sd">        Multioutput-multiclass classifiers are not supported.</span>

<span class="sd">    X : {array-like or dataframe} of shape (n_samples, n_features)</span>
<span class="sd">        Training or validation data used to compute the IML methods.</span>
<span class="sd">        If ndnumpy.array, must specify `feature_names`.</span>

<span class="sd">    y : {list or numpy.array} of shape (n_samples,)</span>
<span class="sd">        The target values (class labels in classification, real numbers in regression).</span>

<span class="sd">    estimator_output : ``&quot;raw&quot;`` or ``&quot;probability&quot;``</span>
<span class="sd">        What output of the estimator should be explained. Determined internally by</span>
<span class="sd">        ExplainToolkit. However, if using a classification model, the user</span>
<span class="sd">        can set to &quot;raw&quot; for non-probabilistic output.</span>

<span class="sd">    feature_names : array-like of shape (n_features,), dtype=str, default=None</span>
<span class="sd">        Name of each feature; ``feature_names[i]`` holds the name of the feature</span>
<span class="sd">        with index ``i``. By default, the name of the feature corresponds to their numerical</span>
<span class="sd">        index for NumPy array and their column name for pandas dataframe.</span>
<span class="sd">        Feature names are only required if ``X`` is an ndnumpy.array, a it will be</span>
<span class="sd">        converted to a pandas.DataFrame internally.</span>
<span class="sd">        </span>
<span class="sd">    seaborn_kws : dict, None, or False (default is None)</span>
<span class="sd">        Arguments for the seaborn.set_theme(). By default, we use the following settings. </span>
<span class="sd">        </span>
<span class="sd">        custom_params = {&quot;axes.spines.right&quot;: False, &quot;axes.spines.top&quot;: False}</span>
<span class="sd">        sns.set_theme(style=&quot;ticks&quot;, rc=custom_params)</span>
<span class="sd">        </span>
<span class="sd">        If False, then seaborn settings are not used. </span>
<span class="sd">        </span>

<span class="sd">    Raises</span>
<span class="sd">    ---------</span>
<span class="sd">    AssertError</span>
<span class="sd">        Number of estimator objects is not equal to the number of estimator names given!</span>
<span class="sd">    TypeError</span>
<span class="sd">        y variable must be numpy array or pandas.DataFrame.</span>
<span class="sd">    Exception</span>
<span class="sd">        Feature names must be specified if X is an numpy.array.</span>
<span class="sd">    ValueError</span>
<span class="sd">        estimator_output is not an accepted option.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">estimators</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])),</span>
        <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
        <span class="n">estimator_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">seaborn_kws</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="o">=</span><span class="n">seaborn_kws</span>
        <span class="k">if</span> <span class="n">estimators</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_list</span><span class="p">(</span><span class="n">estimators</span><span class="p">)</span> <span class="ow">and</span> <span class="n">estimators</span><span class="p">:</span>
                <span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimators</span><span class="p">]</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">]</span>
            <span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_estimator_attribute</span><span class="p">(</span><span class="n">estimators</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_y_attribute</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_attribute</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_estimator_output</span><span class="p">(</span><span class="n">estimator_output</span><span class="p">,</span> <span class="n">estimators</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Initialize a global interpret object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span> <span class="o">=</span> <span class="n">GlobalExplainer</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
            <span class="n">checked_attributes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Initialize a local interpret object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span> <span class="o">=</span> <span class="n">LocalExplainer</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
            <span class="n">checked_attributes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;estimator_output&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
            <span class="s2">&quot;estimators used&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="s2">&quot;ExplainToolkit(estimator=</span><span class="si">%s</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                                 estimator_names=</span><span class="si">%s</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                                 X=</span><span class="si">%s</span><span class="s2"> length:</span><span class="si">%d</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                                 y=</span><span class="si">%s</span><span class="s2"> length:</span><span class="si">%d</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                                 estimator_output=</span><span class="si">%s</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> </span><span class="se">\</span>
<span class="s2">                                 feature_names=</span><span class="si">%s</span><span class="s2"> length </span><span class="si">%d</span><span class="s2">)&quot;</span>
            <span class="o">%</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
                <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
                <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">_append_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        FOR INTERNAL PURPOSES ONLY.</span>

<span class="sd">        Append attributes to a xarray.Dataset or pandas.DataFrame</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        ds : xarray.Dataset or pandas.DataFrame</span>
<span class="sd">            Results data from the IML methods</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">ds</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">ds</span>

<div class="viewcode-block" id="ExplainToolkit.permutation_importance"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.permutation_importance">[docs]</a>    <span class="k">def</span> <span class="nf">permutation_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_vars</span><span class="p">,</span>
        <span class="n">evaluation_fn</span><span class="p">,</span>
        <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_permute</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">scoring_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">return_iterations</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">to_importance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs single-pass and/or multi-pass permutation importance using a modified version of the</span>
<span class="sd">        PermutationImportance package (skexplain.PermutationImportance) [1]_. The single-pass approach was first</span>
<span class="sd">        developed in Brieman (2001) [2]_ and then improved upon in Lakshmanan et al. (2015) [3]_.</span>

<span class="sd">        .. attention ::</span>
<span class="sd">                The permutation importance rankings can be sensitive to the evaluation function used.</span>
<span class="sd">                Consider re-computing with multiple evaluation functions.</span>

<span class="sd">        .. attention ::</span>
<span class="sd">                The permutation importance rankings can be sensitive to the direction used.</span>
<span class="sd">                Consider re-computing with both forward- and backward-based methods.</span>

<span class="sd">        .. hint ::</span>
<span class="sd">            Since the permutation importance is a marginal-based method, you can often use</span>
<span class="sd">            subsample &lt;&lt; 1.0 without substantially altering the feature rankings.</span>
<span class="sd">            Using a subsample &lt;&lt; 1.0 can reduce the computation time for larger datasets (e.g., &gt;100 K X),</span>
<span class="sd">            especially since 100-1000s of bootstrap iterations are often required for reliable rankings.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        n_vars : integer</span>
<span class="sd">            number of variables to calculate the multipass permutation importance for. If ``n_vars=1``, then</span>
<span class="sd">            only the single-pass permutation importance is computed. If ``n_vars&gt;1``, both the single-pass</span>
<span class="sd">            and multiple-pass are computed.</span>

<span class="sd">        evaluation_fn : string or callable</span>
<span class="sd">            evaluation/scoring function for evaluating the loss of skill once a feature is permuted.</span>
<span class="sd">            evaluation_fn can be set to one of the following strings:</span>

<span class="sd">                - ``&quot;auc&quot;``, Area under the Curve</span>
<span class="sd">                - ``&quot;auprc&quot;``, Area under the Precision-Recall Curve</span>
<span class="sd">                - ``&quot;bss&quot;``, Brier Skill Score</span>
<span class="sd">                - ``&quot;mse&quot;``, Mean Square Error</span>
<span class="sd">                - ``&quot;norm_aupdc&quot;``,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</span>

<span class="sd">            Otherwise, evaluation_fn can be any function of form,</span>
<span class="sd">            `evaluation_fn(targets, predictions)` and must return a scalar value</span>

<span class="sd">            When using a custom function, you must also set the scoring strategy (see below).</span>

<span class="sd">        scoring_strategy : string (default=None)</span>

<span class="sd">            This argument is only required if you are using a non-default evaluation_fn (see above)</span>

<span class="sd">            If the evaluation_fn is positively-oriented (a higher value is better),</span>
<span class="sd">            then set ``scoring_strategy = &quot;minimize&quot;`` (i.e., a lower score after permutation</span>
<span class="sd">            indicates higher importance) and if it is negatively-oriented-</span>
<span class="sd">            (a lower value is better), then set ``scoring_strategy = &quot;maximize&quot;``</span>

<span class="sd">        direction : ``&quot;forward&quot;`` or ``&quot;backward&quot;``</span>

<span class="sd">            For the multi-pass method. For ``&quot;backward&quot;``, the top feature is left permuted before determining</span>
<span class="sd">            the second-most important feature (and so on). For ``&quot;forward&quot;``, all features are permuted</span>
<span class="sd">            and then the top features are progressively left unpermuted. For real-world datasets, the two</span>
<span class="sd">            methods often do not produce the same feature rankings and is worth exploring both.</span>

<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>

<span class="sd">            if value is between 0-1, it is interpreted as fraction of total X to use</span>
<span class="sd">            if value &gt; 1, interpreted as the number of X to randomly sample</span>
<span class="sd">            from the original dataset.</span>

<span class="sd">        n_jobs : interger or float (default=1; no multiprocessing)</span>

<span class="sd">            if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        n_permute: integer (default=1 for only one permutation per feature)</span>
<span class="sd">            Number of permutations for computing confidence intervals on the feature rankings.</span>

<span class="sd">        random_seed : int, RandomState instance, default=None</span>

<span class="sd">            Pseudo-random number generator to control the permutations of each</span>
<span class="sd">            feature. Pass an int to get reproducible results across function calls.</span>

<span class="sd">        verbose : boolean</span>
<span class="sd">            True for print statements on the progress</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Permutation importance results. Includes the both multi-pass and single-pass</span>
<span class="sd">            feature rankings and the scores with the various features permuted.</span>

<span class="sd">        References</span>
<span class="sd">        -----------</span>
<span class="sd">        .. [1] https://github.com/gelijergensen/PermutationImportance</span>

<span class="sd">        .. [2] L. Breiman, &quot;Random Forests&quot;, Machine Learning, 45(1), 5-32, 2001.</span>

<span class="sd">        .. [3] Lakshmanan, V., C. Karstens, J. Krause, K. Elmore, A. Ryzhkov, and S. Berkseth, 2015:</span>
<span class="sd">               Which Polarimetric Variables Are Important for Weather/No-Weather Discrimination?</span>
<span class="sd">               Journal of Atmospheric and Oceanic Technology, 32, 1209–1223,</span>
<span class="sd">               https://doi.org/10.1175/jtech-d-13-00205.1.</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; # Only compute for the first model</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators[0],</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.permutation_importance(</span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_permute=20,</span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; print(perm_imp_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">            Dimensions:           (n_permute: 20, n_vars_multipass: 10, n_vars_singlepass: 30)</span>
<span class="sd">            Dimensions without coordinates: n_permute, n_vars_multipass, n_vars_singlepass</span>
<span class="sd">            Data variables:</span>
<span class="sd">                multipass_rankings__Random Forest   (n_vars_multipass) &lt;U17 &#39;sfc_te...</span>
<span class="sd">                multipass_scores__Random Forest     (n_vars_multipass, n_permute) float64 ...</span>
<span class="sd">                singlepass_rankings__Random Forest  (n_vars_singlepass) &lt;U17 &#39;sfc_t...</span>
<span class="sd">                singlepass_scores__Random Forest    (n_vars_singlepass, n_permute) float64 ...</span>
<span class="sd">                original_score__Random Forest       (n_permute) float64 0.9851 .....</span>
<span class="sd">            Attributes:</span>
<span class="sd">                estimator_output:  probability</span>
<span class="sd">                estimators used:   [&#39;Random Forest&#39;]</span>
<span class="sd">                n_multipass_vars:  10</span>
<span class="sd">                method:            permutation_importance</span>
<span class="sd">                direction:         backward</span>
<span class="sd">                evaluation_fn:     norm_aupdc</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results_ds</span><span class="p">,</span> <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">calc_permutation_importance</span><span class="p">(</span>
            <span class="n">n_vars</span><span class="o">=</span><span class="n">n_vars</span><span class="p">,</span>
            <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">n_permute</span><span class="o">=</span><span class="n">n_permute</span><span class="p">,</span>
            <span class="n">scoring_strategy</span><span class="o">=</span><span class="n">scoring_strategy</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">direction</span><span class="o">=</span><span class="n">direction</span><span class="p">,</span>
            <span class="n">return_iterations</span><span class="o">=</span><span class="n">return_iterations</span><span class="p">,</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Rename the results:</span>
        <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;multipass&#39;</span><span class="p">,</span> <span class="s1">&#39;singlepass&#39;</span><span class="p">]:</span>
            <span class="n">pimp_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">results_ds</span><span class="o">.</span><span class="n">data_vars</span> <span class="k">if</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">v</span><span class="p">]</span>
            <span class="n">name_dict</span> <span class="o">=</span> <span class="p">{</span> <span class="n">v</span> <span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">direction</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pimp_vars</span><span class="p">}</span>
            <span class="n">results_ds</span> <span class="o">=</span> <span class="n">results_ds</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">name_dict</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_str</span><span class="p">(</span><span class="n">evaluation_fn</span><span class="p">):</span>
            <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">evaluation_fn</span><span class="o">.</span><span class="vm">__name__</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;n_multipass_vars&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;permutation_importance&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;direction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">direction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;evaluation_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_fn</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="c1"># Convert the permutation scores to proper importance scores.</span>
        <span class="k">if</span> <span class="n">to_importance</span><span class="p">:</span>
            <span class="n">results_ds</span> <span class="o">=</span> <span class="n">compute_importance</span><span class="p">(</span><span class="n">results_ds</span><span class="p">,</span> <span class="n">scoring_strategy</span><span class="p">,</span> <span class="n">direction</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.grouped_permutation_importance"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.grouped_permutation_importance">[docs]</a>    <span class="k">def</span> <span class="nf">grouped_permutation_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">perm_method</span><span class="p">,</span>
        <span class="n">evaluation_fn</span><span class="p">,</span>
        <span class="n">scoring_strategy</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_permute</span><span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">clustering_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;n_clusters&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The group only permutation feature importance (GOPFI) from Au et al. 2021 [1]_</span>
<span class="sd">        (see their equations 10 and 11). This function has a built-in method for clustering</span>
<span class="sd">        features using the sklearn.cluster.FeatureAgglomeration. It also has the ability to</span>
<span class="sd">        compute the results over multiple permutations to improve the feature importance</span>
<span class="sd">        estimate (and provide uncertainty).</span>

<span class="sd">        Original score = Jointly permute all features</span>
<span class="sd">        Permuted score = Jointly permuting all features except the considered group</span>

<span class="sd">        Loss metrics := Original_score - Permuted Score</span>
<span class="sd">        Skill Score metrics := Permuted score - Original Score</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        perm_method : ``&quot;grouped&quot;`` or ``&quot;grouped_only&quot;``</span>
<span class="sd">            If ``&quot;grouped&quot;``, the features within a group are jointly permuted and other features</span>
<span class="sd">            are left unpermuted.</span>

<span class="sd">            If ``&quot;grouped_only&quot;``, only the features within a group are left unpermuted and</span>
<span class="sd">            other features are jointly permuted.</span>

<span class="sd">        evaluation_fn : string or callable</span>
<span class="sd">            evaluation/scoring function for evaluating the loss of skill once a feature is permuted.</span>
<span class="sd">            evaluation_fn can be set to one of the following strings:</span>

<span class="sd">                - ``&quot;auc&quot;``, Area under the Curve</span>
<span class="sd">                - ``&quot;auprc&quot;``, Area under the Precision-Recall Curve</span>
<span class="sd">                - ``&quot;bss&quot;``, Brier Skill Score</span>
<span class="sd">                - ``&quot;mse&quot;``, Mean Square Error</span>
<span class="sd">                - ``&quot;norm_aupdc&quot;``,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</span>

<span class="sd">            Otherwise, evaluation_fn can be any function of form,</span>
<span class="sd">            `evaluation_fn(targets, predictions)` and must return a scalar value</span>

<span class="sd">            When using a custom function, you must also set the scoring strategy (see below).</span>

<span class="sd">        scoring_strategy : string (default=None)</span>
<span class="sd">            This argument is only required if you are using a non-default evaluation_fn (see above)</span>

<span class="sd">            If the evaluation_fn is positively-oriented (a higher value is better),</span>
<span class="sd">            then set ``scoring_strategy = &quot;minimize&quot;`` (i.e., a lower score after permutation</span>
<span class="sd">            indicates higher importance) and if it is negatively-oriented-</span>
<span class="sd">            (a lower value is better), then set ``scoring_strategy = &quot;maximize&quot;``</span>

<span class="sd">        n_permute: integer (default=1 for only one permutation per feature)</span>
<span class="sd">            Number of permutations for computing confidence intervals on the feature rankings.</span>

<span class="sd">        groups : dict (default=None)</span>
<span class="sd">            Dictionary of group names and the feature names or feature column indices.</span>
<span class="sd">            If None, then the feature groupings are determined internally based on</span>
<span class="sd">            feature clusterings.</span>

<span class="sd">        sample_size : integer (default=100)</span>
<span class="sd">            Number of random samples to determine the correlation for the feature clusterings</span>

<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total X to use</span>
<span class="sd">            if value &gt; 1, interpreted as the number of X to randomly sample</span>
<span class="sd">            from the original dataset.</span>

<span class="sd">        n_jobs : interger or float (default=1; no multiprocessing)</span>
<span class="sd">           if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">           if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        clustering_kwargs : dict (default = {&#39;n_clusters&#39; : 10})</span>
<span class="sd">            See https://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html</span>
<span class="sd">            for details</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Permutation importance results. Includes the both multi-pass and single-pass</span>
<span class="sd">            feature rankings and the scores with the various features permuted.</span>

<span class="sd">        groups : dict</span>
<span class="sd">            If groups is None, then it returns the groups that were</span>
<span class="sd">            automatically created in the feature clustering. Otherwise,</span>
<span class="sd">            only results is returned.</span>

<span class="sd">        References</span>
<span class="sd">        -----------</span>
<span class="sd">        .. [1] Au, Q., J. Herbinger, C. Stachl, B. Bischl, and G. Casalicchio, 2021:</span>
<span class="sd">        Grouped Feature Importance and Combined Features Effect Plot. Arxiv,.</span>

<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; # Only compute for the first model</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators[0],</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Group only, the features within a group are the only one&#39;s left unpermuted</span>
<span class="sd">        &gt;&gt;&gt; results, groups = explainer.grouped_permutation_importance(</span>
<span class="sd">        ...                                          perm_method = &#39;grouped_only&#39;,</span>
<span class="sd">        ...                                          evaluation_fn = &#39;norm_aupdc&#39;,)</span>
<span class="sd">        &gt;&gt;&gt; print(results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">             Dimensions:                        (n_vars_group: 10, n_bootstrap: 1)</span>
<span class="sd">             Dimensions without coordinates: n_vars_group, n_bootstrap</span>
<span class="sd">             Data variables:</span>
<span class="sd">                 group_rankings__Random Forest  (n_vars_group) &lt;U7 &#39;group 3&#39; ... &#39;group 4&#39;</span>
<span class="sd">                 group_scores__Random Forest    (n_vars_group, n_bootstrap) float64 0.4822...</span>
<span class="sd">             Attributes:</span>
<span class="sd">                 estimators used:   [&#39;Random Forest&#39;]</span>
<span class="sd">                 estimator output:  probability</span>
<span class="sd">                 estimator_output:  probability</span>
<span class="sd">                 groups:            {&#39;group 0&#39;: array([&#39;d_rad_d&#39;, &#39;d_rad_u&#39;], dtype=object...</span>
<span class="sd">                 method:            grouped_permutation_importance</span>
<span class="sd">                 perm_method:       grouped_only</span>
<span class="sd">                 evaluation_fn:     norm_aupdc</span>
<span class="sd">        &gt;&gt;&gt; print(groups)</span>
<span class="sd">        {&#39;group 0&#39;: array([&#39;d_rad_d&#39;, &#39;d_rad_u&#39;], dtype=object),</span>
<span class="sd">        &#39;group 1&#39;: array([&#39;high_cloud&#39;, &#39;lat_hf&#39;, &#39;mid_cloud&#39;, &#39;sfcT_hrs_ab_frez&#39;, &#39;date_marker&#39;], dtype=object),</span>
<span class="sd">        &#39;group 2&#39;: array([&#39;dllwave_flux&#39;, &#39;uplwav_flux&#39;], dtype=object),</span>
<span class="sd">        &#39;group 3&#39;: array([&#39;dwpt2m&#39;, &#39;fric_vel&#39;, &#39;sat_irbt&#39;, &#39;sfc_rough&#39;, &#39;sfc_temp&#39;,</span>
<span class="sd">        &#39;temp2m&#39;, &#39;wind10m&#39;, &#39;urban&#39;, &#39;rural&#39;, &#39;hrrr_dT&#39;], dtype=object),</span>
<span class="sd">        &#39;group 4&#39;: array([&#39;low_cloud&#39;, &#39;tot_cloud&#39;, &#39;vbd_flux&#39;, &#39;vdd_flux&#39;], dtype=object),</span>
<span class="sd">        &#39;group 5&#39;: array([&#39;gflux&#39;, &#39;d_ground&#39;], dtype=object),</span>
<span class="sd">        &#39;group 6&#39;: array([&#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;], dtype=object),</span>
<span class="sd">        &#39;group 7&#39;: array([&#39;swave_flux&#39;], dtype=object),</span>
<span class="sd">        &#39;group 8&#39;: array([&#39;sens_hf&#39;], dtype=object),</span>
<span class="sd">        &#39;group 9&#39;: array([&#39;tmp2m_hrs_ab_frez&#39;], dtype=object)</span>
<span class="sd">        }</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">perm_method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;grouped&#39;</span><span class="p">,</span> <span class="s1">&#39;grouped_only&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid perm_method! Available options are &#39;grouped&#39; and &#39;grouped_only&#39;&quot;</span><span class="p">)</span>
        
        <span class="n">return_names</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_names</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">results_ds</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">grouped_feature_importance</span><span class="p">(</span>
            <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
            <span class="n">perm_method</span><span class="o">=</span><span class="n">perm_method</span><span class="p">,</span>
            <span class="n">n_permute</span><span class="o">=</span><span class="n">n_permute</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
            <span class="n">sample_size</span><span class="o">=</span><span class="n">sample_size</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">clustering_kwargs</span><span class="o">=</span><span class="n">clustering_kwargs</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;grouped_permutation_importance&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;perm_method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">perm_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;evaluation_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_fn</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_names</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results_ds</span><span class="p">,</span> <span class="n">groups</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.ale_variance"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.ale_variance">[docs]</a>    <span class="k">def</span> <span class="nf">ale_variance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ale</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">interaction</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the standard deviation (std) of the ALE values for each</span>
<span class="sd">        features in a dataset and then rank by the magnitude. A higher std(ALE) indicates a</span>
<span class="sd">        greater expected contribution to an estimator&#39;s prediction and is thus considered more important.</span>
<span class="sd">        If ``interaction=True``, then the method computes a similar method for the</span>
<span class="sd">        2D ALE to measure the feature interaction strength.</span>

<span class="sd">        This method is inspired by the feature importance and interaction</span>
<span class="sd">        methods developed in Greenwell et al. (2018) [4]_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        ale : xarray.Dataset</span>

<span class="sd">            Results of :func:`~ExplainToolkit.ale` for</span>
<span class="sd">            ``features``.</span>

<span class="sd">        features : &#39;all&#39;, string, list of strings, list of 2-tuples</span>

<span class="sd">            Features to compute the ALE variance for. If set to ``&#39;all&#39;``, it is</span>
<span class="sd">            computed for all features. If ``interaction=True``, then features</span>
<span class="sd">            must be a list of 2-tuples for computing the interaction between</span>
<span class="sd">            the set of feature combinations.</span>

<span class="sd">        estimator_names : string, list of strings</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute the ALE variance for.</span>

<span class="sd">        interaction : boolean</span>

<span class="sd">            - If True, it computes the feature interaction strength</span>
<span class="sd">            - If False, compute the feature importance</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            ALE variance results. Includes both the rankings and scores.</span>

<span class="sd">        References</span>
<span class="sd">        -------------</span>

<span class="sd">        .. [4] Greenwell, B. M., B. C. Boehmke, and A. J. McCarthy, 2018:</span>
<span class="sd">               A Simple and Effective estimator-Based Variable Importance Measure. Arxiv,.</span>


<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; import itertools</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;, n_bins=10, subsample=1000, n_bootstrap=1)</span>
<span class="sd">        &gt;&gt;&gt; # Compute 1D ALE variance</span>
<span class="sd">        &gt;&gt;&gt; ale_var_results = explainer.ale_variance(ale)</span>
<span class="sd">        &gt;&gt;&gt; print(ale_var_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">        Dimensions:    (n_bootstrap: 1, n_vars_ale_variance: 30)</span>
<span class="sd">        Dimensions without coordinates: n_bootstrap, n_vars_ale_variance</span>
<span class="sd">        Data variables:</span>
<span class="sd">            ale_variance_rankings__Random Forest        (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="sd">            ale_variance_scores__Random Forest          (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_rankings__Gradient Boosting    (n_vars_ale_variance) &lt;U17 &#39;u...</span>
<span class="sd">            ale_variance_scores__Gradient Boosting      (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_rankings__Logistic Regression  (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="sd">            ale_variance_scores__Logistic Regression    (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">        Attribute:</span>
<span class="sd">            estimator_output:  probability</span>
<span class="sd">            estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="sd">            n_multipass_vars:  5</span>
<span class="sd">            method:            ale_variance</span>
<span class="sd">            direction:         backward</span>
<span class="sd">            evaluation_fn:     sigma_ale</span>
<span class="sd">            dimension:         1D</span>
<span class="sd">            features used:     [&#39;dllwave_flux&#39;, &#39;dwpt2m&#39;, &#39;fric_vel&#39;, &#39;gflux&#39;, &#39;high_...</span>
<span class="sd">            estimator output:  probability</span>
<span class="sd">            interaction:       False</span>

<span class="sd">        &gt;&gt;&gt; #Typical, we only want to evaluate the feature interactions for</span>
<span class="sd">        &gt;&gt;&gt; # the most important features</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,</span>
<span class="sd">        ...   &#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; # Create all possible combinations</span>
<span class="sd">        &gt;&gt;&gt; important_vars_2d = list(itertools.combinations(important_vars, r=2))</span>
<span class="sd">        &gt;&gt;&gt; #For the 2D ALE variance to measure feature interaction strength</span>
<span class="sd">        &gt;&gt;&gt; ale_2d = explainer.ale(features=important_vars_2d, n_bins=10,</span>
<span class="sd">        ...              subsample=1000, n_bootstrap=1)</span>
<span class="sd">        &gt;&gt;&gt; # Compute 2D ALE variance</span>
<span class="sd">        &gt;&gt;&gt; ale_var_results = explainer.ale_variance(ale_2d, features=important_vars_2d,</span>
<span class="sd">        ...                    interaction=True)</span>
<span class="sd">        &gt;&gt;&gt; print(ale_var_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">        Dimensions:   (n_bootstrap: 1, n_vars_ale_variance_interactions: 10)</span>
<span class="sd">        Dimensions without coordinates: n_bootstrap, n_vars_ale_variance_interactions</span>
<span class="sd">        Data variables:</span>
<span class="sd">            ale_variance_interactions_rankings__Random Forest        (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Random Forest          (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_interactions_rankings__Gradient Boosting    (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Gradient Boosting      (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_interactions_rankings__Logistic Regression  (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Logistic Regression    (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">        Attribute:</span>
<span class="sd">            estimator_output:  probability</span>
<span class="sd">            estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="sd">            n_multipass_vars:  5</span>
<span class="sd">            method:            ale_variance</span>
<span class="sd">            direction:         backward</span>
<span class="sd">            evaluation_fn:     Interaction Importance</span>
<span class="sd">            dimension:         2D</span>
<span class="sd">            features used:     [(&#39;sfc_temp&#39;, &#39;temp2m&#39;), (&#39;sfc_temp&#39;, &#39;sfcT_hrs_bl_fre...</span>
<span class="sd">            estimator output:  probability</span>
<span class="sd">            interaction:       True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span> <span class="ow">or</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Assume all features. </span>
            <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            
            
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>

        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;dimension&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;2D&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="s2">&quot;ale must be second-order if interaction == True&quot;</span>
                <span class="p">)</span>

        <span class="c1"># Check that ale_data is an xarray.Dataset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">xr</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">                                 ale must be an xarray.Dataset, </span>
<span class="sd">                                 perferably generated by ExplainToolkit.ale </span>
<span class="sd">                                 to be formatted correctly</span>
<span class="sd">                                 &quot;&quot;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">any_missing</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
                <span class="p">[</span><span class="n">m</span> <span class="ow">in</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">any_missing</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;ale does not contain values for all the estimator names given!&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_interaction_rankings</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_ale_variance</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ale_variance&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;estimator output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;probability&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;interaction&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">interaction</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;evaluation_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Interaction Importance&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;evaluation_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sigma_ale&quot;</span>  <span class="c1">#&#39;$\sigma$(ALE)&#39;</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.main_effect_complexity"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.main_effect_complexity">[docs]</a>    <span class="k">def</span> <span class="nf">main_effect_complexity</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_segments</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">approx_error</span><span class="o">=</span><span class="mf">0.05</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Main Effect Complexity (MEC; Molnar et al. 2019) [5]_.</span>
<span class="sd">        MEC is the number of linear segements required to approximate</span>
<span class="sd">        the first-order ALE curves averaged over all features.</span>
<span class="sd">        The MEC is weighted-averged by the variance. Higher values indicate</span>
<span class="sd">        a more complex estimator (less interpretable).</span>

<span class="sd">        References</span>
<span class="sd">        -----------</span>
<span class="sd">        .. [5] Molnar, C., G. Casalicchio, and B. Bischl, 2019: Quantifying estimator Complexity via</span>
<span class="sd">            Functional Decomposition for Better Post-Hoc Interpretability. ArXiv.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------------</span>

<span class="sd">        ale : xarray.Dataset</span>

<span class="sd">             Results of :func:`~ExplainToolkit.ale`. Must be computed for all features in X.</span>

<span class="sd">        estimator_names : string, list of strings</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute the MEC for.</span>

<span class="sd">        max_segments : integer; default=10</span>

<span class="sd">            Maximum number of linear segments used to approximate the main/first-order</span>
<span class="sd">            effect of a feature. default is 10. Used to limit the computational runtime.</span>

<span class="sd">        approx_error : float; default=0.05</span>

<span class="sd">            The accepted error of the R squared between the piece-wise linear function</span>
<span class="sd">            and the true ALE curve. If the R square is within the approx_error, then</span>
<span class="sd">            no additional segments are added.</span>


<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">            mec_dict : dictionary</span>
<span class="sd">                mec_dict = {estimator_name0 : mec0, estimator_name1 : mec2, ..., estimator_nameN : mecN,}</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;, n_bins=20, subsample=0.5, n_bootstrap=20)</span>
<span class="sd">        &gt;&gt;&gt; # Compute Main Effect Complexity (MEC)</span>
<span class="sd">        &gt;&gt;&gt; mec_ds = explainer.main_effect_complexity(ale)</span>
<span class="sd">        &gt;&gt;&gt; print(mes_ds)</span>
<span class="sd">        {&#39;Random Forest&#39;: 2.6792782503392756,</span>
<span class="sd">         &#39;Gradient Boosting&#39;: 2.692392706080586,</span>
<span class="sd">         &#39;Logistic Regression&#39;: 1.6338281469152958}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="n">check_all_features_for_ale</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>

        <span class="n">mec_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">estimator_name</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">:</span>
            <span class="n">mec</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_main_effect_complexity</span><span class="p">(</span>
                <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
                <span class="n">ale_ds</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
                <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>
                <span class="n">max_segments</span><span class="o">=</span><span class="n">max_segments</span><span class="p">,</span>
                <span class="n">approx_error</span><span class="o">=</span><span class="n">approx_error</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">mec_dict</span><span class="p">[</span><span class="n">estimator_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">mec</span>

        <span class="k">return</span> <span class="n">mec_dict</span></div>

<div class="viewcode-block" id="ExplainToolkit.perm_based_interaction"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.perm_based_interaction">[docs]</a>    <span class="k">def</span> <span class="nf">perm_based_interaction</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">evaluation_fn</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the performance-based feature interactions from Oh (2019) [6]_.</span>
<span class="sd">        For a pair of features, the loss of skill is recorded for permuting</span>
<span class="sd">        each feature separately and permuting both. If there is no feature interaction</span>
<span class="sd">        and the covariance between the two features is close to zero, the sum of the</span>
<span class="sd">        individual losses will approximately equal the loss of skill from permuting</span>
<span class="sd">        both features. Otherwise, a non-zero difference indicates some interaction.</span>
<span class="sd">        The differences for different pairs of features can be used to rank the</span>
<span class="sd">        strength of any feature interactions.</span>

<span class="sd">        References</span>
<span class="sd">        -------------</span>
<span class="sd">        .. [6]  Oh, Sejong, 2019. Feature Interaction in Terms of Prediction Performance</span>
<span class="sd">            https://www.mdpi.com/2076-3417/9/23/5191</span>


<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        features : list of 2-tuple of strings</span>
<span class="sd">            Pairs of features to compute the interaction strength for.</span>

<span class="sd">        evaluation_fn : string or callable</span>
<span class="sd">            evaluation/scoring function for evaluating the loss of skill once a feature is permuted.</span>
<span class="sd">            evaluation_fn can be set to one of the following strings:</span>

<span class="sd">                - ``&quot;auc&quot;``, Area under the Curve</span>
<span class="sd">                - ``&quot;auprc&quot;``, Area under the Precision-Recall Curve</span>
<span class="sd">                - ``&quot;bss&quot;``, Brier Skill Score</span>
<span class="sd">                - ``&quot;mse&quot;``, Mean Square Error</span>
<span class="sd">                - ``&quot;norm_aupdc&quot;``,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</span>

<span class="sd">            Otherwise, evaluation_fn can be any function of form,</span>
<span class="sd">            `evaluation_fn(targets, predictions)` and must return a scalar value</span>

<span class="sd">        estimator_names : string, list of strings</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute for.</span>

<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>

<span class="sd">            - if value is between 0-1, it is interpreted as fraction of total X to use</span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>

<span class="sd">        n_jobs : interger or float (default=1; no multiprocessing)</span>

<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the feature pair rankings.</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>

<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            Permutation importance-based feature interaction strength results</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,</span>
<span class="sd">        ...      &#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; important_vars_2d = list(itertools.combinations(important_vars, r=2))</span>
<span class="sd">        &gt;&gt;&gt; perm_based_interact_ds = explainer.perm_based_interaction(</span>
<span class="sd">        ...                          important_vars_2d, evaluation_fn=&#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                         )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_interaction_rankings_performance_based</span><span class="p">(</span>
            <span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">features</span><span class="p">,</span>
            <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
            <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;perm_based&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;estimator output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;evaluation_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Interaction Importance&quot;</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.ice"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.ice">[docs]</a>    <span class="k">def</span> <span class="nf">ice</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the indiviudal conditional expectations (ICE) [7]_.</span>

<span class="sd">        References</span>
<span class="sd">        ------------</span>
<span class="sd">        .. [7] https://christophm.github.io/interpretable-ml-book/ice.html</span>


<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the ICE for.  if &#39;all&#39;, the method will compute</span>
<span class="sd">            the ICE for all features.</span>

<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the ICE for. Bins are decided based</span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in</span>
<span class="sd">            each bin.</span>

<span class="sd">        n_jobs : float or integer (default=1)</span>

<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        subsample : float or integer (default=1.0)</span>

<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use</span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>

<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the ICE curves.</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>

<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Main keys are the user-provided estimator names while the sub-key</span>
<span class="sd">            are the features computed for. The items are data for the ICE curves. Also,</span>
<span class="sd">            contains X data (feature values where the ICE curves were computed) for plotting.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ice_ds = explainer.ice(features=&#39;all&#39;, subsample=200)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ice&quot;</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">dimension</span> <span class="o">=</span> <span class="s2">&quot;2D&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;1D&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ice&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;dimension&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;features used&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feature_used</span> <span class="o">=</span> <span class="n">features</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.pd"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.pd">[docs]</a>    <span class="k">def</span> <span class="nf">pd</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the 1D or 2D centered partial dependence (PD) [8]_.</span>

<span class="sd">        References</span>
<span class="sd">        ------------</span>

<span class="sd">        .. [8] https://christophm.github.io/interpretable-ml-book/pdp.html</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the PD for.  if &#39;all&#39;, the method will compute</span>
<span class="sd">            the PD for all features.</span>

<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the PD for. Bins are decided based</span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in</span>
<span class="sd">            each bin.</span>

<span class="sd">        n_jobs : float or integer (default=1)</span>

<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        subsample : float or integer (default=1.0)</span>

<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use</span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>

<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the PD curves.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Partial dependence result dataset</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd = explainer.pd(features=&#39;all&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            <span class="k">elif</span> <span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all_2d&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pd&quot;</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">dimension</span> <span class="o">=</span> <span class="s2">&quot;2D&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;1D&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pd&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;dimension&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;features used&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span> <span class="o">=</span> <span class="n">features</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.ale"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.ale">[docs]</a>    <span class="k">def</span> <span class="nf">ale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the 1D or 2D centered accumulated local effects (ALE) [9]_ [10]_.</span>
<span class="sd">        For categorical features, simply set the type of those features in the</span>
<span class="sd">        dataframe as ``category`` and the categorical ALE will be computed.</span>

<span class="sd">        References</span>
<span class="sd">        -----------</span>

<span class="sd">        .. [9] https://christophm.github.io/interpretable-ml-book/ale.html</span>

<span class="sd">        .. [10] Apley, D. W., and J. Zhu, 2016: Visualizing the Effects of Predictor Variables in</span>
<span class="sd">                Black Box Supervised Learning Models. ArXiv.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the PD for.  if &#39;all&#39;, the method will compute</span>
<span class="sd">            the ALE for all features.</span>

<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the ALE for. Bins are decided based</span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in</span>
<span class="sd">            each bin.</span>

<span class="sd">        n_jobs : float or integer (default=1)</span>

<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>

<span class="sd">        subsample : float or integer (default=1.0)</span>

<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use</span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>

<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the ALE curves.</span>

<span class="sd">        Returns</span>
<span class="sd">        ----------</span>

<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            ALE result dataset</span>

<span class="sd">        Raise</span>
<span class="sd">        ----------</span>
<span class="sd">        Exception</span>
<span class="sd">            Highly skewed data may not be divisable into n_bins given. In that case, calc_ale</span>
<span class="sd">            uses the max bins the data can be divided into. But a warning message is raised.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models() # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; # Set the type for categorical features and ExplainToolkit with compute the</span>
<span class="sd">        &gt;&gt;&gt; # categorical ALE.</span>
<span class="sd">        &gt;&gt;&gt; X = X.astype({&#39;urban&#39;: &#39;category&#39;, &#39;rural&#39;:&#39;category&#39;})</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            <span class="k">elif</span> <span class="n">features</span> <span class="o">==</span> <span class="s2">&quot;all_2d&quot;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
            <span class="n">random_seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">dimension</span> <span class="o">=</span> <span class="s2">&quot;2D&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;1D&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ale&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;dimension&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;features used&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span> <span class="o">=</span> <span class="n">features</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.friedman_h_stat"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.friedman_h_stat">[docs]</a>    <span class="k">def</span> <span class="nf">friedman_h_stat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pd_1d</span><span class="p">,</span> <span class="n">pd_2d</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the second-order Friedman&#39;s H-statistic for computing feature interactions [11]_ [12]_.</span>
<span class="sd">        Based on equation (44) from Friedman and Popescu (2008) [12]_. Only computes the interaction strength</span>
<span class="sd">        between two features. In future versions of skexplain we hope to include the first-order H-statistics</span>
<span class="sd">        that measure the interaction between a single feature and the</span>
<span class="sd">        remaining set of features.</span>

<span class="sd">        References</span>
<span class="sd">        -----------</span>

<span class="sd">        .. [11] https://christophm.github.io/interpretable-ml-book/interaction.html</span>
<span class="sd">        .. [12] Friedman, J. H., and B. E. Popescu, 2008: Predictive learning via rule ensembles.</span>
<span class="sd">                Ann Appl Statistics, 2, 916–954, https://doi.org/10.1214/07-aoas148.</span>


<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        pd_1d : xarray.Dataset</span>
<span class="sd">            1D partial dependence dataset. Results of :func:`~ExplainToolkit.pd` for ``features``</span>

<span class="sd">        pd_2d : xarray.Dataset</span>
<span class="sd">            2D partial dependence dataset. Results of :func:`~ExplainToolkit.pd`, but 2-tuple combinations</span>
<span class="sd">            of ``features``.</span>

<span class="sd">        features : list of 2-tuples of strings</span>
<span class="sd">            The pairs of features to compute the feature interaction between.</span>

<span class="sd">        estimator_names : string, list of strings (default is None)</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute the H-statistic for.</span>


<span class="sd">        Returns</span>
<span class="sd">        ----------</span>

<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            The second-order Friedman H-statistic for all estimators.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd_1d = explainer.pd(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; pd_2d = explainer.pd(features=&#39;all_2d&#39;)</span>
<span class="sd">        &gt;&gt;&gt; hstat = explainer.friedman_h_stat(pd_1d, pd_2d,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_scalar_interaction_stats</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;hstat&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">pd_1d</span><span class="p">,</span>
            <span class="n">data_2d</span><span class="o">=</span><span class="n">pd_2d</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.interaction_strength"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.interaction_strength">[docs]</a>    <span class="k">def</span> <span class="nf">interaction_strength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the InterAction Strength (IAS) statistic from Molnar et al. (2019) [5]_.</span>
<span class="sd">        The IAS varies between 0-1 where values closer to 0 indicate no feature interaction</span>
<span class="sd">        strength.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>

<span class="sd">        ale : xarray.Dataset</span>

<span class="sd">            Results of :func:`~ExplainToolkit.ale`, but must be computed for all features</span>

<span class="sd">        estimator_names : string, list of strings (default is None)</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute the IAS for.</span>

<span class="sd">        kwargs : dict</span>

<span class="sd">            - subsample</span>
<span class="sd">            - n_bootstrap</span>
<span class="sd">            - estimator_output</span>

<span class="sd">        Returns</span>
<span class="sd">        ----------</span>

<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            Interaction strength result dataset</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ias = explainer.interaction_strength(ale)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="n">check_all_features_for_ale</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>        
                
        <span class="c1"># Check that ale_data is an xarray.Dataset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">xr</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">                                 ale must be an xarray.Dataset, </span>
<span class="sd">                                 perferably generated by mintpy.ExplainToolkit.calc_ale to be formatted correctly</span>
<span class="sd">                                 &quot;&quot;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">any_missing</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
                <span class="p">[</span><span class="n">m</span> <span class="ow">in</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">any_missing</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;ale does not contain data for all the estimator names given!&quot;</span>
                <span class="p">)</span>

        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_scalar_interaction_stats</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ias&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

    <span class="k">def</span> <span class="nf">_plot_interpret_curves</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">method</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="p">,</span>
        <span class="n">add_hist</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">to_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">line_kws</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        FOR INTERNAL USE ONLY.</span>

<span class="sd">        Handles 1D or 2D PD/ALE plots.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No features were provided to plot!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
                <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;dimension&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;2D&quot;</span><span class="p">:</span>
            <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotInterpret2D</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_contours</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">base_font_size</span> <span class="o">=</span> <span class="mi">12</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">6</span> <span class="k">else</span> <span class="mi">16</span>
            <span class="n">base_font_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_font_size&quot;</span><span class="p">,</span> <span class="n">base_font_size</span><span class="p">)</span>
            <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotInterpretCurves</span><span class="p">(</span><span class="n">BASE_FONT_SIZE</span><span class="o">=</span><span class="n">base_font_size</span><span class="p">,</span> <span class="n">seaborn_kws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_1d_curve</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">add_hist</span><span class="o">=</span><span class="n">add_hist</span><span class="p">,</span>
                <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
                <span class="n">line_kws</span><span class="o">=</span><span class="n">line_kws</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="ExplainToolkit.plot_pd"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_pd">[docs]</a>    <span class="k">def</span> <span class="nf">plot_pd</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">add_hist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">to_probability</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">line_kws</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the 1D and 2D partial dependence plotting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        pd : xarray.Dataset</span>
<span class="sd">            Results of :func:`~ExplainToolkit.pd` for</span>
<span class="sd">            ``features``.</span>

<span class="sd">        features : string, list of strings, list of 2-tuple of strings</span>
<span class="sd">            Features to plot the PD for.  To plot for 2D PD,</span>
<span class="sd">            pass a list of 2-tuples of features.</span>

<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to plot for.</span>

<span class="sd">        add_hist : True/False (default=True)</span>
<span class="sd">            If True, adds the histogram of a feature&#39;s values behind the interpret curves.</span>

<span class="sd">        display_feature_names : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>

<span class="sd">            The plotting code can handle latex-style formatting.</span>

<span class="sd">        display_units : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            to their units.</span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>

<span class="sd">        line_colors : str or list of strs of len(estimators)</span>
<span class="sd">            User-defined colors for curve plotting.</span>

<span class="sd">        to_probability : boolean</span>
<span class="sd">            If True, the values are multipled by 100.</span>

<span class="sd">        Keyword arguments include arguments typically used for matplotlib.</span>


<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        fig, axes: matplotlib figure instance and the corresponding axes</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models() # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd = explainer.calc_pd(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Provide a small subset of features to plot</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;,</span>
<span class="sd">        ...     &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_pd(pd, features=important_vars)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">to_probability</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pd</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">to_probability</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;left_yaxis_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Centered PD (%)&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;left_yaxis_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Centered PD&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plot_interpret_curves</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pd&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">add_hist</span><span class="o">=</span><span class="n">add_hist</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
            <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
            <span class="n">line_kws</span><span class="o">=</span><span class="n">line_kws</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_ale"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_ale">[docs]</a>    <span class="k">def</span> <span class="nf">plot_ale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">add_hist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">to_probability</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">line_kws</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the 1D and 2D accumulated local effects plotting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        ale : xarray.Dataset</span>
<span class="sd">             Results of :func:`~ExplainToolkit.ale` for</span>
<span class="sd">            ``features``.</span>

<span class="sd">        features : string, list of strings, list of 2-tuple of strings</span>
<span class="sd">            Features to plot the PD for.  To plot for 2D PD,</span>
<span class="sd">            pass a list of 2-tuples of features.</span>

<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to plot for.</span>

<span class="sd">        add_hist : True/False (default=True)</span>
<span class="sd">            If True, adds the histogram of a feature&#39;s values behind the interpret curves.</span>

<span class="sd">        display_feature_names : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>

<span class="sd">            The plotting code can handle latex-style formatting.</span>

<span class="sd">        display_units : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            to their units.</span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>

<span class="sd">        line_colors : str or list of strs of len(estimators)</span>
<span class="sd">            User-defined colors for curve plotting.</span>

<span class="sd">        to_probability : boolean</span>
<span class="sd">            If True, the values are multipled by 100.</span>

<span class="sd">        Keyword arguments include arguments typically used for matplotlib.</span>
<span class="sd">            E.g.,</span>
<span class="sd">            figsize, hist_color,</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        fig, axes: matplotlib figure instance and the corresponding axes</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Provide a small subset of features to plot</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;,</span>
<span class="sd">        ...     &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_ale(ale, features=important_vars)</span>

<span class="sd">        .. image :: ../../images/ale_1d.png</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">to_probability</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">to_probability</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;left_yaxis_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Centered ALE (%)&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;left_yaxis_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Centered ALE&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plot_interpret_curves</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
            <span class="n">add_hist</span><span class="o">=</span><span class="n">add_hist</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
            <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
            <span class="n">line_kws</span><span class="o">=</span><span class="n">line_kws</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.local_contributions"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.local_contributions">[docs]</a>    <span class="k">def</span> <span class="nf">local_contributions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;shap&quot;</span><span class="p">,</span>
        <span class="n">performance_based</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">shap_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lime_kws</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the individual feature contributions to a predicted outcome for</span>
<span class="sd">        a series of examples either based on tree interpreter (only Tree-based methods)</span>
<span class="sd">        , Shapley Additive Explanations, or Local Interpretable Model-Agnostic Explanations (LIME). </span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        method : ``&#39;shap&#39;`` , ``&#39;tree_interpreter&#39;``, or ``&#39;lime&#39;``</span>
<span class="sd">            Can use SHAP, treeinterpreter, or LIME to compute the feature contributions.</span>
<span class="sd">            SHAP and LIME are estimator-agnostic while treeinterpreter can only be used on</span>
<span class="sd">            select decision-tree based estimators in scikit-learn (e.g., random forests). </span>
<span class="sd">            </span>
<span class="sd">        performance_based : boolean (default=False)</span>
<span class="sd">            If True, will average feature contributions over the best and worst</span>
<span class="sd">            performing of the given X. The number of examples to average over</span>
<span class="sd">            is given by n_samples</span>

<span class="sd">        n_samples : interger (default=100)</span>
<span class="sd">            Number of samples to compute average over if performance_based = True</span>

<span class="sd">        shap_kwargs : dict</span>
<span class="sd">            Arguments passed to the shap.Explainer object. See</span>
<span class="sd">            https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer</span>
<span class="sd">            for details. The main two arguments supported in skexplain is the masker and</span>
<span class="sd">            algorithm options. By default, the masker option uses</span>
<span class="sd">            masker = shap.maskers.Partition(X, max_samples=100, clustering=&quot;correlation&quot;) for</span>
<span class="sd">            hierarchical clustering by correlations. You can also provide a background dataset</span>
<span class="sd">            e.g., background_dataset = shap.sample(X, 100).reset_index(drop=True). The algorithm</span>
<span class="sd">            option is set to &quot;auto&quot; by default.</span>

<span class="sd">            - masker</span>
<span class="sd">            - algorithm</span>

<span class="sd">        lime_kws : dict </span>
<span class="sd">            Arguments passed to the LimeTabularExplainer object. See https://github.com/marcotcr/lime</span>
<span class="sd">            for details. Generally, you&#39;ll pass the in the following:</span>
<span class="sd">            </span>
<span class="sd">            - training_data </span>
<span class="sd">            - categorical_names (scikit-explain will attempt to determine it internally, </span>
<span class="sd">                                 if it is not passed in)</span>
<span class="sd">            - random_state (for reproduciability) </span>
<span class="sd">           </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        results_df : nested pandas.DataFrame</span>
<span class="sd">            For each example, contributions from each feature plus the bias</span>
<span class="sd">            The dataframe is nested by the estimator names and additional keys</span>
<span class="sd">            if performance_based=True.</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; # Only give the X you want contributions for.</span>
<span class="sd">        &gt;&gt;&gt; # In this case, we are using a single example.</span>
<span class="sd">        &gt;&gt;&gt; single_example = X.iloc[[0]]</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=single_example,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;,</span>
<span class="sd">        ...                   background_dataset=background_dataset)</span>

<span class="sd">        &gt;&gt;&gt; # For the performance-based contributions,</span>
<span class="sd">        &gt;&gt;&gt; # provide the full set of X and y values.</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                            y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;,</span>
<span class="sd">        ...                   background_dataset=background_dataset,</span>
<span class="sd">        ...                   performance_based=True, n_samples=100)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;shap&quot;</span><span class="p">,</span> <span class="s2">&quot;tree_interpreter&quot;</span><span class="p">,</span> <span class="s2">&quot;lime&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid method! Method must be &#39;shap&#39;, &#39;tree_interpreter&#39;, &#39;lime&#39;&quot;</span>
            <span class="p">)</span>

        <span class="n">results_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="o">.</span><span class="n">_get_local_prediction</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
            <span class="n">performance_based</span><span class="o">=</span><span class="n">performance_based</span><span class="p">,</span>
            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
            <span class="n">shap_kwargs</span><span class="o">=</span><span class="n">shap_kwargs</span><span class="p">,</span>
            <span class="n">lime_kws</span><span class="o">=</span><span class="n">lime_kws</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Add metadata</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;method&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;n_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;performance_based&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">performance_based</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;feature_names&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
        <span class="n">results_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_df</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_df</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_contributions"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_contributions">[docs]</a>    <span class="k">def</span> <span class="nf">plot_contributions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">contrib</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the feature contributions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        contrib : Nested pandas.DataFrame</span>
<span class="sd">            Results of :func:`~ExplainToolkit.local_contributions`</span>

<span class="sd">        features : string or list of strings (default=None)</span>

<span class="sd">               Features to plot. If None, all features are eligible to be plotted.</span>
<span class="sd">               However, the default number of features to plot is 10. Can be set</span>
<span class="sd">               by n_vars (see keyword arguments).</span>

<span class="sd">        estimator_names : string, list of strings (default is None)</span>

<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s)</span>
<span class="sd">            to compute the IAS for.</span>

<span class="sd">        display_feature_names : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., display_feature_names = { &#39;dwpt2m&#39; : &#39;T$_{d}$&#39;, }</span>
<span class="sd">            The plotting code can handle latex-style formatting.</span>

<span class="sd">        Keyword arguments include arguments typically used for matplotlib</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>

<span class="sd">        fig: matplotlib figure instance</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models() # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; # Only give the X you want contributions for.</span>
<span class="sd">        &gt;&gt;&gt; # In this case, we are using a single example.</span>
<span class="sd">        &gt;&gt;&gt; single_example = X.iloc[[0]]</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=single_example,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;,</span>
<span class="sd">        ...                   background_dataset=background_dataset)</span>

<span class="sd">        &gt;&gt;&gt; explainer.plot_contributions(contrib_ds)</span>

<span class="sd">        .. image :: ../../images/feature_contribution_single.png</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="n">estimator_output</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;feature_names&quot;</span><span class="p">]</span>

        <span class="c1"># initialize a plotting object</span>
        <span class="n">only_one_panel</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">contrib</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;non_performance&quot;</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">base_font_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_font_size&quot;</span><span class="p">,</span> <span class="mi">16</span> <span class="k">if</span> <span class="n">only_one_panel</span> <span class="k">else</span> <span class="mi">11</span><span class="p">)</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotFeatureContributions</span><span class="p">(</span><span class="n">BASE_FONT_SIZE</span><span class="o">=</span><span class="n">base_font_size</span><span class="p">,</span> <span class="n">seaborn_kws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span>

        <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_contributions</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">contrib</span><span class="p">,</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.shap"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.shap">[docs]</a>    <span class="k">def</span> <span class="nf">shap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shap_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;masker&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">}):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the SHapley Additive Explanations (SHAP) values [13]_ [14]_ [15]_. </span>
<span class="sd">        By default, we set algorithm = ``&#39;auto&#39;``, so that the best algorithm </span>
<span class="sd">        for a model is determined internally in the SHAP package. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------------</span>
<span class="sd">        shap_kwargs : dict</span>
<span class="sd">            Arguments passed to the shap.Explainer object. See</span>
<span class="sd">            https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer</span>
<span class="sd">            for details. The main two arguments supported in skexplain is the masker and</span>
<span class="sd">            algorithm options. By default, the masker option uses</span>
<span class="sd">            masker = shap.maskers.Partition(X, max_samples=100, clustering=&quot;correlation&quot;) for</span>
<span class="sd">            hierarchical clustering by correlations. You can also provide a background dataset</span>
<span class="sd">            e.g., background_dataset = shap.sample(X, 100).reset_index(drop=True). The algorithm</span>
<span class="sd">            option is set to &quot;auto&quot; by default.</span>

<span class="sd">            - masker</span>
<span class="sd">            - algorithm</span>

<span class="sd">        Returns</span>
<span class="sd">        -------------------</span>

<span class="sd">        results : xarray.Dataset</span>
<span class="sd">            A dataset containing shap values [(n_samples, n_features)] for each estimator</span>
<span class="sd">            (e.g., &#39;shap_values__estimator_name&#39;), the bias (&#39;bias__estimator_name&#39;)</span>
<span class="sd">            of shape (n_examples, 1), and the X and y values the shap values were determined from.</span>

<span class="sd">        References</span>
<span class="sd">        ------------</span>
<span class="sd">        .. [13] https://christophm.github.io/interpretable-ml-book/shap.html</span>
<span class="sd">        .. [14] Lundberg, S. M., G. G. Erion, and S.-I. Lee, 2018: Consistent Individualized</span>
<span class="sd">                Feature Attribution for Tree Ensembles. Arxiv,.</span>
<span class="sd">        .. [15] Lundberg, S. M., and Coauthors, 2020: From local explanations to global understanding</span>
<span class="sd">                with explainable AI for trees. Nat Mach Intell, 2, 56–67, https://doi.org/10.1038/s42256-019-0138-9.</span>


<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, _ = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; X_subset = shap.sample(X, 50, random_state=22)</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X_subset,)</span>
<span class="sd">        &gt;&gt;&gt; results = explainer.shap(shap_kwargs={&#39;masker&#39; :</span>
<span class="sd">        ...                          shap.maskers.Partition(X, max_samples=100, clustering=&quot;correlation&quot;),</span>
<span class="sd">        ...                          &#39;algorithm&#39; : &#39;auto&#39;})</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">include_ys</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sd">&quot;&quot;&quot;No y values were provided! </span>
<span class="sd">                          The y values are useful for color-coding in the shap dependence plots.&quot;&quot;&quot;</span>
            <span class="p">)</span>
            <span class="n">include_ys</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">estimator_name</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">shap_values</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="o">.</span><span class="n">_get_shap_values</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                <span class="n">shap_kwargs</span><span class="o">=</span><span class="n">shap_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">dataset</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;shap_values__</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;n_examples&quot;</span><span class="p">,</span> <span class="s2">&quot;n_features&quot;</span><span class="p">],</span>
                <span class="n">shap_values</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">dataset</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;bias__</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;n_examples&quot;</span><span class="p">],</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="s2">&quot;n_examples&quot;</span><span class="p">,</span> <span class="s2">&quot;n_features&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

        <span class="c1"># Y may not be given. Need to check!</span>
        <span class="k">if</span> <span class="n">include_ys</span><span class="p">:</span>
            <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="s2">&quot;n_examples&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_shap"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_shap">[docs]</a>    <span class="k">def</span> <span class="nf">plot_shap</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">shap_values</span><span class="p">,</span>
        <span class="n">estimator_name</span><span class="p">,</span>
        <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the SHapley Additive Explanations (SHAP) [13]_ [14]_ [15]_ summary plot or dependence</span>
<span class="sd">        plots for various features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        plot_type : ``&#39;summary&#39;`` or ``&#39;dependence&#39;``</span>
<span class="sd">            if &#39;summary&#39;, plots a feature importance-style plot</span>
<span class="sd">            if &#39;dependence&#39;, plots a partial depedence style plot</span>

<span class="sd">        shap_values : array of shape (n_samples, n_features)</span>

<span class="sd">            SHAP values</span>

<span class="sd">        features : string or list of strings (default=None)</span>
<span class="sd">            features to plots if plot_type is &#39;dependence&#39;.</span>

<span class="sd">        display_feature_names : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>
<span class="sd">            The plotting code can handle latex-style formatting.</span>

<span class="sd">        display_units : dict</span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            to their units.</span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>

<span class="sd">        to_probability : boolean</span>
<span class="sd">            if True, values are multiplied by 100.</span>

<span class="sd">        Returns</span>
<span class="sd">        -----------------------</span>
<span class="sd">        fig: matplotlib figure instance</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; shap_results = explainer.shap(background_dataset)</span>
<span class="sd">        &gt;&gt;&gt; print(estimator_names)</span>
<span class="sd">        ... [&#39;Random Forest&#39;, ]</span>
<span class="sd">        &gt;&gt;&gt; shap_values, bias = shap_results[estimator_names[0]]</span>
<span class="sd">        &gt;&gt;&gt; # Plot the SHAP-summary style plot</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_shap(plot_type=&#39;summary&#39;,shap_values=shap_values,)</span>

<span class="sd">        &gt;&gt;&gt; # Plot the SHAP-dependence style plot</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_shap(plot_type=&#39;dependence&#39;,</span>
<span class="sd">        ...            shap_values=shap_values, features=important_vars)</span>

<span class="sd">        .. image :: ../../images/shap_dependence.png</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">plot_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span> <span class="s2">&quot;dependence&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid plot_type! Must be &#39;summary&#39; or &#39;dependence&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">xr</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;shap_values__</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shap_values</span><span class="o">.</span><span class="n">data_vars</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> is not an available variable for this dataset! </span>
<span class="s2">                                Check that SHAP values were compute for estimator : </span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                                &quot;&quot;&quot;</span>
                <span class="p">)</span>

            <span class="n">shap_values</span> <span class="o">=</span> <span class="n">shap_values</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;shap_values__</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;shap_values must be 2D array-like data!&quot;</span><span class="p">)</span>

        <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="n">to_probability</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;to_probability&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">to_probability</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">True</span>        
                
        <span class="c1">###to_probability = True if self.estimator_output == &#39;probability&#39; else False</span>
        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">shap_values_copy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">shap_values_copy</span> <span class="o">*=</span> <span class="mf">100.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shap_values_copy</span> <span class="o">=</span> <span class="n">shap_values</span>

        <span class="c1"># initialize a plotting object</span>
        <span class="k">if</span> <span class="n">plot_type</span> <span class="o">==</span> <span class="s2">&quot;summary&quot;</span><span class="p">:</span>
            <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">6</span> <span class="k">else</span> <span class="mi">16</span>

        <span class="n">base_font_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_font_size&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="p">)</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotFeatureContributions</span><span class="p">(</span><span class="n">BASE_FONT_SIZE</span><span class="o">=</span><span class="n">base_font_size</span><span class="p">,</span> <span class="n">seaborn_kws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="p">)</span>
        <span class="n">plot_obj</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
        <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_shap</span><span class="p">(</span>
            <span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_copy</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_importance"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_importance">[docs]</a>    <span class="k">def</span> <span class="nf">plot_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">panels</span><span class="p">,</span> <span class="n">plot_correlated_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for plotting the permutation importance and other ranking-based results.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -------------</span>
<span class="sd">        panels: List of 2-tuple of (estimator name, method) to determine the sub-panel</span>
<span class="sd">                matrixing for the plotting. E.g., If you wanted to compare multi-pass to</span>
<span class="sd">                single-pass permutation importance for a random forest:</span>
<span class="sd">               ``panels  = [(&#39;Random Forest&#39;, &#39;multipass&#39;), (&#39;Random Forest&#39;, &#39;singlepass&#39;)``</span>
<span class="sd">                The available ranking methods in skexplain include &#39;multipass&#39;, &#39;singlepass&#39;,</span>
<span class="sd">                &#39;perm_based&#39;, &#39;ale_variance&#39;, or &#39;ale_variance_interactions&#39;.</span>

<span class="sd">        data :  list of xarray.Datasets</span>
<span class="sd">            Results from</span>

<span class="sd">            - :func:`~ExplainToolkit.permutation_importance`</span>
<span class="sd">            - :func:`~ExplainToolkit.ale_variance`</span>
<span class="sd">            - :func:`~ExplainToolkit.friedman_h_stat`</span>
<span class="sd">            - :func:`~ExplainToolkit.perm_based_interaction`</span>

<span class="sd">            For each element in panels, there needs to be a corresponding element in data.</span>

<span class="sd">        columns : list of strings</span>
<span class="sd">            What will be the columns of the plot? These can be x-axis label (default is</span>
<span class="sd">            the different estimator names)</span>

<span class="sd">        rows : list of strings</span>
<span class="sd">            Y-axis label or multiple labels for each row in a multi-panel plot. (default is None).</span>

<span class="sd">        plot_correlated_features : boolean</span>
<span class="sd">            If True, pairs of features with a linear correlation coefficient &gt; 0.8</span>
<span class="sd">            are annotate/paired by bars or color-coding. This is useful for identifying</span>
<span class="sd">            spurious rankings due to the correlations.</span>

<span class="sd">        kwargs : keyword arguments</span>

<span class="sd">        num_vars_to_plot : integer</span>
<span class="sd">            Number of features to plot from permutation importance calculation.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        fig: matplotlib figure instance</span>


<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.permutation_importance(</span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20,</span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_importance(data=perm_imp_results, method=&#39;multipass&#39;)</span>


<span class="sd">        &gt;&gt;&gt; #If we want to annonate pairs of highly correlated feature pairs</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_importance(data=perm_imp_results, method=&#39;multipass&#39;,</span>
<span class="sd">        ...                     plot_correlated_features=True)</span>

<span class="sd">        .. image :: ../../images/multi_pass_perm_imp.png</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_list</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">panels</span>
            <span class="p">),</span> <span class="s2">&quot;Panels and Data must have the same number of elements&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">panels</span><span class="p">):</span>
            <span class="c1"># Assuming that data contains multiple models.</span>
            <span class="n">given_estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">panels</span><span class="p">]</span>
            <span class="n">available_estimators</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;rankings__&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data_vars</span><span class="p">)</span> <span class="k">if</span> <span class="s2">&quot;rank&quot;</span> <span class="ow">in</span> <span class="n">f</span>
            <span class="p">]</span>
            <span class="n">missing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="kc">True</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">available_estimators</span> <span class="k">else</span> <span class="kc">False</span>
                    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">given_estimator_names</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="n">missing_estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">given_estimator_names</span><span class="p">)[</span><span class="n">missing</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">missing</span><span class="p">):</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">missing_estimators</span><span class="p">:</span>
                    <span class="n">txt</span> <span class="o">+=</span> <span class="n">i</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Results for </span><span class="si">{</span><span class="n">txt</span><span class="si">}</span><span class="s2"> are not in the given dataset. </span>
<span class="s2">                      Check for possible spelling errors&quot;&quot;&quot;</span>
                <span class="p">)</span>

            <span class="n">data</span> <span class="o">*=</span> <span class="nb">len</span><span class="p">(</span><span class="n">panels</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">estimator_name</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">panels</span><span class="p">):</span>
            <span class="n">available_methods</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">d</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">data_vars</span><span class="p">)</span>
                <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;rankings__</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">d</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_rankings&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">available_methods</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2"> does not match the available methods for this item(</span><span class="si">{</span><span class="n">available_methods</span><span class="si">}</span><span class="s2">). </span>
<span class="s2">                         Ensure that the elements of data match up with those panels!</span>
<span class="s2">                         Also check for any possible spelling error. </span>
<span class="s2">                         &quot;&quot;&quot;</span>
                <span class="p">)</span>

        <span class="n">estimator_output</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># initialize a plotting object</span>
        <span class="n">base_font_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_font_size&quot;</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotImportance</span><span class="p">(</span><span class="n">BASE_FONT_SIZE</span><span class="o">=</span><span class="n">base_font_size</span><span class="p">,</span> <span class="n">seaborn_kws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">plot_correlated_features</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>

        <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_variable_importance</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span>
            <span class="n">panels</span><span class="o">=</span><span class="n">panels</span><span class="p">,</span>
            <span class="n">plot_correlated_features</span><span class="o">=</span><span class="n">plot_correlated_features</span><span class="p">,</span>
            <span class="n">estimator_output</span><span class="o">=</span><span class="n">estimator_output</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_box_and_whisker"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_box_and_whisker">[docs]</a>    <span class="k">def</span> <span class="nf">plot_box_and_whisker</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">important_vars</span><span class="p">,</span>
        <span class="n">example</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the training dataset distribution for a given set of important variables</span>
<span class="sd">        as a box-and-whisker plot. The user provides a single example, which is highlighted</span>
<span class="sd">        over those examples. Useful for real-time explainability.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------------</span>

<span class="sd">        important_vars : str or list of strings</span>
<span class="sd">            List of features to plot</span>

<span class="sd">        example : Pandas Series, shape = (important_vars,)</span>
<span class="sd">            Single row dataframe to be overlaid, must have columns equal to</span>
<span class="sd">            the given important_vars</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_list</span><span class="p">(</span><span class="n">important_vars</span><span class="p">):</span>
            <span class="n">important_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">important_vars</span><span class="p">]</span>

        <span class="n">axis</span> <span class="o">=</span> <span class="s2">&quot;columns&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;index&quot;</span>
        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">important_vars</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The example dataframe/series must have important_vars as columns!&quot;</span>
            <span class="p">)</span>

        <span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">box_and_whisker</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">top_preds</span><span class="o">=</span><span class="n">important_vars</span><span class="p">,</span>
            <span class="n">example</span><span class="o">=</span><span class="n">example</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">,</span> <span class="n">axes</span></div>

<div class="viewcode-block" id="ExplainToolkit.plot_scatter"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.plot_scatter">[docs]</a>    <span class="k">def</span> <span class="nf">plot_scatter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        2-D Scatter plot of ML model predictions. If kde=True, it will plot KDE contours</span>
<span class="sd">        overlays to show highest concentrations. If the model type is classification, then</span>
<span class="sd">        the code will plot KDE contours per class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Handle plotting multiple models!</span>
        <span class="c1"># TODO: Determining if it is raw or probability (multiple classes too!)</span>
        <span class="c1"># if there is more than a couple classes, then only plot one kde contours</span>

        <span class="c1"># Are features in X?</span>
        <span class="n">bad_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">f</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bad_features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">bad_features</span><span class="si">}</span><span class="s2"> is not a valid feature. Check for possible spelling errors!&quot;</span>
            <span class="p">)</span>

        <span class="c1"># initialize a plotting object</span>
        <span class="n">base_font_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_font_size&quot;</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotScatter</span><span class="p">(</span><span class="n">base_font_size</span><span class="p">,</span> <span class="n">seaborn_kws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seaborn_kws</span><span class="p">)</span>

        <span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
            <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">peak_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">kde</span><span class="o">=</span><span class="n">kde</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">f</span><span class="p">,</span> <span class="n">axes</span></div>

<div class="viewcode-block" id="ExplainToolkit.get_important_vars"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.get_important_vars">[docs]</a>    <span class="k">def</span> <span class="nf">get_important_vars</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">perm_imp_data</span><span class="p">,</span> <span class="n">multipass</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the most important variables from permutation importance.</span>
<span class="sd">        Can combine rankings from different estimators and only keep those variables that</span>
<span class="sd">        occur in more than one estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>

<span class="sd">        perm_imp_data : xarray.Dataset</span>
<span class="sd">            Permutation importance result dataset</span>

<span class="sd">        multipass : boolean (defaults to True)</span>

<span class="sd">            if True, return the multipass rankings else returns the singlepass rankings</span>

<span class="sd">        n_vars : integer (default=10)</span>
<span class="sd">            Number of variables to retrieve if multipass=True.</span>

<span class="sd">        combine : boolean  (default=False)</span>
<span class="sd">            If combine=True, n_vars can be set such that you only include a certain amount of</span>
<span class="sd">            top features from each estimator. E.g., n_vars=5 and combine=True means to combine</span>
<span class="sd">            the top 5 features from each estimator into a single list.</span>

<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">            if combine=True</span>
<span class="sd">                results : list</span>
<span class="sd">                    List of top features from a different estimators.</span>
<span class="sd">            if combine=False</span>
<span class="sd">                results : dict</span>
<span class="sd">                    keys are the estimator names and items are the</span>
<span class="sd">                    top features.</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_data = explainer.permutation_importance(</span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20,</span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; important_vars = explainer.get_important_vars(perm_imp_data,</span>
<span class="sd">        ...        multipass=True, n_vars=5, combine=False)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # set combine=True</span>
<span class="sd">        &gt;&gt;&gt; important_vars = explainer.get_important_vars(perm_imp_data,</span>
<span class="sd">        ...        multipass=True, n_vars=5, combine=True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">retrieve_important_vars</span><span class="p">(</span>
            <span class="n">perm_imp_data</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span> <span class="n">multipass</span><span class="o">=</span><span class="n">multipass</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">combine</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">combine_top_features</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="n">n_vars</span><span class="p">)</span></div>

<div class="viewcode-block" id="ExplainToolkit.load"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fnames</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;dataset&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load results of a computation (permutation importance, calc_ale, calc_pd, etc)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fnames : string or list of strings</span>
<span class="sd">            File names of dataframes or datasets to load.</span>

<span class="sd">        dtype : &#39;dataset&#39; or &#39;dataframe&#39;</span>
<span class="sd">            Indicate whether you are loading a set of xarray.Datasets</span>
<span class="sd">            or pandas.DataFrames</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>

<span class="sd">        results : xarray.DataSet or pandas.DataFrame</span>
<span class="sd">            data for plotting purposes</span>

<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit()</span>
<span class="sd">        &gt;&gt;&gt; fname = &#39;path/to/your/perm_imp_results&#39;</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_data = explainer.load(fnames=fname, dtype=&#39;dataset&#39;)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;dataset&quot;</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">load_netcdf</span><span class="p">(</span><span class="n">fnames</span><span class="o">=</span><span class="n">fnames</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;dataframe&quot;</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">load_dataframe</span><span class="p">(</span><span class="n">fnames</span><span class="o">=</span><span class="n">fnames</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dtype must be &quot;dataset&quot; or &quot;dataframe&quot;!&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="p">]:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;estimator_output&quot;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimator_output&quot;</span><span class="p">])</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;estimators used&quot;</span><span class="p">]]</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;estimator_output&quot;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;model_output&quot;</span><span class="p">])</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;models used&quot;</span><span class="p">]]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_list</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">is_list</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">estimator_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;estimator_names&quot;</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;estimators used&quot;</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span>

            <span class="c1"># in the case of shap_values.</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;dataset&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;X&quot;</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">data_vars</span><span class="p">:</span>
                    <span class="n">feature_names</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;feature_names&quot;</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>

                <span class="k">if</span> <span class="s2">&quot;y&quot;</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">data_vars</span><span class="p">:</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="ExplainToolkit.save"><a class="viewcode-back" href="../../../explain_toolkit.html#skexplain.main.explain_toolkit.ExplainToolkit.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save results of a computation (permutation importance, calc_ale, calc_pd, etc)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fname : string</span>
<span class="sd">            filename to store the results in (including path)</span>
<span class="sd">        data : ExplainToolkit results</span>
<span class="sd">            the results of a ExplainToolkit calculation. Can be a dataframe or dataset.</span>

<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">        &gt;&gt;&gt; import skexplain</span>
<span class="sd">        &gt;&gt;&gt; estimators = skexplain.load_models() # pre-fit estimators within skexplain</span>
<span class="sd">        &gt;&gt;&gt; X, y = skexplain.load_data() # training data</span>
<span class="sd">        &gt;&gt;&gt; explainer = skexplain.ExplainToolkit(estimators=estimators</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.calc_permutation_importance(</span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20,</span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; fname = &#39;path/to/save/the/file&#39;</span>
<span class="sd">        &gt;&gt;&gt; explainer.save(fname, perm_imp_results)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">save_netcdf</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fname</span><span class="p">,</span> <span class="n">ds</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_dataframe</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">save_dataframe</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fname</span><span class="p">,</span> <span class="n">dframe</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;data is not a pandas.DataFrame or xarray.Dataset. The type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Montgomery Flora; Shawn Handler.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>