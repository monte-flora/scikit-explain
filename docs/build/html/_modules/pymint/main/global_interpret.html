

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pymint.main.global_interpret &mdash; PyMint v0.0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
  
  
  

  

  
  
    

  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/audeering.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          <a href="../../../index.html">
          
            <img src="../../../_static/images/audeering.svg" class="logo" alt="audEERING"/>
          
          
            <span> PyMint</span>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"></div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyMint</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>pymint.main.global_interpret</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pymint.main.global_interpret</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">cKDTree</span>
<span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">interp1d</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">add</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">roc_auc_score</span><span class="p">,</span>
    <span class="n">roc_curve</span><span class="p">,</span>
    <span class="n">average_precision_score</span><span class="p">,</span>
    <span class="n">mean_squared_error</span><span class="p">,</span>
    <span class="n">r2_score</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">..common.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_bootstrap_indices</span><span class="p">,</span>
    <span class="n">merge_nested_dict</span><span class="p">,</span>
    <span class="n">merge_dict</span><span class="p">,</span>
    <span class="n">is_str</span><span class="p">,</span>
    <span class="n">is_valid_feature</span><span class="p">,</span>
    <span class="n">is_regressor</span><span class="p">,</span>
    <span class="n">is_classifier</span><span class="p">,</span>
    <span class="n">cartesian</span><span class="p">,</span>
    <span class="n">brier_skill_score</span><span class="p">,</span>
    <span class="n">norm_aupdc</span><span class="p">,</span>
    <span class="n">to_xarray</span><span class="p">,</span>
    <span class="n">order_groups</span><span class="p">,</span>
    <span class="n">determine_feature_dtype</span><span class="p">,</span>
    <span class="n">check_is_permuted</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">..common.multiprocessing_utils</span> <span class="kn">import</span> <span class="n">run_parallel</span><span class="p">,</span> <span class="n">to_iterator</span>
<span class="kn">from</span> <span class="nn">..common.attributes</span> <span class="kn">import</span> <span class="n">Attributes</span>

<span class="kn">from</span> <span class="nn">.PermutationImportance</span> <span class="kn">import</span> <span class="n">sklearn_permutation_importance</span>


<div class="viewcode-block" id="GlobalInterpret"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret">[docs]</a><span class="k">class</span> <span class="nc">GlobalInterpret</span><span class="p">(</span><span class="n">Attributes</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    InterpretToolkit inherits functionality from GlobalInterpret and is not meant to be</span>
<span class="sd">    instantiated by the end-user. </span>
<span class="sd">    </span>
<span class="sd">    GlobalInterpret incorporates important methods for explaining global model behavior</span>
<span class="sd">    across all data examples. These include permutation importance and</span>
<span class="sd">    partial dependence (Friedman 2001) / accumulated local effects (Apley and Zhy et al. 2016)</span>
<span class="sd">    which produce feature ranking and expected relationship between a feature</span>
<span class="sd">    with the predict outcome, respectively.</span>

<span class="sd">    The permutation importance computations rely on the</span>
<span class="sd">    PermutationImportance python package (Jergensen 2019) with slight modification for</span>
<span class="sd">    use in py-mint.</span>

<span class="sd">    Parts of the partial dependence code were based on</span>
<span class="sd">    the computations in sklearn.inspection.partial_dependence (Pedregosa et al. 2011).</span>

<span class="sd">    Parts of the accumulated local effects</span>
<span class="sd">    are based on ALEPython (Jumelle 2020) and PyALE.</span>


<span class="sd">    PartialDependence is a class for computing first- and second-order</span>
<span class="sd">    partial dependence (PD; Friedman (2001). Parts of the code were based on</span>
<span class="sd">    the computations in sklearn.inspection.partial_dependence (Pedregosa et al. 2011).</span>
<span class="sd">    Currently, the package handles regression and binary classification.</span>

<span class="sd">    Attributes</span>
<span class="sd">    --------------</span>
<span class="sd">    models : object, list</span>
<span class="sd">        A pre-fit scikit-learn model, or list thereof.</span>

<span class="sd">    model_names : string, list</span>
<span class="sd">        Names of the models (for internal and plotting purposes)</span>

<span class="sd">    examples : pandas.DataFrame or ndnumpy.array; shape = (n_examples, n_features)</span>
<span class="sd">        Training or validation examples to evaluate.</span>
<span class="sd">        If ndnumpy array, make sure to specify the feature names</span>

<span class="sd">    targets : list or numpy.array; shape = (n_examples,)</span>
<span class="sd">        Target values.</span>

<span class="sd">    model_output : &quot;raw&quot; or &quot;probability&quot;</span>
<span class="sd">        What output of the model should be evaluated. default is None. If None, </span>
<span class="sd">        InterpretToolkit will determine internally what the model output is. </span>

<span class="sd">    feature_names : string</span>
<span class="sd">        list of feature names. defaults to None. Feature names are only required </span>
<span class="sd">        if examples is an ndnumpy.array as examples will be converted to a </span>
<span class="sd">        pandas.DataFrame internally. </span>

<span class="sd">    Reference</span>
<span class="sd">    ------------</span>
<span class="sd">        Friedman, J. H., 2001: GREEDY FUNCTION APPROXIMATION: A GRADIENT BOOSTING MACHINE.</span>
<span class="sd">        Ann Statistics, 29, 1189â€“1232, https://doi.org/10.1214/aos/1013203451.</span>

<span class="sd">        Jumelle, M., 2020: ALEPython.</span>
<span class="sd">        Github Python software library https://github.com/blent-ai/ALEPython.</span>

<span class="sd">        Jergensen, G., 2019: PermutationImportance.</span>
<span class="sd">        Github Python software library https://github.com/gelijergensen/PermutationImportance.</span>

<span class="sd">        Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">models</span><span class="p">,</span>
        <span class="n">model_names</span><span class="p">,</span>
        <span class="n">examples</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">model_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">checked_attributes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># These functions come from the inherited Attributes class</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">checked_attributes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_model_attribute</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_examples_attribute</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_target_attribute</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_names</span> <span class="o">=</span> <span class="n">model_names</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">examples</span> <span class="o">=</span> <span class="n">examples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">=</span> <span class="n">model_output</span>

<div class="viewcode-block" id="GlobalInterpret.permutation_importance"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.permutation_importance">[docs]</a>    <span class="k">def</span> <span class="nf">permutation_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_vars</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">evaluation_fn</span><span class="o">=</span><span class="s2">&quot;auprc&quot;</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">scoring_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;backward&#39;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs single-pass and/or multi-pass permutation importance using the PermutationImportance</span>
<span class="sd">        package.</span>

<span class="sd">        See calc_permutation_importance in IntepretToolkit for documentation.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">available_scores</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;auc&quot;</span><span class="p">,</span> <span class="s2">&quot;auprc&quot;</span><span class="p">,</span> <span class="s2">&quot;bss&quot;</span><span class="p">,</span> <span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="s2">&quot;norm_aupdc&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluation_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">evaluation_fn</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">is_str</span><span class="o">=</span><span class="kc">True</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluation_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">scoring_strategy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">                The scoring_strategy argument is None! If you are using a user-define evaluation_fn </span>
<span class="sd">                then scoring_strategy must be set! If a metric is positively-oriented (a higher value is better), </span>
<span class="sd">                then set scoring_strategy = &quot;argmin_of_mean&quot; and if is negatively-oriented-</span>
<span class="sd">                (a lower value is better), then set scoring_strategy = &quot;argmax_of_mean&quot;</span>
<span class="sd">                &quot;&quot;&quot;</span>
            <span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluation_fn</span><span class="p">,</span><span class="nb">str</span><span class="p">):</span>    
            <span class="k">if</span> <span class="n">evaluation_fn</span> <span class="o">==</span> <span class="s2">&quot;auc&quot;</span><span class="p">:</span>
                <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">roc_auc_score</span>
                <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="s2">&quot;argmin_of_mean&quot;</span>
            <span class="k">elif</span> <span class="n">evaluation_fn</span> <span class="o">==</span> <span class="s2">&quot;auprc&quot;</span><span class="p">:</span>
                <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">average_precision_score</span>
                <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="s2">&quot;argmin_of_mean&quot;</span>
            <span class="k">elif</span> <span class="n">evaluation_fn</span> <span class="o">==</span> <span class="s2">&quot;norm_aupdc&quot;</span><span class="p">:</span>
                <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">norm_aupdc</span>
                <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="s2">&quot;argmin_of_mean&quot;</span>
            <span class="k">elif</span> <span class="n">evaluation_fn</span> <span class="o">==</span> <span class="s2">&quot;bss&quot;</span><span class="p">:</span>
                <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">brier_skill_score</span>
                <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="s2">&quot;argmin_of_mean&quot;</span>
            <span class="k">elif</span> <span class="n">evaluation_fn</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
                <span class="n">evaluation_fn</span> <span class="o">=</span> <span class="n">mean_squared_error</span>
                <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="s2">&quot;argmax_of_mean&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;evaluation_fn is not set! Available options are </span><span class="si">{</span><span class="n">available_scores</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_str</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">direction</span> <span class="o">==</span> <span class="s1">&#39;forward&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;max&#39;</span> <span class="ow">in</span> <span class="n">scoring_strategy</span><span class="p">:</span>
                    <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="n">scoring_strategy</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">)</span> 
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">scoring_strategy</span> <span class="o">=</span> <span class="n">scoring_strategy</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">)</span> 
                    
         
                
        <span class="k">if</span> <span class="n">subsample</span> <span class="o">!=</span> <span class="mf">1.0</span> <span class="ow">and</span> <span class="n">n_bootstrap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_bootstrap</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">targets</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Test&quot;</span><span class="p">])</span>

        <span class="n">pi_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># loop over each model</span>
        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">pi_result</span> <span class="o">=</span> <span class="n">sklearn_permutation_importance</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">scoring_data</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
                <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
                <span class="n">variable_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>
                <span class="n">scoring_strategy</span><span class="o">=</span><span class="n">scoring_strategy</span><span class="p">,</span>
                <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                <span class="n">nimportant_vars</span><span class="o">=</span><span class="n">n_vars</span><span class="p">,</span>
                <span class="n">njobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                <span class="n">nbootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">direction</span><span class="o">=</span><span class="n">direction</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">pi_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">pi_result</span>

            <span class="k">del</span> <span class="n">pi_result</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_names</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">func</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;retrieve_multipass&quot;</span><span class="p">,</span> <span class="s2">&quot;retrieve_singlepass&quot;</span><span class="p">]:</span>
                <span class="n">adict</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pi_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">func</span><span class="p">)()</span>
                <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">adict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
                <span class="n">rankings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">([</span><span class="n">adict</span><span class="p">[</span><span class="n">f</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>
                <span class="n">top_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">rankings</span><span class="p">]</span>
                <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">adict</span><span class="p">[</span><span class="n">f</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">top_features</span><span class="p">])</span>
                <span class="n">pass_method</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

                <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pass_method</span><span class="si">}</span><span class="s2">_rankings__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_</span><span class="si">{</span><span class="n">pass_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span>
                    <span class="n">top_features</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pass_method</span><span class="si">}</span><span class="s2">_scores__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_</span><span class="si">{</span><span class="n">pass_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                    <span class="n">scores</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;original_score__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                <span class="n">pi_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">original_score</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

    <span class="k">def</span> <span class="nf">_run_interpret_curves</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">method</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">feature_encoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the interpretation curve (partial dependence, accumulated local effects,</span>
<span class="sd">        or individual conditional expectations.) calculations.</span>
<span class="sd">        Includes assessing whether the calculation is 1D or 2D and handling</span>
<span class="sd">        initializing the parallelization, subsampling data, and/or using bootstraping</span>
<span class="sd">        to compute confidence intervals.</span>

<span class="sd">        Returns a nested dictionary with all neccesary inputs for plotting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ---------</span>
<span class="sd">        method : &#39;pd&#39; , &#39;ale&#39;, or &#39;ice&#39;</span>
<span class="sd">                determines whether to compute partial dependence (&#39;pd&#39;),</span>
<span class="sd">                accumulated local effects (&#39;ale&#39;), or individual conditional expectations (&#39;ice&#39;)</span>

<span class="sd">        features: string, 2-tuple of strings, list of strings, or lists of 2-tuple strings</span>
<span class="sd">                feature names to compute for. If 2-tuple, it will compute</span>
<span class="sd">                the second-order results.</span>

<span class="sd">        n_bins : int</span>
<span class="sd">            Number of evenly-spaced bins to compute PD/ALE over.</span>

<span class="sd">        n_jobs : int or float</span>
<span class="sd">            if int, the number of processors to use for parallelization</span>
<span class="sd">            if float, percentage of total processors to use for parallelization</span>

<span class="sd">        subsample : float or integer</span>
<span class="sd">            if value between 0-1 interpreted as fraction of total examples to use</span>
<span class="sd">                    if value &gt; 1, interpreted as the number of examples to randomly sample</span>
<span class="sd">                        from the original dataset.</span>

<span class="sd">        n_bootstrap: integer</span>
<span class="sd">            Number of bootstrap iterations to perform. Defaults to 1 (no bootstrapping).</span>
<span class="sd">                        </span>
<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        results_ds : xarray.Dataset </span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if features is a string</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">cat_features</span> <span class="o">=</span> <span class="n">determine_feature_dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cat_features</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cat_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ale&quot;</span><span class="p">:</span>
                <span class="c1"># check first element of feature and see if the type is a tuple; assume second-order calculations</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_second_order_ale</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_first_order_ale</span>
            <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;pd&quot;</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_partial_dependence</span>
            <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ice&quot;</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_individual_cond_expect</span>

            <span class="n">args_iterator</span> <span class="o">=</span> <span class="n">to_iterator</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_names</span><span class="p">,</span>
                <span class="n">features</span><span class="p">,</span>
                <span class="p">[</span><span class="n">n_bins</span><span class="p">],</span>
                <span class="p">[</span><span class="n">subsample</span><span class="p">],</span>
                <span class="p">[</span><span class="n">n_bootstrap</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">results</span> <span class="o">=</span> <span class="n">run_parallel</span><span class="p">(</span>
                <span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> <span class="n">args_iterator</span><span class="o">=</span><span class="n">args_iterator</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">nprocs_to_use</span><span class="o">=</span><span class="n">n_jobs</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ale&quot;</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_first_order_ale_cat</span>
            <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;pd&quot;</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_partial_dependence</span>
            <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ice&quot;</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_individual_cond_expect</span>

            <span class="n">args_iterator</span> <span class="o">=</span> <span class="n">to_iterator</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_names</span><span class="p">,</span>
                <span class="n">cat_features</span><span class="p">,</span>
                <span class="p">[</span><span class="n">subsample</span><span class="p">],</span>
                <span class="p">[</span><span class="n">n_bootstrap</span><span class="p">],</span>
                <span class="p">[</span><span class="n">feature_encoder</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">cat_results</span> <span class="o">=</span> <span class="n">run_parallel</span><span class="p">(</span>
                <span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> <span class="n">args_iterator</span><span class="o">=</span><span class="n">args_iterator</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">nprocs_to_use</span><span class="o">=</span><span class="n">n_jobs</span>
            <span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">cat_results</span> <span class="o">+</span> <span class="n">results</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">merge_dict</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span>

    <span class="k">def</span> <span class="nf">_store_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">xdata</span><span class="p">,</span> <span class="n">hist_data</span><span class="p">,</span> <span class="n">categorical</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        FOR INTERNAL PURPOSES ONLY.</span>
<span class="sd">        </span>
<span class="sd">        Store the results of the ALE/PD/ICE calculations into a dict,</span>
<span class="sd">        which is converted to an xarray.Dataset</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">feature1</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">features</span>
        <span class="n">feature2</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;__</span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>

        <span class="n">y_shape</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;n_bootstrap&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;n_bins__</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;n_bins</span><span class="si">{</span><span class="n">feature2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">feature2</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">y_shape</span> <span class="o">=</span> <span class="n">y_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">hist_data1</span> <span class="o">=</span> <span class="n">hist_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">xdata2</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;pd&quot;</span> <span class="ow">or</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ice&quot;</span> <span class="ow">or</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ale&quot;</span> <span class="ow">and</span> <span class="n">categorical</span><span class="p">):</span>
            <span class="n">xdata1</span> <span class="o">=</span> <span class="n">xdata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">xdata</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xdata2</span> <span class="o">=</span> <span class="n">xdata</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">hist_data2</span> <span class="o">=</span> <span class="n">hist_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">feature2</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">xdata1</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">xdata</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">xdata</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">xdata2</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">xdata</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">xdata</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xdata1</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">xdata</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">xdata</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">feature2</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">hist_data2</span> <span class="o">=</span> <span class="n">hist_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}{</span><span class="n">feature2</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_shape</span><span class="p">,</span> <span class="n">ydata</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">__bin_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="sa">f</span><span class="s2">&quot;n_bins__</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="n">xdata1</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="s2">&quot;n_examples&quot;</span><span class="p">],</span> <span class="n">hist_data1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">feature2</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature2</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s2">__bin_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="sa">f</span><span class="s2">&quot;n_bins</span><span class="si">{</span><span class="n">feature2</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="n">xdata2</span><span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature2</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="s2">&quot;n_examples&quot;</span><span class="p">],</span> <span class="n">hist_data2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

<div class="viewcode-block" id="GlobalInterpret.compute_individual_cond_expect"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_individual_cond_expect">[docs]</a>    <span class="k">def</span> <span class="nf">compute_individual_cond_expect</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Individual Conditional Expectations (see https://christophm.github.io/interpretable-ml-book/ice.html)</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">            </span>
<span class="sd">        features : string or 2-tuple of strings</span>
<span class="sd">            Feature name or pair of feature names to compute ICE for. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        ------------</span>
<span class="sd">        </span>
<span class="sd">        results : dict </span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Retrieve the model object from the models dict attribute</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>

        <span class="c1"># Check if features is a string</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="c1"># Check if feature is valid</span>
        <span class="n">is_valid_feature</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">n_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">)</span>
            <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_examples</span> <span class="o">*</span> <span class="n">subsample</span><span class="p">)</span> <span class="k">if</span> <span class="n">subsample</span> <span class="o">&lt;=</span> <span class="mf">1.0</span> <span class="k">else</span> <span class="n">subsample</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_examples</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">examples</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># Extract the values for the features</span>
        <span class="n">feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>

        <span class="c1"># Create a grid of values</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">n_bins</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_values</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="n">prediction_method</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
            <span class="n">prediction_method</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span>

        <span class="n">ice_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">value_set</span> <span class="ow">in</span> <span class="n">cartesian</span><span class="p">(</span><span class="n">grid</span><span class="p">):</span>
            <span class="n">examples_temp</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">examples_temp</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">value_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">ice_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prediction_method</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>

        <span class="n">ice_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ice_values</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="c1"># Binary classification, shape is (2, n_points).</span>
            <span class="c1"># we output the effect of **positive** class</span>
            <span class="c1"># and convert to percentages</span>
            <span class="n">ice_values</span> <span class="o">=</span> <span class="n">ice_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># center the ICE plots</span>
        <span class="n">ice_values</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ice_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ice_values</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ice_values</span> <span class="o">=</span> <span class="n">ice_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_bootstrap</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_store_results</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ice&quot;</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">ydata</span><span class="o">=</span><span class="n">ice_values</span><span class="p">,</span>
            <span class="n">xdata</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
            <span class="n">hist_data</span><span class="o">=</span><span class="n">feature_values</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_partial_dependence"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_partial_dependence">[docs]</a>    <span class="k">def</span> <span class="nf">compute_partial_dependence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the centered partial dependence.</span>

<span class="sd">        # Friedman, J., 2001: Greedy function approximation: a gradient boosting machine.</span>
<span class="sd">        Annals of Statistics, 29 (5), 1189â€“1232.</span>
<span class="sd">        ##########################################################################</span>
<span class="sd">        # Partial dependence plots fix a value for one or more predictors</span>
<span class="sd">        # for examples, passing these new data through a trained model,</span>
<span class="sd">        # and then averaging the resulting predictions. After repeating this process</span>
<span class="sd">        # for a range of values of X*, regions of non-zero slope indicates that</span>
<span class="sd">        # where the ML model is sensitive to X* (McGovern et al. 2019). Only disadvantage is</span>
<span class="sd">        # that PDP do not account for non-linear interactions between X and the other predictors.</span>
<span class="sd">        #########################################################################</span>

<span class="sd">        Parameters</span>
<span class="sd">        --------------</span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">            </span>
<span class="sd">        features : string or 2-tuple of strings</span>
<span class="sd">            Feature name or pair of feature names to compute ICE for. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>

<span class="sd">        Returns</span>
<span class="sd">        ------------------</span>
<span class="sd">            results : dict </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Retrieve the model object from the models dict attribute</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>

        <span class="c1"># Check if features is a string</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">features</span><span class="p">]</span>

        <span class="c1"># Check if feature is valid</span>
        <span class="n">is_valid_feature</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>

        <span class="c1"># Extract the values for the features</span>
        <span class="n">full_feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>

        <span class="c1"># Create a grid of values</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">n_bins</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">full_feature_values</span>
        <span class="p">]</span>

        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
            <span class="n">prediction_method</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
            <span class="n">prediction_method</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span>

        <span class="n">pd_values</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># for each bootstrap set</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>
            <span class="c1"># get samples</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
            <span class="n">averaged_predictions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># for each value, set all indices to the value,</span>
            <span class="c1"># make prediction, store mean prediction</span>
            <span class="k">for</span> <span class="n">value_set</span> <span class="ow">in</span> <span class="n">cartesian</span><span class="p">(</span><span class="n">grid</span><span class="p">):</span>
                <span class="n">examples_temp</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
                    <span class="n">examples_temp</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">prediction_method</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

                <span class="c1"># average over samples</span>
                <span class="n">averaged_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

            <span class="n">averaged_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">averaged_predictions</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                <span class="c1"># Binary classification, shape is (2, n_points).</span>
                <span class="c1"># we output the effect of **positive** class</span>
                <span class="c1"># and convert to percentages</span>
                <span class="n">averaged_predictions</span> <span class="o">=</span> <span class="n">averaged_predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Center the predictions</span>
            <span class="n">averaged_predictions</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">averaged_predictions</span><span class="p">)</span>

            <span class="n">pd_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">averaged_predictions</span><span class="p">)</span>

        <span class="c1"># Reshape the pd_values for higher-order effects</span>
        <span class="n">pd_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pd_values</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">pd_values</span> <span class="o">=</span> <span class="n">pd_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">n_bootstrap</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">n_bins</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_store_results</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pd&quot;</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">ydata</span><span class="o">=</span><span class="n">pd_values</span><span class="p">,</span>
            <span class="n">xdata</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
            <span class="n">hist_data</span><span class="o">=</span><span class="n">feature_values</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_first_order_ale"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_first_order_ale">[docs]</a>    <span class="k">def</span> <span class="nf">compute_first_order_ale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes first-order ALE function on single continuous feature data.</span>

<span class="sd">        Script is largely the _first_order_ale_quant from</span>
<span class="sd">        https://github.com/blent-ai/ALEPython/ with small modifications.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">            </span>
<span class="sd">        features : string or 2-tuple of strings</span>
<span class="sd">            Feature name or pair of feature names to compute ICE for. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>
<span class="sd">            </span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">            results : nested dictionary</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="c1"># check to make sure feature is valid</span>
        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> is not a valid feature.&quot;</span><span class="p">)</span>

        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

        <span class="c1"># Using the original, unaltered feature values</span>
        <span class="c1"># calculate the bin edges to be used in the bootstrapping.</span>
        <span class="n">original_feature_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
            <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span>
                    <span class="n">original_feature_values</span><span class="p">,</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># Initialize an empty ale array</span>
            <span class="n">ale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_bootstrap</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use the unique values for discrete data.</span>
            <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">original_feature_values</span><span class="p">)</span>

            <span class="c1"># Initialize an empty ale array</span>
            <span class="n">ale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_bootstrap</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">)))</span>

        <span class="c1"># for each bootstrap set</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Find the ranges to calculate the local effects over</span>
            <span class="c1"># Using xdata ensures each bin gets the same number of examples</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

            <span class="c1"># if right=True, then the smallest value in data is not included in a bin.</span>
            <span class="c1"># Thus, Define the bins the feature samples fall into. Shift and clip to ensure we are</span>
            <span class="c1"># getting the index of the left bin edge and the smallest sample retains its index</span>
            <span class="c1"># of 0.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># indices for discrete data</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="c1"># Assign the feature quantile values (based on its bin index) to two copied training datasets,</span>
            <span class="c1"># one for each bin edge. Then compute the difference between the corresponding predictions</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                <span class="n">examples_temp</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">examples_temp</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">bin_edges</span><span class="p">[</span><span class="n">indices</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>

            <span class="c1"># The individual (local) effects.</span>
            <span class="n">effects</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># Group the effects by their bin index</span>
            <span class="n">index_groupby</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="n">indices</span><span class="p">,</span> <span class="s2">&quot;effects&quot;</span><span class="p">:</span> <span class="n">effects</span><span class="p">}</span>
            <span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">)</span>

            <span class="c1"># Compute the mean local effect for each bin</span>
            <span class="n">mean_effects</span> <span class="o">=</span> <span class="n">index_groupby</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="c1"># Accumulate (cumulative sum) the mean local effects.</span>
            <span class="c1"># Adding a 0 at the lower boundary of the first bin</span>
            <span class="c1"># for the interpolation step in the next step</span>
            <span class="n">ale_uninterpolated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">mean_effects</span><span class="p">)])</span>

            <span class="c1"># Interpolate the ale to the center of the bins.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">ale</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">ale_uninterpolated</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">ale_uninterpolated</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">traceback</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                                 The value of n_bins (</span><span class="si">{</span><span class="n">n_bins</span><span class="si">}</span><span class="s2">) is likely too </span>
<span class="s2">                                 high relative to the sample size of the data. Either increase</span>
<span class="s2">                                 the data size (if using subsample) or use less bins. </span>
<span class="s2">                                 &quot;&quot;&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Center the ALE by substracting the bin-size weighted mean.</span>
            <span class="n">ale</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ale</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">index_groupby</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="n">examples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_store_results</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
            <span class="n">ydata</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
            <span class="n">xdata</span><span class="o">=</span><span class="n">bin_edges</span><span class="p">,</span>
            <span class="n">hist_data</span><span class="o">=</span><span class="p">[</span><span class="n">original_feature_values</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

    <span class="k">def</span> <span class="nf">_get_centers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<div class="viewcode-block" id="GlobalInterpret.compute_second_order_ale"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_second_order_ale">[docs]</a>    <span class="k">def</span> <span class="nf">compute_second_order_ale</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes second-order ALE function on two continuous features data.</span>

<span class="sd">        Script is largely the _first_order_ale_quant from</span>
<span class="sd">        https://github.com/blent-ai/ALEPython/ with small modifications.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">            </span>
<span class="sd">        features : string or 2-tuple of strings</span>
<span class="sd">            Feature name or pair of feature names to compute ICE for. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>
<span class="sd">            </span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">            results : nested dictionary</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>

        <span class="c1"># make sure there are two features...</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Size of features must be equal to 2.&quot;</span>

        <span class="c1"># check to make sure both features are valid</span>
        <span class="k">if</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature </span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> is not a valid feature&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature </span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> is not a valid feature&quot;</span><span class="p">)</span>

        <span class="c1"># create bins for computation for both features</span>

        <span class="n">original_feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>

        <span class="n">bin_edges</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span>
                    <span class="n">v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;lower&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">original_feature_values</span>
        <span class="p">]</span>

        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

        <span class="n">feature1_nbin_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">feature2_nbin_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">ale_set</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># for each bootstrap set</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>

            <span class="n">ale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">feature1_nbin_edges</span><span class="p">,</span> <span class="n">feature2_nbin_edges</span><span class="p">)),</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">feature1_nbin_edges</span><span class="p">,</span> <span class="n">feature2_nbin_edges</span><span class="p">)),</span>
                <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># get samples</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># create bins for computation for both features</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>

            <span class="c1"># Define the bins the feature samples fall into. Shift and clip to ensure we are</span>
            <span class="c1"># getting the index of the left bin edge and the smallest sample retains its index</span>
            <span class="c1"># of 0.</span>
            <span class="n">indices_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">f</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">)</span>
            <span class="p">]</span>

            <span class="c1"># Invoke the predictor at the corners of the bins. Then compute the second order</span>
            <span class="c1"># difference between the predictions at the bin corners.</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">shifts</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">examples_temp</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                    <span class="n">examples_temp</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">bin_edges</span><span class="p">[</span><span class="n">i</span><span class="p">][</span>
                        <span class="n">indices_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">shifts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="p">]</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">shifts</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">)[</span>
                        <span class="p">:,</span> <span class="mi">1</span>
                    <span class="p">]</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">shifts</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples_temp</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

            <span class="c1"># The individual (local) effects.</span>
            <span class="n">effects</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span> <span class="o">-</span> <span class="p">(</span>
                <span class="n">predictions</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
            <span class="p">)</span>

            <span class="c1"># Group the effects by their indices along both axes.</span>
            <span class="n">index_groupby</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;index_0&quot;</span><span class="p">:</span> <span class="n">indices_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="s2">&quot;index_1&quot;</span><span class="p">:</span> <span class="n">indices_list</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="s2">&quot;effects&quot;</span><span class="p">:</span> <span class="n">effects</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;index_0&quot;</span><span class="p">,</span> <span class="s2">&quot;index_1&quot;</span><span class="p">])</span>

            <span class="c1"># Compute mean effects.</span>
            <span class="n">mean_effects</span> <span class="o">=</span> <span class="n">index_groupby</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="c1"># Get the indices of the mean values.</span>
            <span class="n">group_indices</span> <span class="o">=</span> <span class="n">mean_effects</span><span class="o">.</span><span class="n">index</span>
            <span class="n">valid_grid_indices</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">group_indices</span><span class="p">))</span>
            <span class="c1"># Extract only the data.</span>
            <span class="n">mean_effects</span> <span class="o">=</span> <span class="n">mean_effects</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="c1"># Get the number of samples in each bin.</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">index_groupby</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

            <span class="c1"># Create a 2D array of the number of samples in each bin.</span>
            <span class="n">samples_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">feature1_nbin_edges</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">feature2_nbin_edges</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">samples_grid</span><span class="p">[</span><span class="n">valid_grid_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_samples</span>

            <span class="c1"># Mark the first row/column as valid, since these are meant to contain 0s.</span>
            <span class="n">ale</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">ale</span><span class="o">.</span><span class="n">mask</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># Place the mean effects into the final array.</span>
            <span class="c1"># Since `ale` contains `len(quantiles)` rows/columns the first of which are</span>
            <span class="c1"># guaranteed to be valid (and filled with 0s), ignore the first row and column.</span>
            <span class="n">ale</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:][</span><span class="n">valid_grid_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_effects</span>

            <span class="c1"># Record where elements were missing.</span>
            <span class="n">missing_bin_mask</span> <span class="o">=</span> <span class="n">ale</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">copy</span><span class="p">()[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span>

            <span class="c1"># Replace the invalid bin values with the nearest valid ones.</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">missing_bin_mask</span><span class="p">):</span>
                <span class="c1"># Replace missing entries with their nearest neighbours.</span>

                <span class="c1"># Calculate the dense location matrices (for both features) of all bin centres.</span>
                <span class="n">centers_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
                    <span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_centers</span><span class="p">(</span><span class="n">quantiles</span><span class="p">)</span> <span class="k">for</span> <span class="n">quantiles</span> <span class="ow">in</span> <span class="n">bin_edges</span><span class="p">),</span>
                    <span class="n">indexing</span><span class="o">=</span><span class="s2">&quot;ij&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Select only those bin centres which are valid (had observation).</span>
                <span class="n">valid_indices_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">missing_bin_mask</span><span class="p">)</span>
                <span class="n">tree</span> <span class="o">=</span> <span class="n">cKDTree</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                        <span class="nb">tuple</span><span class="p">(</span>
                            <span class="n">centers</span><span class="p">[</span><span class="n">valid_indices_list</span><span class="p">][:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">centers</span> <span class="ow">in</span> <span class="n">centers_list</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="n">row_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">inds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">inds</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">missing_bin_mask</span><span class="p">)]</span>
                <span class="p">)</span>
                <span class="c1"># Select both columns for each of the rows above.</span>
                <span class="n">column_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">row_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">row_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="c1"># Determine the indices of the points which are nearest to the empty bins.</span>
                <span class="n">nearest_points</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">column_indices</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>

                <span class="n">nearest_indices</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                    <span class="n">valid_indices</span><span class="p">[</span><span class="n">nearest_points</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">valid_indices</span> <span class="ow">in</span> <span class="n">valid_indices_list</span>
                <span class="p">)</span>

                <span class="c1"># Replace the invalid bin values with the nearest valid ones.</span>
                <span class="n">ale</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:][</span><span class="n">missing_bin_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">ale</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:][</span><span class="n">nearest_indices</span><span class="p">]</span>
            
            <span class="c1"># Compute the cumulative sums.</span>
            <span class="n">ale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Subtract first order effects along both axes separately.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                <span class="c1"># Depending on `i`, reverse the arguments to operate on the opposite axis.</span>
                <span class="n">flip</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span>

                <span class="c1"># Undo the cumulative sum along the axis.</span>
                <span class="n">first_order</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">ale</span><span class="p">[(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="o">...</span><span class="p">)[</span><span class="n">flip</span><span class="p">]]</span> <span class="o">-</span> <span class="n">ale</span><span class="p">[(</span><span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">...</span><span class="p">)[</span><span class="n">flip</span><span class="p">]]</span>
                <span class="p">)</span>
                <span class="c1"># Average the diffs across the other axis.</span>
                <span class="n">first_order</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">first_order</span><span class="p">[(</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">))[</span><span class="n">flip</span><span class="p">]]</span>
                    <span class="o">+</span> <span class="n">first_order</span><span class="p">[(</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="n">flip</span><span class="p">]]</span>
                <span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
                <span class="c1"># Weight by the number of samples in each bin.</span>
                <span class="n">first_order</span> <span class="o">*=</span> <span class="n">samples_grid</span>
                <span class="c1"># Take the sum along the axis.</span>
                <span class="n">first_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">first_order</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
                <span class="c1"># Normalise by the number of samples in the bins along the axis.</span>
                <span class="n">first_order</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">samples_grid</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
                <span class="c1"># The final result is the cumulative sum (with an additional 0).</span>
                <span class="n">first_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">first_order</span><span class="p">)])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="n">flip</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="c1"># Subtract the first order effect.</span>
                <span class="n">ale</span> <span class="o">-=</span> <span class="n">first_order</span>

            <span class="c1"># Compute the ALE at the bin centres.</span>
            <span class="n">ale</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">reduce</span><span class="p">(</span>
                    <span class="n">add</span><span class="p">,</span>
                    <span class="p">(</span>
                        <span class="n">ale</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">ale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="p">:</span> <span class="n">ale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="o">/</span> <span class="mi">4</span>
            <span class="p">)</span>

            <span class="c1"># Center the ALE by subtracting its expectation value.</span>
            <span class="n">ale</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">samples_grid</span> <span class="o">*</span> <span class="n">ale</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>
            
            <span class="n">ale_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ale</span><span class="p">)</span>

        <span class="c1">###ale_set_ds = xarray.DataArray(ale_set).to_masked_array()</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_store_results</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">ydata</span><span class="o">=</span><span class="n">ale_set</span><span class="p">,</span>
            <span class="n">xdata</span><span class="o">=</span><span class="n">bin_edges</span><span class="p">,</span>
            <span class="n">hist_data</span><span class="o">=</span><span class="n">original_feature_values</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_first_order_ale_cat"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_first_order_ale_cat">[docs]</a>    <span class="k">def</span> <span class="nf">compute_first_order_ale_cat</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">feature</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">feature_encoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes first-order ALE function on a single categorical feature.</span>

<span class="sd">        Script is largely from aleplot_1D_categorical from</span>
<span class="sd">        PyALE with small modifications (https://github.com/DanaJomar/PyALE).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">            </span>
<span class="sd">        features : string or 2-tuple of strings</span>
<span class="sd">            Feature name or pair of feature names to compute ICE for. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">            results : nested dictionary</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">inspect</span> <span class="kn">import</span> <span class="n">currentframe</span><span class="p">,</span> <span class="n">getframeinfo</span>
        <span class="kn">from</span> <span class="nn">pandas.core.common</span> <span class="kn">import</span> <span class="n">SettingWithCopyError</span>

        <span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">chained_assignment</span> <span class="o">=</span> <span class="s2">&quot;raise&quot;</span>

        <span class="k">if</span> <span class="n">feature_encoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">feature_encoder_func</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">data</span>

            <span class="n">feature_encoder</span> <span class="o">=</span> <span class="n">feature_encoder_func</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="c1"># check to make sure feature is valid</span>
        <span class="k">if</span> <span class="n">feature</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2"> is not a valid feature&quot;</span><span class="p">)</span>

        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

        <span class="n">original_feature_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
        <span class="n">xdata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">original_feature_values</span><span class="p">)])</span>
        <span class="n">xdata</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

        <span class="c1"># Initialize an empty ale array</span>
        <span class="n">ale</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># for each bootstrap set</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;category&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">ordered</span>
            <span class="p">):</span>
                <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
                <span class="n">groups_order</span> <span class="o">=</span> <span class="n">order_groups</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">feature</span><span class="p">)</span>
                <span class="n">groups</span> <span class="o">=</span> <span class="n">groups_order</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span>
                <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                    <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">CategoricalDtype</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span> <span class="n">ordered</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">groups</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
            <span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>
            <span class="n">feature_codes</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span>
            <span class="n">groups_counts</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
            <span class="n">groups_props</span> <span class="o">=</span> <span class="n">groups_counts</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">groups_counts</span><span class="p">)</span>

            <span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>

            <span class="c1"># create copies of the dataframe</span>
            <span class="n">examples_plus</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">examples_neg</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="c1"># all groups except last one</span>
            <span class="n">last_group</span> <span class="o">=</span> <span class="n">groups</span><span class="p">[</span><span class="n">K</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">ind_plus</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">!=</span> <span class="n">last_group</span>
            <span class="c1"># all groups except first one</span>
            <span class="n">first_group</span> <span class="o">=</span> <span class="n">groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">ind_neg</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">!=</span> <span class="n">first_group</span>
            <span class="c1"># replace once with one level up</span>
            <span class="n">examples_plus</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">,</span> <span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">groups</span><span class="p">[</span><span class="n">feature_codes</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># replace once with one level down</span>
            <span class="n">examples_neg</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">,</span> <span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">groups</span><span class="p">[</span><span class="n">feature_codes</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># predict with original and with the replaced values</span>
                <span class="c1"># encode the categorical feature</span>
                <span class="n">examples_coded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">examples</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">feature_encoder</span><span class="p">(</span><span class="n">examples</span><span class="p">[[</span><span class="n">feature</span><span class="p">]]),</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># predict</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples_coded</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">])[</span>
                        <span class="p">:,</span> <span class="mi">1</span>
                    <span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples_coded</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">])</span>

                <span class="c1"># encode the categorical feature</span>
                <span class="n">examples_plus_coded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">examples_plus</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">feature_encoder</span><span class="p">(</span><span class="n">examples_plus</span><span class="p">[[</span><span class="n">feature</span><span class="p">]]),</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># predict</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                    <span class="n">y_hat_plus</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span>
                        <span class="n">examples_plus_coded</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span>
                    <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_hat_plus</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                        <span class="n">examples_plus_coded</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span>
                    <span class="p">)</span>

                <span class="c1"># encode the categorical feature</span>
                <span class="n">examples_neg_coded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">examples_neg</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">feature_encoder</span><span class="p">(</span><span class="n">examples_neg</span><span class="p">[[</span><span class="n">feature</span><span class="p">]]),</span>
                    <span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># predict</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                    <span class="n">y_hat_neg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span>
                        <span class="n">examples_neg_coded</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span>
                    <span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">y_hat_neg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                        <span class="n">examples_neg_coded</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">]</span>
                    <span class="p">)</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="sd">&quot;&quot;&quot;There seems to be a problem when predicting with the model.</span>
<span class="sd">                    Please check the following: </span>
<span class="sd">                    - Your model is fitted.</span>
<span class="sd">                        - The list of predictors contains the names of all the features&quot;&quot;&quot;</span>
                    <span class="sd">&quot;&quot;&quot; used for training the model.</span>
<span class="sd">                        - The encoding function takes the raw feature and returns the&quot;&quot;&quot;</span>
                    <span class="sd">&quot;&quot;&quot; right columns encoding it, including the case of a missing category.</span>
<span class="sd">                    &quot;&quot;&quot;</span>
                <span class="p">)</span>

            <span class="c1"># compute prediction difference</span>
            <span class="n">Delta_plus</span> <span class="o">=</span> <span class="n">y_hat_plus</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">]</span>
            <span class="n">Delta_neg</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_hat_neg</span>

            <span class="c1"># compute the mean of the difference per group</span>
            <span class="n">delta_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;eff&quot;</span><span class="p">:</span> <span class="n">Delta_plus</span><span class="p">,</span>
                            <span class="n">feature</span><span class="p">:</span> <span class="n">groups</span><span class="p">[</span><span class="n">feature_codes</span><span class="p">[</span><span class="n">ind_plus</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                        <span class="p">}</span>
                    <span class="p">),</span>
                    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                        <span class="p">{</span><span class="s2">&quot;eff&quot;</span><span class="p">:</span> <span class="n">Delta_neg</span><span class="p">,</span> <span class="n">feature</span><span class="p">:</span> <span class="n">groups</span><span class="p">[</span><span class="n">feature_codes</span><span class="p">[</span><span class="n">ind_neg</span><span class="p">]]}</span>
                    <span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="n">res_df</span> <span class="o">=</span> <span class="n">delta_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">feature</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">&quot;ale&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">&quot;eff&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>

            <span class="n">res_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># sort the index (which is at this point an ordered categorical) as a safety measure</span>
            <span class="n">res_df</span> <span class="o">=</span> <span class="n">res_df</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>

            <span class="c1"># Subtract the mean value to get the centered value.</span>
            <span class="n">ale_temp</span> <span class="o">=</span> <span class="n">res_df</span><span class="p">[</span><span class="s2">&quot;ale&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">res_df</span><span class="p">[</span><span class="s2">&quot;ale&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups_props</span><span class="p">)</span>
            <span class="n">ale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ale_temp</span><span class="p">)</span>

        <span class="n">ale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ale</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_store_results</span><span class="p">(</span>
            <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
            <span class="n">ydata</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
            <span class="n">xdata</span><span class="o">=</span><span class="n">xdata</span><span class="p">,</span>
            <span class="n">hist_data</span><span class="o">=</span><span class="n">original_feature_values</span><span class="p">,</span>
            <span class="n">categorical</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_scalar_interaction_stats"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_scalar_interaction_stats">[docs]</a>    <span class="k">def</span> <span class="nf">compute_scalar_interaction_stats</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">method</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">model_names</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">data_2d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wrapper function for computing the interaction strength statistic or the Friedman</span>
<span class="sd">        H-statistic (see below). Will perform calculation in parallel for multiple models.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        </span>
<span class="sd">        method : &#39;ias&#39; or &#39;hstat&#39;</span>
<span class="sd">            Whether to compute the interaction strength (ias) or the </span>
<span class="sd">            Friedman H-statistics (hstat)</span>
<span class="sd">        </span>
<span class="sd">        data : xarray.Dataset</span>
<span class="sd">        data_2d : xarray.Dataset</span>
<span class="sd">        </span>
<span class="sd">        features : string</span>
<span class="sd">      </span>
<span class="sd">        model_name : string</span>
<span class="sd">            Name of the model; used as a dict key </span>
<span class="sd">   </span>
<span class="sd">        n_bins : integer</span>
<span class="sd">            Number of bins </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total examples to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of examples to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            number of bootstrap resamples for computing confidence intervals. </span>
<span class="sd">            </span>
<span class="sd">        n_jobs : integer or float</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">            results : xarray.Dataset</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;ias&quot;</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_interaction_strength</span>
            <span class="n">args_iterator</span> <span class="o">=</span> <span class="n">to_iterator</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="p">[</span><span class="n">n_bins</span><span class="p">],</span> <span class="p">[</span><span class="n">subsample</span><span class="p">],</span> <span class="p">[</span><span class="n">n_bootstrap</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;hstat&quot;</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">friedman_h_statistic</span>
            <span class="n">args_iterator</span> <span class="o">=</span> <span class="n">to_iterator</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="p">[</span><span class="n">n_bins</span><span class="p">],</span> <span class="p">[</span><span class="n">subsample</span><span class="p">],</span> <span class="p">[</span><span class="n">n_bootstrap</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_2d</span> <span class="o">=</span> <span class="n">data_2d</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;n_jobs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">run_parallel</span><span class="p">(</span>
            <span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">,</span> <span class="n">args_iterator</span><span class="o">=</span><span class="n">args_iterator</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">nprocs_to_use</span><span class="o">=</span><span class="n">n_jobs</span>
        <span class="p">)</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="n">merge_dict</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;hstat&#39;</span><span class="p">:</span>
            <span class="n">final_results</span><span class="o">=</span><span class="p">{}</span>
            <span class="n">feature_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">__</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
                <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s1">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_hstat&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_pairs</span><span class="p">])</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">feature_names_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_pairs</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">values_sorted</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

                <span class="n">final_results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;hstat_rankings__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_perm_based_interactions&quot;</span><span class="p">],</span>
                    <span class="n">feature_names_sorted</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">final_results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;hstat_scores__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_perm_based_interactions&quot;</span><span class="p">,</span> <span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                    <span class="n">values_sorted</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">final_results</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results</span></div>
    
<div class="viewcode-block" id="GlobalInterpret.friedman_h_statistic"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.friedman_h_statistic">[docs]</a>    <span class="k">def</span> <span class="nf">friedman_h_statistic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the H-statistic for two-way interactions between two features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -------------</span>
<span class="sd">        model_name : str</span>
<span class="sd">        feature_tuple : 2-tuple of strs</span>
<span class="sd">        n_bins : int</span>
<span class="sd">        subsample : integer or float</span>
<span class="sd">        n_bootstrap : integer </span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        results : dictionary </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feature1</span><span class="p">,</span> <span class="n">feature2</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">feature1_pd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__pd&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">feature2_pd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature2</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__pd&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

        <span class="n">combined_pd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_2d</span><span class="p">[</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">feature2</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__pd&quot;</span>
        <span class="p">]</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># Calculate the H-statistics</span>
        <span class="n">pd_decomposed</span> <span class="o">=</span> <span class="n">feature1_pd</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature2_pd</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">numer</span> <span class="o">=</span> <span class="p">(</span><span class="n">combined_pd</span> <span class="o">-</span> <span class="n">pd_decomposed</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">combined_pd</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">H_squared</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">numer</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">denom</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature1</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">feature2</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_hstat&quot;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">H_squared</span><span class="p">)}</span>
        
        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_interaction_strength"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_interaction_strength">[docs]</a>    <span class="k">def</span> <span class="nf">compute_interaction_strength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the interaction strenth of a ML model (based on IAS from</span>
<span class="sd">        Quantifying Model Complexity via Functional</span>
<span class="sd">        Decomposition for Better Post-Hoc Interpretability).</span>

<span class="sd">        Parameters</span>
<span class="sd">        --------------------</span>
<span class="sd">        model_names : list of strings</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        ias : dict </span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ale_subsample</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ale_subsample&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="k">if</span> <span class="s2">&quot;Run Date&quot;</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
            <span class="n">feature_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;Run Date&quot;</span><span class="p">)</span>

        <span class="c1"># Get the interpolated ALE curves</span>
        <span class="n">ale_main_effects</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
            <span class="n">ale_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__ale&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">ale_x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s2">__bin_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
            
            <span class="n">ale_main_effects</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">interp1d</span><span class="p">(</span>
                <span class="n">ale_x</span><span class="p">,</span> <span class="n">ale_y</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;extrapolate&quot;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span>
            <span class="p">)</span>

        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

        <span class="n">ias</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_output</span> <span class="o">==</span> <span class="s2">&quot;probability&quot;</span><span class="p">:</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>

            <span class="c1"># Get the average model prediction</span>
            <span class="n">avg_prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

            <span class="c1"># Get the ALE value for each feature per example</span>
            <span class="n">main_effects</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">ale_main_effects</span><span class="p">[</span><span class="n">f</span><span class="p">](</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">examples</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="p">)</span>

            
            <span class="c1"># Sum the ALE values per example and add on the average value</span>
            <span class="n">main_effects</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">main_effects</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">avg_prediction</span>

            <span class="n">num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">main_effects</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">avg_prediction</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

            <span class="c1"># Compute the interaction strength</span>
            <span class="n">ias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">denom</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">model_name</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ias</span><span class="p">)}</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_ale_variance"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_ale_variance">[docs]</a>    <span class="k">def</span> <span class="nf">compute_ale_variance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">model_names</span><span class="p">,</span>
        <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the standard deviation of the ALE values</span>
<span class="sd">        for each feature and rank then for predictor importance.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : xarray.Dataset</span>
<span class="sd">        model_names : list of strings</span>
<span class="sd">        features : str</span>
<span class="sd">        ale_subsample : float or integer</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>

<span class="sd">        results_ds : xarray.Dataset</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
            <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">data_vars</span> <span class="k">if</span> <span class="s2">&quot;__&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="p">])</span>
            <span class="n">feature_names</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

            <span class="c1"># Compute the std over the bin axis [shape = (n_features, n_bootstrap)]</span>
            <span class="c1"># Input shape : (n_bootstrap, n_bins) </span>
            <span class="n">ale_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__ale&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_names</span>
                <span class="p">]</span>
            <span class="p">)</span>

            <span class="c1"># Average over the bootstrap indices </span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ale_std</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
            <span class="n">feature_names_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">ale_std_sorted</span> <span class="o">=</span> <span class="n">ale_std</span><span class="p">[</span><span class="n">idx</span><span class="p">,:]</span>

            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;ale_variance_rankings__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_ale_variance&quot;</span><span class="p">],</span>
                <span class="n">feature_names_sorted</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;ale_variance_scores__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_ale_variance&quot;</span><span class="p">,</span> <span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                <span class="n">ale_std_sorted</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="GlobalInterpret.compute_interaction_rankings"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_interaction_rankings">[docs]</a>    <span class="k">def</span> <span class="nf">compute_interaction_rankings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">model_names</span><span class="p">,</span>
        <span class="n">features</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the variable interaction rankings from Greenwell et al. 2018, but</span>
<span class="sd">        using the purely second-order ALE rather than the second-order PD.</span>

<span class="sd">        For a given second-order ALE,</span>
<span class="sd">         1. Compute the standard deviation over one axis and then take the std of those values</span>
<span class="sd">         2. Compute the standard deviation over another axis and then take the std of those values</span>
<span class="sd">         3. Average 1 and 2 together.</span>

<span class="sd">        Sort by magnitudes given in (3). Larger values (relative to other values) are</span>
<span class="sd">        possibly indicative of  stronger feature interactions.</span>


<span class="sd">        Parameters</span>
<span class="sd">        --------------------</span>
<span class="sd">        data : xarray.Dataset</span>
<span class="sd">        model_names : list of strings</span>
<span class="sd">        features : str</span>
<span class="sd">        ale_subsample : float or integer</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
            
            <span class="n">interaction_effects</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
                <span class="n">data_temp</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">__ale&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
                <span class="n">std_feature0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data_temp</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">std_feature1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data_temp</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">interaction_effects</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">std_feature0</span> <span class="o">+</span> <span class="n">std_feature1</span><span class="p">))</span>

            <span class="n">interaction_effects</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">interaction_effects</span><span class="p">)</span>
            <span class="c1"># Average over the bootstrap indices</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">interaction_effects</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">feature_names_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">interaction_effects_sorted</span> <span class="o">=</span> <span class="n">interaction_effects</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">feature_names_sorted</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">__</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_names_sorted</span><span class="p">]</span>

            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;ale_variance_interactions_rankings__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_ale_variance_interactions&quot;</span><span class="p">],</span>
                <span class="n">feature_names_sorted</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;ale_variance_interactions_scores__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_ale_variance_interactions&quot;</span><span class="p">,</span> <span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                <span class="n">interaction_effects_sorted</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="GlobalInterpret.number_of_features_used"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.number_of_features_used">[docs]</a>    <span class="k">def</span> <span class="nf">number_of_features_used</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the number of features (NF) from Molnar et al. 2019</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
            <span class="n">examples_temp</span> <span class="o">=</span> <span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">examples_temp</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">examples_temp</span><span class="p">[</span><span class="n">f</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

            <span class="n">new_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">examples_temp</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">change</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">new_predictions</span> <span class="o">-</span> <span class="n">original_predictions</span><span class="p">)</span></div>
   
    
<div class="viewcode-block" id="GlobalInterpret.compute_interaction_performance_based"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_interaction_performance_based">[docs]</a>    <span class="k">def</span> <span class="nf">compute_interaction_performance_based</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> 
                                           <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                           <span class="n">X_permuted</span><span class="p">,</span> 
                                           <span class="n">features</span><span class="p">,</span> 
                                           <span class="n">evaluation_fn</span><span class="p">,</span>
                                           <span class="n">model_output</span><span class="p">,</span> 
                                           <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the performance-based feature interactions from Oh (2019).</span>
<span class="sd">    </span>
<span class="sd">        Err(F_i) : Error when feature F_i is permuted as compared </span>
<span class="sd">               against the original model performance.  </span>
<span class="sd">               </span>
<span class="sd">        Err({F_i, F_j}) : Error when features F_i &amp; F_j are permuted as </span>
<span class="sd">                       compared against the original model performance. </span>
<span class="sd">    </span>
<span class="sd">        Interaction = Err(F_i) + Err(F_j) - Err({F_i, F_j}), for classification </span>
<span class="sd">        Interaction = Err({F_i, F_j}) - (Err(F_i) + Err(F_j)), for regression</span>
<span class="sd">    </span>
<span class="sd">        Interaction(F_i, F_j) = 0 -&gt; no interaction between F_i &amp; F_j </span>
<span class="sd">        Interaction(F_i, F_j) &gt; 0 -&gt; positive interaction between F_i &amp; F_j </span>
<span class="sd">        Interaction(F_i, F_j) &lt; 0 -&gt; negative interaction between F_i &amp; F_j </span>
<span class="sd">    </span>
<span class="sd">        Negative interaction implies that the connection between Fi and Fj reduces the prediction performance, </span>
<span class="sd">        whereas positive interaction leads to an increase in the prediction performance. </span>
<span class="sd">        In other words, positive or negative interactions decrease or increase the </span>
<span class="sd">        prediction error, respectively.</span>
<span class="sd">    </span>
<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        model, </span>
<span class="sd">        X : pandas.DataFrame  of shape (n_examples, n_features)</span>
<span class="sd">        Data to compute importance over. </span>
<span class="sd">        y : numpy.array</span>
<span class="sd">        Target values</span>
<span class="sd">        features: list of 2-tuples </span>
<span class="sd">        evaluation_fn : callable </span>
<span class="sd">        random_state : integer</span>
<span class="sd">    </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        err : numpy.array</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="c1">#Classification</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#Regression</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="n">original_score</span> <span class="o">=</span> <span class="n">evaluation_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        
        <span class="n">err</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">X_permuted_both</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Compute the change in model performance for the two features separately </span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
            <span class="n">X_temp</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">X_temp</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_permuted</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">feature</span><span class="p">]</span>
            <span class="n">X_permuted_both</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_permuted</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">feature</span><span class="p">]</span>

            <span class="c1"># Get the predictions for the dataset with a permuted feature. </span>
            <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
                <span class="c1">#Classification</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_temp</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#Regression</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_temp</span><span class="p">)</span>

            <span class="c1"># Compute the permuted score </span>
            <span class="n">permuted_score</span> <span class="o">=</span> <span class="n">evaluation_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
                <span class="c1">#Classification</span>
                <span class="n">err_i</span> <span class="o">=</span> <span class="n">original_score</span> <span class="o">-</span> <span class="n">permuted_score</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#Regression</span>
                <span class="n">err_i</span> <span class="o">=</span> <span class="n">permuted_score</span> <span class="o">-</span> <span class="n">original_score</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">permuted_features</span> <span class="o">=</span> <span class="n">check_is_permuted</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_temp</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Reduced performance by </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1"> : </span><span class="si">{</span><span class="n">err_i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Permuted Features: </span><span class="si">{</span><span class="n">permuted_features</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
            <span class="n">err</span><span class="o">+=</span><span class="n">err_i</span>
        
        <span class="c1"># Compute the change in model performance with both features permuted. </span>
        <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="n">predictions_both</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_permuted_both</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predictions_both</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_permuted_both</span><span class="p">)</span>
        
        <span class="c1"># Compute the permuted score </span>
        <span class="n">permuted_score_both</span> <span class="o">=</span> <span class="n">evaluation_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions_both</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="n">err_both</span> <span class="o">=</span> <span class="n">original_score</span> <span class="o">-</span> <span class="n">permuted_score_both</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">err_both</span> <span class="o">=</span> <span class="n">permuted_score_both</span> <span class="o">-</span> <span class="n">original_score</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">permuted_features</span> <span class="o">=</span> <span class="n">check_is_permuted</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_permuted_both</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Reduced performance by </span><span class="si">{</span><span class="n">features</span><span class="si">}</span><span class="s1"> : </span><span class="si">{</span><span class="n">err_both</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>    
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Permuted Features: </span><span class="si">{</span><span class="n">permuted_features</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            
        <span class="c1"># Combine for the feature interaction between the two features </span>
        <span class="k">if</span> <span class="n">model_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="n">err</span><span class="o">-=</span><span class="n">err_both</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">err_both</span> <span class="o">-</span> <span class="n">err</span>  
    
        <span class="k">return</span> <span class="n">err</span></div>
    
<div class="viewcode-block" id="GlobalInterpret.compute_interaction_rankings_performance_based"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_interaction_rankings_performance_based">[docs]</a>    <span class="k">def</span> <span class="nf">compute_interaction_rankings_performance_based</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_names</span><span class="p">,</span> 
                                           <span class="n">features</span><span class="p">,</span> 
                                           <span class="n">evaluation_fn</span><span class="p">,</span>
                                           <span class="n">model_output</span><span class="p">,</span> 
                                           <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                           <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                           <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                     
                                           <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wrapper function for performance_based_feature_interactions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">unique_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">t</span><span class="p">]))</span>
        <span class="n">n_feature_pairs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">examples_permuted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Permute all features up front to save on computation cost</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">unique_features</span><span class="p">:</span>
            <span class="n">examples_permuted</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">f</span><span class="p">])</span>
            
        <span class="n">args_iterator</span> <span class="o">=</span> <span class="n">to_iterator</span><span class="p">(</span>
                <span class="n">model_names</span><span class="p">,</span>
                <span class="n">features</span><span class="p">,</span>
                <span class="p">[</span><span class="n">examples_permuted</span><span class="p">],</span>
                <span class="p">[</span><span class="n">evaluation_fn</span><span class="p">],</span>
                <span class="p">[</span><span class="n">model_output</span><span class="p">],</span> 
                <span class="p">[</span><span class="n">subsample</span><span class="p">],</span>
                <span class="p">[</span><span class="n">n_bootstrap</span><span class="p">],</span>
                <span class="p">[</span><span class="n">verbose</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">run_parallel</span><span class="p">(</span>
                <span class="n">func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_feature_interaction_worker</span><span class="p">,</span> <span class="n">args_iterator</span><span class="o">=</span><span class="n">args_iterator</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">nprocs_to_use</span><span class="o">=</span><span class="n">n_jobs</span>
            <span class="p">)</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="n">merge_dict</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        
        <span class="n">final_results</span><span class="o">=</span><span class="p">{}</span>
        <span class="n">feature_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">__</span><span class="si">{</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s1">_interaction__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">feature_pairs</span><span class="p">])</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">feature_names_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_pairs</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">values_sorted</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

            <span class="n">final_results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;perm_based_interactions_rankings__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_perm_based_interactions&quot;</span><span class="p">],</span>
                <span class="n">feature_names_sorted</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">final_results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;perm_based_interactions_scores__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;n_vars_perm_based_interactions&quot;</span><span class="p">,</span> <span class="s2">&quot;n_bootstrap&quot;</span><span class="p">],</span>
                <span class="n">values_sorted</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">to_xarray</span><span class="p">(</span><span class="n">final_results</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results_ds</span></div>
    
    <span class="k">def</span> <span class="nf">_feature_interaction_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> 
                                    <span class="n">examples_permuted</span><span class="p">,</span> <span class="n">evaluation_fn</span><span class="p">,</span> 
                                    <span class="n">model_output</span><span class="p">,</span> 
                                    <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Internal worker function for parallel computations. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>
            
        <span class="c1"># get the bootstrap samples</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">float</span><span class="p">(</span><span class="n">subsample</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">compute_bootstrap_indices</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
            
        <span class="n">results</span><span class="o">=</span><span class="p">{}</span>
        <span class="n">err_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_bootstrap</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bootstrap_indices</span><span class="p">):</span>
            <span class="c1"># get samples</span>
            <span class="n">examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">targets</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="n">err</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_interaction_performance_based</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
                                          <span class="n">examples</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">examples_permuted</span><span class="p">,</span> 
                                          <span class="n">features</span><span class="p">,</span> 
                                          <span class="n">evaluation_fn</span><span class="p">,</span>
                                          <span class="n">model_output</span><span class="p">,</span>                        
                                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="n">err_set</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">err</span>

        <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">__</span><span class="si">{</span><span class="n">features</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">_interaction__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">err_set</span>

        <span class="k">return</span> <span class="n">results</span>       


<div class="viewcode-block" id="GlobalInterpret.compute_main_effect_complexity"><a class="viewcode-back" href="../../../index.html#pymint.main.global_interpret.GlobalInterpret.compute_main_effect_complexity">[docs]</a>    <span class="k">def</span> <span class="nf">compute_main_effect_complexity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">ale_ds</span><span class="p">,</span>  
                            <span class="n">features</span><span class="p">,</span> <span class="n">max_segments</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">approx_error</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Main Effect Complexity (MEC) from Molnar et al. (2019)</span>
<span class="sd">    </span>
<span class="sd">        Args:</span>
<span class="sd">            model_name,</span>
<span class="sd">            ale_ds,</span>
<span class="sd">            features, </span>
<span class="sd">            max_segements, default=10</span>
<span class="sd">            approx_error, default=0.05</span>
<span class="sd">    </span>
<span class="sd">        Returns:</span>
<span class="sd">            mec_avg, float</span>
<span class="sd">                Average Main Effect Complexity </span>
<span class="sd">            best_break_dict, dict</span>
<span class="sd">                For each feature, the list of &quot;optimal&quot; breakpoints</span>
<span class="sd">                Used to plot and verify the code is running correctly. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)))</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)))</span>
    
        <span class="n">best_breaks_dict</span> <span class="o">=</span> <span class="p">{}</span>
    
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="n">ale_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ale_ds</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s1">__</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">__ale&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">ale_x</span> <span class="o">=</span> <span class="n">ale_ds</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s1">__bin_values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    
            <span class="n">b_max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">ale_x</span><span class="p">)</span>
            <span class="c1"># Approximate ALE with linear model</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
            <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ale_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ale_y</span><span class="p">)</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ale_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
            <span class="n">coef</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ale_y</span><span class="p">)</span>
    
            <span class="c1"># Increase num. of segements until approximation is good enough. </span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">best_breaks</span><span class="o">=</span><span class="p">[]</span>
            <span class="k">while</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">max_segments</span> <span class="ow">and</span> <span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ale_y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">approx_error</span><span class="p">)):</span>
                <span class="c1">#print(&#39;k: &#39;, k)</span>
                <span class="c1"># Find intervals Z_k through exhaustive search along ALE curve breakpoints</span>
                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">b_max</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">b</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">best_breaks</span><span class="p">:</span>
                        <span class="n">temp_breaks</span><span class="o">=</span><span class="n">copy</span><span class="p">(</span><span class="n">best_breaks</span><span class="p">)</span>
                        <span class="n">temp_breaks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
                        <span class="n">temp_breaks</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

                        <span class="n">idxs_set</span> <span class="o">=</span> <span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">temp_breaks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> \
                               <span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">temp_breaks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">temp_breaks</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">temp_breaks</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">+</span>\
                               <span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">temp_breaks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">b_max</span><span class="p">)]</span>

                        <span class="n">model_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">LinearRegression</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idxs_set</span><span class="p">))]</span>
                        <span class="n">model_fit_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ale_x</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ale_y</span><span class="p">[</span><span class="n">idxs</span><span class="p">])</span>
                                             <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idxs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs_set</span><span class="p">)</span>
                            <span class="p">]</span>
                        <span class="n">predict_set</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="n">model_fit_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ale_x</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idxs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs_set</span><span class="p">)</span>
                        <span class="p">]</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idxs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idxs_set</span><span class="p">):</span>
                            <span class="n">g</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span> <span class="o">=</span> <span class="n">predict_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
             
                        <span class="c1">#coef = [model_fit_set[i].coef_[0] for i in range(len(idxs_set))]</span>
            
                        <span class="n">current_score</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ale_y</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">current_score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
                            <span class="n">best_score</span> <span class="o">=</span> <span class="n">current_score</span>
                            <span class="n">best_break</span> <span class="o">=</span> <span class="n">b</span> 
            
                        <span class="c1">#coef = [model_fit_set[i].coef_[0] for i in range(len(idxs_set))]</span>
                        <span class="c1"># Greedily set slopes to zero while R^2 &gt; 1 - error</span>
                        <span class="c1"># Basically, the ALE curve is approximated quite well </span>
                        <span class="c1"># by a linear model</span>
                        <span class="c1">#if r2_score(g, ale_y) &lt; (1 - approx_error): </span>
                        <span class="c1">#    coef = [model_fit_set[i].coef_[0] for i in range(len(idxs_set))]</span>
                        <span class="c1">#else:</span>
                        <span class="c1">#    coef = [0]</span>
                <span class="n">best_breaks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_break</span><span class="p">)</span>
                <span class="n">k</span><span class="o">+=</span><span class="mi">1</span>
    
            <span class="c1"># Sum of non-zero coefficients minus first intercept </span>
            <span class="n">best_breaks_dict</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_breaks</span>
            <span class="n">mec</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span> <span class="c1">#- 1</span>
            <span class="n">var</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ale_y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
        <span class="n">mec_avg</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">var</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">var</span><span class="o">*</span><span class="n">mec</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">mec_avg</span><span class="p">,</span> <span class="n">best_breaks_dict</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div>
      
      
      
      
      
      
      
        <ul>
          <li><a href="http://data.pp.audeering.com">Data</a></li>
          <li><a href="http://devops.pp.audeering.com/sphinx/">Documentation</a></li>
          <li><a href="http://devops.pp.audeering.com">Infrastructure</a></li>
          <li><a href="http://models.pp.audeering.com">Models</a></li>
          <li><a href="http://devops.pp.audeering.com/python/">Python</a></li>
          <li><a href="http://tools.pp.audeering.com">Tools</a></li>
        </ul>
      
    <p>
        
        
        
          Built with <a href="https://www.sphinx-doc.org/en/master/">Sphinx</a> on 2021/04/09 using the <a href="https://github.com/audeering/sphinx-audeering-theme/">audEERING theme</a>
        
    </p>
  </div>

  <div role="contentinfo">
    <p>
        
      &copy; 2021, Montgomery Flora; Shawn Handler
    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  



  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>