

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pymint.main.interpret_toolkit &mdash; PyMint v0.0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
  
  
  

  

  
  
    

  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/audeering.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          <a href="../../../index.html">
          
            <img src="../../../_static/images/audeering.svg" class="logo" alt="audEERING"/>
          
          
            <span> PyMint</span>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"></div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyMint</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>pymint.main.interpret_toolkit</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pymint.main.interpret_toolkit</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="c1"># Computation imports</span>
<span class="kn">from</span> <span class="nn">..common.attributes</span> <span class="kn">import</span> <span class="n">Attributes</span>
<span class="kn">from</span> <span class="nn">.local_interpret</span> <span class="kn">import</span> <span class="n">LocalInterpret</span>
<span class="kn">from</span> <span class="nn">.global_interpret</span> <span class="kn">import</span> <span class="n">GlobalInterpret</span>

<span class="c1"># Plotting imports</span>
<span class="kn">from</span> <span class="nn">..plot.plot_interpret_curves</span> <span class="kn">import</span> <span class="n">PlotInterpretCurves</span>
<span class="kn">from</span> <span class="nn">..plot.plot_permutation_importance</span> <span class="kn">import</span> <span class="n">PlotImportance</span>
<span class="kn">from</span> <span class="nn">..plot.plot_feature_contributions</span> <span class="kn">import</span> <span class="n">PlotFeatureContributions</span>
<span class="kn">from</span> <span class="nn">..plot.plot_2D</span> <span class="kn">import</span> <span class="n">PlotInterpret2D</span>

<span class="kn">from</span> <span class="nn">..common.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">to_xarray</span><span class="p">,</span>
    <span class="n">get_indices_based_on_performance</span><span class="p">,</span>
    <span class="n">retrieve_important_vars</span><span class="p">,</span>
    <span class="n">load_netcdf</span><span class="p">,</span>
    <span class="n">load_dataframe</span><span class="p">,</span>
    <span class="n">save_netcdf</span><span class="p">,</span>
    <span class="n">save_dataframe</span><span class="p">,</span>
    <span class="n">combine_top_features</span><span class="p">,</span>
    <span class="n">determine_feature_dtype</span><span class="p">,</span>
    <span class="n">is_str</span><span class="p">,</span>
    <span class="n">is_list</span><span class="p">,</span>
    <span class="n">is_dataset</span><span class="p">,</span>
    <span class="n">is_dataframe</span><span class="p">,</span>
    <span class="p">)</span>

<div class="viewcode-block" id="InterpretToolkit"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit">[docs]</a><span class="k">class</span> <span class="nc">InterpretToolkit</span><span class="p">(</span><span class="n">Attributes</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    InterpretToolkit is the primary interface of PyMint. The modules contained within compute several</span>
<span class="sd">    interpretable machine learning (IML) methods such as </span>
<span class="sd">    </span>
<span class="sd">    Feature importance: </span>
<span class="sd">        </span>
<span class="sd">        * `permutation_importance`</span>
<span class="sd">        * `ale_variance`</span>
<span class="sd">        </span>
<span class="sd">    Feature Attributions:</span>
<span class="sd">        </span>
<span class="sd">        - `ale`</span>
<span class="sd">        - `pd`</span>
<span class="sd">        - `ice`</span>
<span class="sd">        - `shap`</span>
<span class="sd">        - `local_contributions`</span>
<span class="sd">        </span>
<span class="sd">    Feature Interactions:</span>
<span class="sd">    </span>
<span class="sd">        - `interaction_strength`</span>
<span class="sd">        - `ale_variance`</span>
<span class="sd">        - `perm_based_interaction`</span>
<span class="sd">        - `friedman_h_stat`</span>
<span class="sd">        - `main_effect_complexity`</span>
<span class="sd">        - `ale`</span>
<span class="sd">        - `pd`</span>
<span class="sd">    </span>
<span class="sd">    Additionally, there are corresponding plotting modules for </span>
<span class="sd">    each IML method, which are designed to produce publication-quality graphics. </span>
<span class="sd">    </span>
<span class="sd">    .. note:: </span>
<span class="sd">        InterpretToolkit is designed to work with estimators that implement predict or predict_proba. </span>
<span class="sd">        </span>
<span class="sd">    .. caution::</span>
<span class="sd">        InterpretToolkit is only designed to work with binary classification and regression problems. </span>
<span class="sd">        In future versions of PyMint, we hope to be compatiable with multi-class classification. </span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    </span>
<span class="sd">    estimators : model object, list of model objects</span>
<span class="sd">        A fitted estimator object or list thereof implementing `predict` or </span>
<span class="sd">        `predict_proba`.</span>
<span class="sd">        Multioutput-multiclass classifiers are not supported.</span>
<span class="sd">        </span>
<span class="sd">    estimator_names : string, list</span>
<span class="sd">        Names of the estimators (for internal and plotting purposes)</span>

<span class="sd">    X : {array-like or dataframe} of shape (n_samples, n_features)</span>
<span class="sd">        Training or validation data used to compute the IML methods.</span>
<span class="sd">        If ndnumpy.array, must specify `feature_names`</span>

<span class="sd">    y : {list or numpy.array} of shape (n_samples,)</span>
<span class="sd">        The target values (class labels in classification, real numbers in</span>
<span class="sd">            regression).</span>

<span class="sd">    estimator_output : &quot;raw&quot; or &quot;probability&quot;</span>
<span class="sd">        What output of the estimator should be explained. Determined internally by</span>
<span class="sd">        InterpretToolkit. However, if using a classification model, the user</span>
<span class="sd">        can set to &quot;raw&quot; for non-probabilistic output. </span>

<span class="sd">    feature_names : array-like of shape (n_features,), dtype=str, default=None</span>
<span class="sd">        Name of each feature; `feature_names[i]` holds the name of the feature</span>
<span class="sd">        with index `i`. By default, the name of the feature corresponds to their numerical</span>
<span class="sd">        index for NumPy array and their column name for pandas dataframe. </span>
<span class="sd">        Feature names are only required if X is an ndnumpy.array, a it will be </span>
<span class="sd">        converted to a pandas.DataFrame internally. </span>
<span class="sd">    </span>
<span class="sd">    Raises</span>
<span class="sd">    ---------</span>
<span class="sd">    AssertError</span>
<span class="sd">        Number of estimator objects is not equal to the number of estimator names given!</span>
<span class="sd">    TypeError</span>
<span class="sd">        y variable must be numpy array or pandas.DataFrame.</span>
<span class="sd">    Exception</span>
<span class="sd">        Feature names must be specified if X is an numpy.array.</span>
<span class="sd">    ValueError</span>
<span class="sd">        estimator_output is not an accepted option.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimators</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">X</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])),</span> 
                 <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
                 <span class="n">estimator_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">feature_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_estimator_attribute</span><span class="p">(</span><span class="n">estimators</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_y_attribute</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_attribute</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_estimator_output</span><span class="p">(</span><span class="n">estimator_output</span><span class="p">,</span> <span class="n">estimators</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Initialize a global interpret object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span> <span class="o">=</span> <span class="n">GlobalInterpret</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
                                      <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
                                      <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                                      <span class="n">y</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
                                      <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
                                     <span class="n">checked_attributes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span><span class="p">)</span>

        <span class="c1"># Initialize a local interpret object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span> <span class="o">=</span> <span class="n">LocalInterpret</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
                            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
                            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
                            <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
                            <span class="n">checked_attributes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">checked_attributes</span>
                            <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span> <span class="o">=</span> <span class="p">{</span>
                      <span class="s1">&#39;estimator_output&#39;</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
                      <span class="s1">&#39;estimators used&#39;</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
                     <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;InterpretToolkit(estimator=</span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\</span>
<span class="s1">                                 estimator_names=</span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\</span>
<span class="s1">                                 X=</span><span class="si">%s</span><span class="s1"> length:</span><span class="si">%d</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\</span>
<span class="s1">                                 y=</span><span class="si">%s</span><span class="s1"> length:</span><span class="si">%d</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\</span>
<span class="s1">                                 estimator_output=</span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\</span>
<span class="s1">                                 feature_names=</span><span class="si">%s</span><span class="s1"> length </span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> \
                                 <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">,</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span>
                                 <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                                 <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span>
                                 <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_append_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ds</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        FOR INTERNAL PURPOSES ONLY.</span>
<span class="sd">        </span>
<span class="sd">        Append attributes to a xarray.Dataset or pandas.DataFrame</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        ds : xarray.Dataset or pandas.DataFrame</span>
<span class="sd">            Results data from the IML methods </span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">ds</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            
        <span class="k">return</span> <span class="n">ds</span>
    
<div class="viewcode-block" id="InterpretToolkit.permutation_importance"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.permutation_importance">[docs]</a>    <span class="k">def</span> <span class="nf">permutation_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">,</span> <span class="n">evaluation_fn</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s1">&#39;backward&#39;</span><span class="p">,</span>
            <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scoring_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs single-pass and/or multi-pass permutation importance using a modified version of the</span>
<span class="sd">        PermutationImportance package (pymint.PermutationImportance) [1]_. The single-pass approach was first </span>
<span class="sd">        developed in Brieman (2001) [2]_ and then improved upon in Lakshmanan et al. (2015) [3]_. </span>
<span class="sd">         </span>
<span class="sd">        .. attention :: </span>
<span class="sd">                The permutation importance rankings can be sensitive to the evaluation function used. </span>
<span class="sd">                Consider re-computing with multiple evaluation functions. </span>
<span class="sd">                </span>
<span class="sd">        .. attention :: </span>
<span class="sd">                The permutation importance rankings can be sensitive to the direction used. </span>
<span class="sd">                Consider re-computing with both forward- and backward-based methods.         </span>
<span class="sd">        </span>
<span class="sd">        .. hint :: </span>
<span class="sd">            Since the permutation importance is a marginal-based method, you can often use </span>
<span class="sd">            subsample &lt;&lt; 1.0 without substantially altering the feature rankings. </span>
<span class="sd">            Using a subsample &lt;&lt; 1.0 can reduce the computation time for larger datasets (e.g., &gt;100 K X), </span>
<span class="sd">            especially since 100-1000s of bootstrap iterations are often required for reliable rankings. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        n_vars : integer</span>
<span class="sd">            number of variables to calculate the multipass permutation importance for. If ``n_vars=1``, then </span>
<span class="sd">            only the single-pass permutation importance is computed. If ``n_vars&gt;1``, both the single-pass </span>
<span class="sd">            and multiple-pass are computed. </span>
<span class="sd">        </span>
<span class="sd">        evaluation_fn : string or callable </span>
<span class="sd">            evaluation/scoring function for evaluating the loss of skill once a feature is permuted. </span>
<span class="sd">            evaluation_fn can be set to one of the following strings:</span>
<span class="sd">            </span>
<span class="sd">                - ``&quot;auc&quot;``, Area under the Curve</span>
<span class="sd">                - ``&quot;auprc&quot;``, Area under the Precision-Recall Curve</span>
<span class="sd">                - ``&quot;bss&quot;``, Brier Skill Score</span>
<span class="sd">                - ``&quot;mse&quot;``, Mean Square Error</span>
<span class="sd">                - ``&quot;norm_aupdc&quot;``,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</span>
<span class="sd">                </span>
<span class="sd">            Otherwise, evaluation_fn can be any function of form, </span>
<span class="sd">            `evaluation_fn(targets, predictions)` and must return a scalar value</span>
<span class="sd">            </span>
<span class="sd">            When using a custom function, you must also set the scoring strategy (see below).</span>
<span class="sd">        </span>
<span class="sd">        scoring_strategy : string (default=None)</span>
<span class="sd">        </span>
<span class="sd">            This argument is only required if you are using a non-default evaluation_fn (see above)</span>
<span class="sd">        </span>
<span class="sd">            If the evaluation_fn is positively-oriented (a higher value is better), </span>
<span class="sd">            then set ``scoring_strategy = &quot;argmin_of_mean&quot;`` and if it is negatively-oriented-</span>
<span class="sd">            (a lower value is better), then set ``scoring_strategy = &quot;argmax_of_mean&quot;``</span>
<span class="sd">            </span>
<span class="sd">        direction : ``&quot;forward&quot;`` or ``&quot;backward&quot;``</span>
<span class="sd">        </span>
<span class="sd">            For the multi-pass method. For ``&quot;backward&quot;``, the top feature is left permuted before determining</span>
<span class="sd">            the second-most important feature (and so on). For ``&quot;forward&quot;``, all features are permuted</span>
<span class="sd">            and then the top features are progressively left unpermuted. For real-world datasets, the two</span>
<span class="sd">            methods often do not produce the same feature rankings and is worth exploring both. </span>
<span class="sd">      </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            if value is between 0-1, it is interpreted as fraction of total X to use </span>
<span class="sd">            if value &gt; 1, interpreted as the number of X to randomly sample </span>
<span class="sd">            from the original dataset.</span>
<span class="sd">        </span>
<span class="sd">        n_jobs : interger or float (default=1; no multiprocessing)</span>
<span class="sd">        </span>
<span class="sd">            if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            Number of bootstrap iterations for computing confidence intervals on the feature rankings. </span>
<span class="sd">            </span>
<span class="sd">        random_state : int, RandomState instance, default=None</span>
<span class="sd">        </span>
<span class="sd">            Pseudo-random number generator to control the permutations of each</span>
<span class="sd">            feature. Pass an int to get reproducible results across function calls.</span>
<span class="sd">        </span>
<span class="sd">        verbose : boolean</span>
<span class="sd">            True for print statements on the progress</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        results : xarray.DataSet </span>
<span class="sd">            Permutation importance results. Includes the both multi-pass and single-pass </span>
<span class="sd">            feature rankings and the scores with the various features permuted. </span>
<span class="sd">        </span>
<span class="sd">        References </span>
<span class="sd">        -----------</span>
<span class="sd">        .. [1] https://github.com/gelijergensen/PermutationImportance</span>
<span class="sd">        </span>
<span class="sd">        .. [2] L. Breiman, &quot;Random Forests&quot;, Machine Learning, 45(1), 5-32, 2001.</span>
<span class="sd">        </span>
<span class="sd">        .. [3] Lakshmanan, V., C. Karstens, J. Krause, K. Elmore, A. Ryzhkov, and S. Berkseth, 2015: </span>
<span class="sd">               Which Polarimetric Variables Are Important for Weather/No-Weather Discrimination? </span>
<span class="sd">               Journal of Atmospheric and Oceanic Technology, 32, 1209â€“1223, </span>
<span class="sd">               https://doi.org/10.1175/jtech-d-13-00205.1.</span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ----------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; # Only compute for the first model</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs[0],</span>
<span class="sd">        ...                            estimator_names=estimator_names[0],</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.permutation_importance( </span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20, </span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; print(perm_imp_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">            Dimensions:           (n_bootstrap: 20, n_vars_multipass: 10, n_vars_singlepass: 30)</span>
<span class="sd">            Dimensions without coordinates: n_bootstrap, n_vars_multipass, n_vars_singlepass</span>
<span class="sd">            Data variables:</span>
<span class="sd">                multipass_rankings__Random Forest   (n_vars_multipass) &lt;U17 &#39;sfc_te...</span>
<span class="sd">                multipass_scores__Random Forest     (n_vars_multipass, n_bootstrap) float64 ...</span>
<span class="sd">                singlepass_rankings__Random Forest  (n_vars_singlepass) &lt;U17 &#39;sfc_t...</span>
<span class="sd">                singlepass_scores__Random Forest    (n_vars_singlepass, n_bootstrap) float64 ...</span>
<span class="sd">                original_score__Random Forest       (n_bootstrap) float64 0.9851 .....</span>
<span class="sd">            Attributes:</span>
<span class="sd">                estimator_output:  probability</span>
<span class="sd">                estimators used:   [&#39;Random Forest&#39;]</span>
<span class="sd">                n_multipass_vars:  10</span>
<span class="sd">                method:            permutation_importance</span>
<span class="sd">                direction:         backward</span>
<span class="sd">                evaluation_fn:     norm_aupdc</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">calc_permutation_importance</span><span class="p">(</span><span class="n">n_vars</span><span class="o">=</span><span class="n">n_vars</span><span class="p">,</span>
                                                    <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
                                                    <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                                                    <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                                                    <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
                                                    <span class="n">scoring_strategy</span><span class="o">=</span><span class="n">scoring_strategy</span><span class="p">,</span>
                                                    <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                                                    <span class="n">direction</span><span class="o">=</span><span class="n">direction</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
                                                   <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;n_multipass_vars&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_vars</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;permutation_importance&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;direction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">direction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;evaluation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_fn</span>
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="InterpretToolkit.ale_variance"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.ale_variance">[docs]</a>    <span class="k">def</span> <span class="nf">ale_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                     <span class="n">ale</span><span class="p">,</span>
                     <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                          <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">interaction</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                         <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the standard deviation (std) of the ALE values for each </span>
<span class="sd">        features in a dataset and then rank by the magnitude. A higher std(ALE) indicates a </span>
<span class="sd">        greater expected contribution to an estimator&#39;s prediction and is thus considered more important. </span>
<span class="sd">        If ``interaction=True``, then the method computes a similar method for the </span>
<span class="sd">        2D ALE to measure the feature interaction strength. </span>
<span class="sd">        </span>
<span class="sd">        This method is inspired by the feature importance and interaction </span>
<span class="sd">        methods developed in Greenwell et al. (2018) [4]_.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        ale : xarray.Dataset</span>
<span class="sd">            </span>
<span class="sd">            Results of :func:`~InterpretToolkit.ale` for</span>
<span class="sd">            ``features``.</span>
<span class="sd">            </span>
<span class="sd">        features : &#39;all&#39;, string, list of strings, list of 2-tuples</span>
<span class="sd">            </span>
<span class="sd">            Features to compute the ALE variance for. If set to ``&#39;all&#39;``, it is </span>
<span class="sd">            computed for all features. If ``interaction=True``, then features</span>
<span class="sd">            must be a list of 2-tuples for computing the interaction between</span>
<span class="sd">            the set of feature combinations. </span>
<span class="sd">            </span>
<span class="sd">        estimator_names : string, list of strings</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute the ALE variance for. </span>
<span class="sd">        </span>
<span class="sd">        interaction : boolean </span>
<span class="sd">        </span>
<span class="sd">            - If True, it computes the feature interaction strength</span>
<span class="sd">            - If False, compute the feature importance </span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            ALE variance results. Includes both the rankings and scores. </span>
<span class="sd">        </span>
<span class="sd">        References</span>
<span class="sd">        -------------</span>
<span class="sd">        </span>
<span class="sd">        .. [4] Greenwell, B. M., B. C. Boehmke, and A. J. McCarthy, 2018: </span>
<span class="sd">               A Simple and Effective estimator-Based Variable Importance Measure. Arxiv,.</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        -----------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; import itertools</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;, n_bins=10, subsample=1000, n_bootstrap=1)</span>
<span class="sd">        &gt;&gt;&gt; # Compute 1D ALE variance</span>
<span class="sd">        &gt;&gt;&gt; ale_var_results = explainer.ale_variance(ale)</span>
<span class="sd">        &gt;&gt;&gt; print(ale_var_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">        Dimensions:    (n_bootstrap: 1, n_vars_ale_variance: 30)</span>
<span class="sd">        Dimensions without coordinates: n_bootstrap, n_vars_ale_variance</span>
<span class="sd">        Data variables:</span>
<span class="sd">            ale_variance_rankings__Random Forest        (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="sd">            ale_variance_scores__Random Forest          (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_rankings__Gradient Boosting    (n_vars_ale_variance) &lt;U17 &#39;u...</span>
<span class="sd">            ale_variance_scores__Gradient Boosting      (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_rankings__Logistic Regression  (n_vars_ale_variance) &lt;U17 &#39;r...</span>
<span class="sd">            ale_variance_scores__Logistic Regression    (n_vars_ale_variance, n_bootstrap) float64 ...</span>
<span class="sd">        Attribute:</span>
<span class="sd">            estimator_output:  probability</span>
<span class="sd">            estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="sd">            n_multipass_vars:  5</span>
<span class="sd">            method:            ale_variance</span>
<span class="sd">            direction:         backward</span>
<span class="sd">            evaluation_fn:     sigma_ale</span>
<span class="sd">            dimension:         1D</span>
<span class="sd">            features used:     [&#39;dllwave_flux&#39;, &#39;dwpt2m&#39;, &#39;fric_vel&#39;, &#39;gflux&#39;, &#39;high_...</span>
<span class="sd">            estimator output:  probability</span>
<span class="sd">            interaction:       False</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; #Typical, we only want to evaluate the feature interactions for</span>
<span class="sd">        &gt;&gt;&gt; # the most important features</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,</span>
<span class="sd">        ...   &#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; # Create all possible combinations</span>
<span class="sd">        &gt;&gt;&gt; important_vars_2d = list(itertools.combinations(important_vars, r=2))</span>
<span class="sd">        &gt;&gt;&gt; #For the 2D ALE variance to measure feature interaction strength</span>
<span class="sd">        &gt;&gt;&gt; ale_2d = explainer.ale(features=important_vars_2d, n_bins=10, </span>
<span class="sd">        ...              subsample=1000, n_bootstrap=1)</span>
<span class="sd">        &gt;&gt;&gt; # Compute 2D ALE variance </span>
<span class="sd">        &gt;&gt;&gt; ale_var_results = explainer.ale_variance(ale_2d, features=important_vars_2d, </span>
<span class="sd">        ...                    interaction=True)</span>
<span class="sd">        &gt;&gt;&gt; print(ale_var_results)</span>
<span class="sd">        &lt;xarray.Dataset&gt;</span>
<span class="sd">        Dimensions:   (n_bootstrap: 1, n_vars_ale_variance_interactions: 10)</span>
<span class="sd">        Dimensions without coordinates: n_bootstrap, n_vars_ale_variance_interactions</span>
<span class="sd">        Data variables:</span>
<span class="sd">            ale_variance_interactions_rankings__Random Forest        (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Random Forest          (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_interactions_rankings__Gradient Boosting    (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Gradient Boosting      (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">            ale_variance_interactions_rankings__Logistic Regression  (n_vars_ale_variance_interactions) &lt;U35 ...</span>
<span class="sd">            ale_variance_interactions_scores__Logistic Regression    (n_vars_ale_variance_interactions, n_bootstrap) float64 ...</span>
<span class="sd">        Attribute:</span>
<span class="sd">            estimator_output:  probability</span>
<span class="sd">            estimators used:   [&#39;Random Forest&#39;, &#39;Gradient Boosting&#39;, &#39;Logistic Regre...</span>
<span class="sd">            n_multipass_vars:  5</span>
<span class="sd">            method:            ale_variance</span>
<span class="sd">            direction:         backward</span>
<span class="sd">            evaluation_fn:     Interaction Importance</span>
<span class="sd">            dimension:         2D</span>
<span class="sd">            features used:     [(&#39;sfc_temp&#39;, &#39;temp2m&#39;), (&#39;sfc_temp&#39;, &#39;sfcT_hrs_bl_fre...</span>
<span class="sd">            estimator output:  probability</span>
<span class="sd">            interaction:       True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span> <span class="ow">or</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;dimension&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;2D&#39;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">Expection</span><span class="p">(</span><span class="s2">&quot;ale must be compute for second-order ALE if interaction == True&quot;</span><span class="p">)</span>
                    
        <span class="c1"># Check that ale_data is an xarray.Dataset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">xr</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                                 ale must be an xarray.Dataset, </span>
<span class="s2">                                 perferably generated by InterpretToolkit.ale </span>
<span class="s2">                                 to be formatted correctly</span>
<span class="s2">                                 &quot;&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">any_missing</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">m</span> <span class="ow">in</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">])</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">any_missing</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ale does not contain values for all the estimator names given!&#39;</span><span class="p">)</span>
                
        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_interaction_rankings</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_ale_variance</span>
        
        <span class="n">results_ds</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,)</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ale_variance&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;estimator output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;probability&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;interaction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">interaction</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">interaction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;evaluation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Interaction Importance&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;evaluation_fn&#39;</span><span class="p">]</span> <span class="o">=</span>  <span class="s1">&#39;sigma_ale&#39;</span> <span class="c1">#&#39;$\sigma$(ALE)&#39;</span>
        
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results_ds</span></div>

    
<div class="viewcode-block" id="InterpretToolkit.main_effect_complexity"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.main_effect_complexity">[docs]</a>    <span class="k">def</span> <span class="nf">main_effect_complexity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                    <span class="n">max_segments</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">approx_error</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Main Effect Complexity (MEC; Molnar et al. 2019) [5]_. </span>
<span class="sd">        MEC is the number of linear segements required to approximate </span>
<span class="sd">        the first-order ALE curves averaged over all features. </span>
<span class="sd">        The MEC is weighted-averged by the variance. Higher values indicate</span>
<span class="sd">        a more complex estimator (less interpretable). </span>
<span class="sd">        </span>
<span class="sd">        References </span>
<span class="sd">        -----------</span>
<span class="sd">        .. [5] Molnar, C., G. Casalicchio, and B. Bischl, 2019: Quantifying estimator Complexity via </span>
<span class="sd">            Functional Decomposition for Better Post-Hoc Interpretability. ArXiv.</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------------</span>
<span class="sd">        </span>
<span class="sd">        ale : xarray.Dataset</span>
<span class="sd">            </span>
<span class="sd">             Results of :func:`~InterpretToolkit.ale`. Must be computed for all features in X. </span>

<span class="sd">        estimator_names : string, list of strings</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute the MEC for. </span>
<span class="sd">            </span>
<span class="sd">        max_segments : integer; default=10</span>
<span class="sd">            </span>
<span class="sd">            Maximum number of linear segments used to approximate the main/first-order </span>
<span class="sd">            effect of a feature. default is 10. Used to limit the computational runtime. </span>
<span class="sd">            </span>
<span class="sd">        approx_error : float; default=0.05</span>
<span class="sd">        </span>
<span class="sd">            The accepted error of the R squared between the piece-wise linear function </span>
<span class="sd">            and the true ALE curve. If the R square is within the approx_error, then </span>
<span class="sd">            no additional segments are added.</span>
<span class="sd">            </span>
<span class="sd">         </span>
<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">            mec_dict : dictionary </span>
<span class="sd">                mec_dict = {estimator_name0 : mec0, estimator_name1 : mec2, ..., estimator_nameN : mecN,}</span>
<span class="sd">                </span>
<span class="sd">                </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;, n_bins=20, subsample=0.5, n_bootstrap=20)</span>
<span class="sd">        &gt;&gt;&gt; # Compute Main Effect Complexity (MEC)</span>
<span class="sd">        &gt;&gt;&gt; mec_ds = explainer.main_effect_complexity(ale)</span>
<span class="sd">        &gt;&gt;&gt; print(mes_ds)</span>
<span class="sd">        {&#39;Random Forest&#39;: 2.6792782503392756,</span>
<span class="sd">         &#39;Gradient Boosting&#39;: 2.692392706080586,</span>
<span class="sd">         &#39;Logistic Regression&#39;: 1.6338281469152958}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span><span class="o">=</span><span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
        
        <span class="n">mec_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">estimator_name</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">:</span>
            <span class="n">mec</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_main_effect_complexity</span><span class="p">(</span> 
                        <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span> 
                        <span class="n">ale_ds</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>  
                        <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> 
                        <span class="n">max_segments</span><span class="o">=</span><span class="n">max_segments</span><span class="p">,</span> 
                        <span class="n">approx_error</span><span class="o">=</span><span class="n">approx_error</span>
            <span class="p">)</span>
            
            <span class="n">mec_dict</span><span class="p">[</span><span class="n">estimator_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">mec</span>
        
        <span class="k">return</span> <span class="n">mec_dict</span></div>
    
<div class="viewcode-block" id="InterpretToolkit.perm_based_interaction"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.perm_based_interaction">[docs]</a>    <span class="k">def</span> <span class="nf">perm_based_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">evaluation_fn</span><span class="p">,</span>
                                  <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> 
                                  <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the performance-based feature interactions from Oh (2019) [6]_. </span>
<span class="sd">        For a pair of features, the loss of skill is recorded for permuting</span>
<span class="sd">        each feature separately and permuting both. If there is no feature interaction</span>
<span class="sd">        and the covariance between the two features is close to zero, the sum of the</span>
<span class="sd">        individual losses will approximately equal the loss of skill from permuting</span>
<span class="sd">        both features. Otherwise, a non-zero difference indicates some interaction.</span>
<span class="sd">        The differences for different pairs of features can be used to rank the</span>
<span class="sd">        strength of any feature interactions. </span>
<span class="sd">        </span>
<span class="sd">        References</span>
<span class="sd">        -------------</span>
<span class="sd">        .. [6]  Oh, Sejong, 2019. Feature Interaction in Terms of Prediction Performance </span>
<span class="sd">            https://www.mdpi.com/2076-3417/9/23/5191</span>
<span class="sd">            </span>
<span class="sd">            </span>
<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        features : list of 2-tuple of strings </span>
<span class="sd">            Pairs of features to compute the interaction strength for. </span>
<span class="sd">        </span>
<span class="sd">        evaluation_fn : string or callable </span>
<span class="sd">            evaluation/scoring function for evaluating the loss of skill once a feature is permuted. </span>
<span class="sd">            evaluation_fn can be set to one of the following strings:</span>
<span class="sd">            </span>
<span class="sd">                - ``&quot;auc&quot;``, Area under the Curve</span>
<span class="sd">                - ``&quot;auprc&quot;``, Area under the Precision-Recall Curve</span>
<span class="sd">                - ``&quot;bss&quot;``, Brier Skill Score</span>
<span class="sd">                - ``&quot;mse&quot;``, Mean Square Error</span>
<span class="sd">                - ``&quot;norm_aupdc&quot;``,  Normalized Area under the Performance Diagram (Precision-Recall) Curve</span>
<span class="sd">                </span>
<span class="sd">            Otherwise, evaluation_fn can be any function of form, </span>
<span class="sd">            `evaluation_fn(targets, predictions)` and must return a scalar value</span>
<span class="sd">        </span>
<span class="sd">        estimator_names : string, list of strings</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute for. </span>
<span class="sd">            </span>
<span class="sd">        subsample: float or integer (default=1.0 for no subsampling)</span>
<span class="sd">        </span>
<span class="sd">            - if value is between 0-1, it is interpreted as fraction of total X to use </span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>
<span class="sd">        </span>
<span class="sd">        n_jobs : interger or float (default=1; no multiprocessing)</span>
<span class="sd">        </span>
<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float between 0-1, interpreted as the fraction of proceesors to use for multiprocessing</span>
<span class="sd">        </span>
<span class="sd">        n_bootstrap: integer (default=None for no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the feature pair rankings. </span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            Permutation importance-based feature interaction strength results</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,</span>
<span class="sd">        ...      &#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; important_vars_2d = list(itertools.combinations(important_vars, r=2))</span>
<span class="sd">        &gt;&gt;&gt; perm_based_interact_ds = explainer.perm_based_interaction(</span>
<span class="sd">        ...                          important_vars_2d, evaluation_fn=&#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                         )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span><span class="o">=</span><span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
                
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_interaction_rankings_performance_based</span><span class="p">(</span>
            <span class="n">estimator_names</span><span class="p">,</span> 
            <span class="n">features</span><span class="p">,</span> 
            <span class="n">evaluation_fn</span><span class="o">=</span><span class="n">evaluation_fn</span><span class="p">,</span>
            <span class="n">estimator_output</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">,</span> 
            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;perm_based&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;estimator output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;evaluation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Interaction Importance&#39;</span> 
                        
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results_ds</span></div>
    
    
<div class="viewcode-block" id="InterpretToolkit.ice"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.ice">[docs]</a>    <span class="k">def</span> <span class="nf">ice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the indiviudal conditional expectations (ICE) [7]_.</span>

<span class="sd">        References</span>
<span class="sd">        ------------</span>
<span class="sd">        .. [7] https://christophm.github.io/interpretable-ml-book/ice.html</span>
<span class="sd">    </span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the ICE for.  if &#39;all&#39;, the method will compute </span>
<span class="sd">            the ICE for all features. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the ICE for. Bins are decided based </span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in </span>
<span class="sd">            each bin. </span>
<span class="sd">            </span>
<span class="sd">        n_jobs : float or integer (default=1)</span>
<span class="sd">            </span>
<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>
<span class="sd">            </span>
<span class="sd">        subsample : float or integer (default=1.0)</span>
<span class="sd">            </span>
<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use </span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>
<span class="sd">                </span>
<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the ICE curves.</span>
<span class="sd">                </span>
<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Main keys are the user-provided estimator names while the sub-key </span>
<span class="sd">            are the features computed for. The items are data for the ICE curves. Also, </span>
<span class="sd">            contains X data (feature values where the ICE curves were computed) for plotting. </span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ice_ds = explainer.ice(features=&#39;all&#39;, subsample=200)    </span>
<span class="sd">  </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
                
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;ice&quot;</span><span class="p">,</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">)</span>
        
        <span class="n">dimension</span> <span class="o">=</span> <span class="s1">&#39;2D&#39;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;1D&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ice&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;dimension&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;features used&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span> 
        
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
      
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_used</span><span class="o">=</span><span class="n">features</span>

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="InterpretToolkit.pd"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.pd">[docs]</a>    <span class="k">def</span> <span class="nf">pd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the 1D or 2D centered partial dependence (PD) [8]_.</span>
<span class="sd">        </span>
<span class="sd">        References</span>
<span class="sd">        ------------</span>
<span class="sd">        </span>
<span class="sd">        .. [8] https://christophm.github.io/interpretable-ml-book/pdp.html</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the PD for.  if &#39;all&#39;, the method will compute </span>
<span class="sd">            the PD for all features. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the PD for. Bins are decided based </span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in </span>
<span class="sd">            each bin. </span>
<span class="sd">            </span>
<span class="sd">        n_jobs : float or integer (default=1)</span>
<span class="sd">            </span>
<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>
<span class="sd">            </span>
<span class="sd">        subsample : float or integer (default=1.0)</span>
<span class="sd">            </span>
<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use </span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>
<span class="sd">                </span>
<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the PD curves.</span>
<span class="sd">                </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            Partial dependence result dataset </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd = explainer.pd(features=&#39;all&#39;)    </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all_2d&#39;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
         
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;pd&quot;</span><span class="p">,</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">)</span>
        
        <span class="n">dimension</span> <span class="o">=</span> <span class="s1">&#39;2D&#39;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;1D&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;pd&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;dimension&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;features used&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span> 
        
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span> <span class="o">=</span> <span class="n">features</span> 
        
        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="InterpretToolkit.ale"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.ale">[docs]</a>    <span class="k">def</span> <span class="nf">ale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the 1D or 2D centered accumulated local effects (ALE) [9]_ [10]_ If any features are categorical, </span>
<span class="sd">        then set the type of those features as &#39;category&#39; in the pandas.DataFrame. E.g.,</span>
<span class="sd">        X = X.astype({&#39;urban&#39;: &#39;category&#39;, &#39;rural&#39;:&#39;category&#39;})</span>
<span class="sd">        </span>
<span class="sd">        References</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        .. [9] https://christophm.github.io/interpretable-ml-book/ale.html</span>
<span class="sd">        .. [10] Apley, D. W., and J. Zhu, 2016: Visualizing the Effects of Predictor Variables in </span>
<span class="sd">        Black Box Supervised Learning Models. ArXiv. </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        features : string or list of strings or &#39;all&#39;</span>
<span class="sd">            Features to compute the PD for.  if &#39;all&#39;, the method will compute </span>
<span class="sd">            the ALE for all features. </span>
<span class="sd">            </span>
<span class="sd">        n_bins : integer (default=30)</span>
<span class="sd">            Number of bins used to compute the ALE for. Bins are decided based </span>
<span class="sd">            on percentile intervals to ensure the same number of samples are in </span>
<span class="sd">            each bin. </span>
<span class="sd">            </span>
<span class="sd">        n_jobs : float or integer (default=1)</span>
<span class="sd">            </span>
<span class="sd">            - if integer, interpreted as the number of processors to use for multiprocessing</span>
<span class="sd">            - if float, interpreted as the fraction of proceesors to use for multiprocessing</span>
<span class="sd">            </span>
<span class="sd">        subsample : float or integer (default=1.0)</span>
<span class="sd">            </span>
<span class="sd">            - if value between 0-1 interpreted as fraction of total X to use </span>
<span class="sd">            - if value &gt; 1, interpreted as the absolute number of random samples of X.</span>
<span class="sd">                </span>
<span class="sd">        n_bootstrap : integer (default=1; no bootstrapping)</span>
<span class="sd">            Number of bootstrap resamples for computing confidence intervals on the ALE curves.</span>
<span class="sd">                </span>
<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        results : xarray.DataSet</span>
<span class="sd">            ALE result dataset</span>

<span class="sd">        Raise</span>
<span class="sd">        ----------</span>
<span class="sd">        Exception</span>
<span class="sd">            Highly skewed data may not be divisable into n_bins given. In that case, calc_ale</span>
<span class="sd">            uses the max bins the data can be divided into. But a warning message is raised.</span>
<span class="sd">               </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; # Set the type for categorical features and InterpretToolkit with compute the </span>
<span class="sd">        &gt;&gt;&gt; # categorical ALE. </span>
<span class="sd">        &gt;&gt;&gt; X = X.astype({&#39;urban&#39;: &#39;category&#39;, &#39;rural&#39;:&#39;category&#39;})</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;) </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
            <span class="k">if</span> <span class="n">features</span> <span class="o">==</span> <span class="s1">&#39;all_2d&#39;</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">_run_interpret_curves</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;ale&quot;</span><span class="p">,</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>                            
                            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
                            <span class="n">subsample</span><span class="o">=</span><span class="n">subsample</span><span class="p">,</span>
                            <span class="n">n_bootstrap</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">)</span>
        
        <span class="n">dimension</span> <span class="o">=</span> <span class="s1">&#39;2D&#39;</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span> <span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;1D&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ale&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;dimension&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;features used&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">features</span> 

        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span> <span class="o">=</span> <span class="n">features</span> 

        <span class="k">return</span> <span class="n">results_ds</span></div>

<div class="viewcode-block" id="InterpretToolkit.friedman_h_stat"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.friedman_h_stat">[docs]</a>    <span class="k">def</span> <span class="nf">friedman_h_stat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pd_1d</span><span class="p">,</span> <span class="n">pd_2d</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the second-order Friedman&#39;s H-statistic for computing feature interactions [11]_ [12]_. </span>
<span class="sd">        Based on equation (44) from Friedman and Popescu (2008) [12]_. Only computes the interaction strength </span>
<span class="sd">        between two features. In future versions of PyMint he hope to include the first-order H-statistics</span>
<span class="sd">        that measure the interaction between a single feature and the </span>
<span class="sd">        remaining set of features.</span>
<span class="sd">        </span>
<span class="sd">        References</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        .. [11] https://christophm.github.io/interpretable-ml-book/interaction.html </span>
<span class="sd">        .. [12] Friedman, J. H., and B. E. Popescu, 2008: Predictive learning via rule ensembles. </span>
<span class="sd">                Ann Appl Statistics, 2, 916â€“954, https://doi.org/10.1214/07-aoas148.</span>
<span class="sd">       </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        pd_1d : xarray.Dataset</span>
<span class="sd">            1D partial dependence dataset. Results of :func:`~InterpretToolkit.pd` for ``features``</span>
<span class="sd">            </span>
<span class="sd">        pd_2d : xarray.Dataset</span>
<span class="sd">            2D partial dependence dataset. Results of :func:`~InterpretToolkit.pd`, but 2-tuple combinations </span>
<span class="sd">            of ``features``. </span>
<span class="sd">       </span>
<span class="sd">        features : list of 2-tuples of strings</span>
<span class="sd">            The pairs of features to compute the feature interaction between.</span>
<span class="sd">        </span>
<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute the H-statistic for. </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        results_ds : xarray.Dataset</span>
<span class="sd">            The second-order Friedman H-statistic for all estimators.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models()</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd_1d = explainer.pd(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; pd_2d = explainer.pd(features=&#39;all_2d&#39;)</span>
<span class="sd">        &gt;&gt;&gt; hstat = explainer.friedman_h_stat(pd_1d, pd_2d,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
   
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_scalar_interaction_stats</span><span class="p">(</span>
                                                    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;hstat&#39;</span><span class="p">,</span>
                                                    <span class="n">data</span><span class="o">=</span><span class="n">pd_1d</span><span class="p">,</span>
                                                    <span class="n">data_2d</span> <span class="o">=</span> <span class="n">pd_2d</span><span class="p">,</span>
                                                    <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                                                    <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                                                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                                                   <span class="p">)</span> 
    
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">results_ds</span></div>
    
<div class="viewcode-block" id="InterpretToolkit.interaction_strength"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.interaction_strength">[docs]</a>    <span class="k">def</span> <span class="nf">interaction_strength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ale</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the InterAction Strength (IAS) statistic from Molnar et al. (2019) [5]_.</span>
<span class="sd">        The IAS varies between 0-1 where values closer to 0 indicate no feature interaction</span>
<span class="sd">        strength.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        </span>
<span class="sd">        ale : xarray.Dataset </span>
<span class="sd">        </span>
<span class="sd">            Results of :func:`~InterpretToolkit.ale`, but must be computed for all features</span>
<span class="sd">            </span>
<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute the IAS for. </span>
<span class="sd">            </span>
<span class="sd">        kwargs : dict</span>

<span class="sd">            - subsample </span>
<span class="sd">            - n_bootstrap </span>
<span class="sd">            - estimator_output </span>

<span class="sd">        Returns</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        results_ds : xarray.Dataset </span>
<span class="sd">            Interaction strength result dataset</span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; ias = explainer.interaction_strength(ale)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

        <span class="c1"># Check that ale_data is an xarray.Dataset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ale</span><span class="p">,</span> <span class="n">xr</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                                 ale must be an xarray.Dataset, </span>
<span class="s2">                                 perferably generated by mintpy.InterpretToolkit.calc_ale to be formatted correctly</span>
<span class="s2">                                 &quot;&quot;&quot;</span>
                                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">any_missing</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">m</span> <span class="ow">in</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">])</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">any_missing</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ale does not contain data for all the estimator names given!&#39;</span><span class="p">)</span>
     
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span>
    
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="o">.</span><span class="n">compute_scalar_interaction_stats</span><span class="p">(</span>
                                                    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;ias&#39;</span><span class="p">,</span>
                                                    <span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
                                                    <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                                                    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> 
                                                   <span class="p">)</span> 
        <span class="n">results_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_ds</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results_ds</span></div>
    
    
    <span class="k">def</span> <span class="nf">_plot_interpret_curves</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                               <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span> <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span> 
                               <span class="n">to_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        FOR INTERNAL USE ONLY. </span>
<span class="sd">        </span>
<span class="sd">        Handles 1D or 2D PD/ALE plots.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_used</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;No features were provided to plot!&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
                <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
                
        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;dimension&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;2D&#39;</span><span class="p">:</span>
            <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotInterpret2D</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_contours</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                                          <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                          <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                                          <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                                          <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                                          <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                                          <span class="n">to_probability</span> <span class="o">=</span> <span class="n">to_probability</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotInterpretCurves</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_1d_curve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                                          <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                          <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                                          <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                                          <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                                          <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                                          <span class="n">to_probability</span> <span class="o">=</span> <span class="n">to_probability</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="InterpretToolkit.plot_pd"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.plot_pd">[docs]</a>    <span class="k">def</span> <span class="nf">plot_pd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span> <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span> 
                <span class="n">line_colors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the 1D and 2D partial dependence plotting. </span>
<span class="sd">      </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        pd : xarray.Dataset</span>
<span class="sd">            Results of :func:`~InterpretToolkit.pd` for</span>
<span class="sd">            ``features``.</span>
<span class="sd">            </span>
<span class="sd">        features : string, list of strings, list of 2-tuple of strings</span>
<span class="sd">            Features to plot the PD for.  To plot for 2D PD, </span>
<span class="sd">            pass a list of 2-tuples of features.</span>
<span class="sd">            </span>
<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to plot for.</span>
<span class="sd">            </span>
<span class="sd">        display_feature_names : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>
<span class="sd">            </span>
<span class="sd">            The plotting code can handle latex-style formatting. </span>
<span class="sd">        </span>
<span class="sd">        display_units : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            to their units. </span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>
<span class="sd">        </span>
<span class="sd">        line_colors : str or list of strs of len(estimators)</span>
<span class="sd">            User-defined colors for curve plotting.</span>

<span class="sd">        to_probability : boolean </span>
<span class="sd">            If True, the values are multipled by 100. </span>
<span class="sd">        </span>
<span class="sd">        Keyword arguments include arguments typically used for matplotlib. </span>
<span class="sd">        </span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        fig, axes: matplotlib figure instance and the corresponding axes </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; pd = explainer.calc_pd(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Provide a small subset of features to plot</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, </span>
<span class="sd">        ...     &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_pd(pd, features=important_vars)</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
                
        <span class="k">if</span> <span class="n">pd</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="n">to_probability</span><span class="o">=</span><span class="kc">True</span>
            
        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;left_yaxis_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Centered PD (%)&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;left_yaxis_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Centered PD&#39;</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plot_interpret_curves</span><span class="p">(</span>
                               <span class="n">method</span><span class="o">=</span><span class="s1">&#39;pd&#39;</span><span class="p">,</span>
                               <span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="p">,</span>
                               <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                               <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                               <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                               <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                               <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
                               <span class="n">line_colors</span><span class="o">=</span><span class="n">line_colors</span><span class="p">,</span>            
                               <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.plot_ale"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.plot_ale">[docs]</a>    <span class="k">def</span> <span class="nf">plot_ale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span> <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span> 
                 <span class="n">line_colors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs the 1D and 2D accumulated local effects plotting.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        </span>
<span class="sd">        ale : xarray.Dataset</span>
<span class="sd">             Results of :func:`~InterpretToolkit.ale` for</span>
<span class="sd">            ``features``.</span>
<span class="sd">        </span>
<span class="sd">        features : string, list of strings, list of 2-tuple of strings</span>
<span class="sd">            Features to plot the PD for.  To plot for 2D PD, </span>
<span class="sd">            pass a list of 2-tuples of features.</span>
<span class="sd">            </span>
<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to plot for. </span>
<span class="sd">        </span>
<span class="sd">        display_feature_names : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>
<span class="sd">            </span>
<span class="sd">            The plotting code can handle latex-style formatting. </span>
<span class="sd">        </span>
<span class="sd">        display_units : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            to their units. </span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>
<span class="sd">        </span>
<span class="sd">        line_colors : str or list of strs of len(estimators)</span>
<span class="sd">            User-defined colors for curve plotting.</span>

<span class="sd">        to_probability : boolean </span>
<span class="sd">            If True, the values are multipled by 100. </span>
<span class="sd">        </span>
<span class="sd">        Keyword arguments include arguments typically used for matplotlib. </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        fig, axes: matplotlib figure instance and the corresponding axes </span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; ale = explainer.ale(features=&#39;all&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Provide a small subset of features to plot</span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, </span>
<span class="sd">        ...     &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_ale(ale, features=important_vars)</span>
<span class="sd">        </span>
<span class="sd">        .. image :: ../../images/ale_1d.png</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">ale</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span>
            <span class="n">to_probability</span><span class="o">=</span><span class="kc">True</span>
        
        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;left_yaxis_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Centered ALE (%)&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;left_yaxis_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Centered ALE&#39;</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plot_interpret_curves</span><span class="p">(</span>
                               <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;ale&#39;</span><span class="p">,</span>
                               <span class="n">data</span><span class="o">=</span><span class="n">ale</span><span class="p">,</span>
                               <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                               <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                               <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                               <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                               <span class="n">to_probability</span><span class="o">=</span><span class="n">to_probability</span><span class="p">,</span>
                               <span class="n">line_colors</span><span class="o">=</span><span class="n">line_colors</span><span class="p">,</span>
                               <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.local_contributions"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.local_contributions">[docs]</a>    <span class="k">def</span> <span class="nf">local_contributions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                           <span class="n">method</span><span class="o">=</span><span class="s1">&#39;shap&#39;</span><span class="p">,</span> 
                           <span class="n">background_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                           <span class="n">performance_based</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span> <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the individual feature contributions to a predicted outcome for</span>
<span class="sd">        a series of examples either based on tree interpreter (only Tree-based methods) </span>
<span class="sd">        or Shapley Additive Explanations. </span>

<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>
<span class="sd">        </span>
<span class="sd">        method : ``&#39;shap&#39;`` or ``&#39;tree_interpreter&#39;``</span>
<span class="sd">            Can use SHAP or treeinterpreter to compute the feature contributions.</span>
<span class="sd">            SHAP is estimator-agnostic while treeinterpreter can only be used on</span>
<span class="sd">            select decision-tree based estimators in scikit-learn. SHAP will attempt </span>
<span class="sd">            to first use the Tree-based explainer and if that fails, then the </span>
<span class="sd">            Kernel-based explainer. </span>

<span class="sd">        background_dataset : array of shape (n_samples, n_features)</span>
<span class="sd">            A representative (often a K-means or random sample) subset of the </span>
<span class="sd">            data used to train the ML estimator. Used for the background dataset</span>
<span class="sd">            to compute the expected values for the SHAP calculations. </span>
<span class="sd">            Only required for non-tree based estimators. </span>

<span class="sd">        performance_based : boolean (default=False)</span>
<span class="sd">            If True, will average feature contributions over the best and worst</span>
<span class="sd">            performing of the given X. The number of examples to average over</span>
<span class="sd">            is given by n_samples</span>

<span class="sd">        n_samples : interger (default=100)</span>
<span class="sd">            Number of samples to compute average over if performance_based = True</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        results_df : nested pandas.DataFrame</span>
<span class="sd">            For each example, contributions from each feature plus the bias </span>
<span class="sd">            The dataframe is nested by the estimator names and additional keys</span>
<span class="sd">            if performance_based=True. </span>
<span class="sd">            </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; # Only give the X you want contributions for. </span>
<span class="sd">        &gt;&gt;&gt; # In this case, we are using a single example. </span>
<span class="sd">        &gt;&gt;&gt; single_example = X.iloc[[0]]</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=single_example,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;, </span>
<span class="sd">        ...                   background_dataset=background_dataset)</span>

<span class="sd">        &gt;&gt;&gt; # For the performance-based contributions, </span>
<span class="sd">        &gt;&gt;&gt; # provide the full set of X and y values.</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                            y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;, </span>
<span class="sd">        ...                   background_dataset=background_dataset, </span>
<span class="sd">        ...                   performance_based=True, n_samples=100)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="o">.</span><span class="n">_get_local_prediction</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                                            <span class="n">background_dataset</span><span class="o">=</span><span class="n">background_dataset</span><span class="p">,</span>
                                            <span class="n">performance_based</span><span class="o">=</span><span class="n">performance_based</span><span class="p">,</span>
                                            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,)</span>

        <span class="c1"># Add metadata</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;n_samples&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;performance_based&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">performance_based</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrs_dict</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
        <span class="n">results_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_append_attributes</span><span class="p">(</span><span class="n">results_df</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_df</span></div>

<div class="viewcode-block" id="InterpretToolkit.plot_contributions"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.plot_contributions">[docs]</a>    <span class="k">def</span> <span class="nf">plot_contributions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                           <span class="n">contrib</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                           <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">to_only_varname</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span> 
                           <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the feature contributions.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        contrib : Nested pandas.DataFrame</span>
<span class="sd">            Results of :func:`~InterpretToolkit.local_contributions`</span>

<span class="sd">        features : string or list of strings (default=None)</span>
<span class="sd">        </span>
<span class="sd">               Features to plot. If None, all features are eligible to be plotted. </span>
<span class="sd">               However, the default number of features to plot is 10. Can be set </span>
<span class="sd">               by n_vars (see keyword arguments).</span>
<span class="sd">            </span>
<span class="sd">        estimator_names : string, list of strings (default is None)</span>
<span class="sd">        </span>
<span class="sd">            If using multiple estimators, you can pass a single (or subset of) estimator name(s) </span>
<span class="sd">            to compute the IAS for. </span>

<span class="sd">        to_only_varname : callable (default=None)</span>
<span class="sd">        </span>
<span class="sd">        display_feature_names : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., display_feature_names = { &#39;dwpt2m&#39; : &#39;T$_{d}$&#39;, }</span>
<span class="sd">            The plotting code can handle latex-style formatting.</span>

<span class="sd">        Keyword arguments include arguments typically used for matplotlib</span>

<span class="sd">        Returns</span>
<span class="sd">        ---------</span>
<span class="sd">        </span>
<span class="sd">        fig: matplotlib figure instance</span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; # Only give the X you want contributions for. </span>
<span class="sd">        &gt;&gt;&gt; # In this case, we are using a single example. </span>
<span class="sd">        &gt;&gt;&gt; single_example = X.iloc[[0]]</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=single_example,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; contrib_ds = explainer.local_contributions(method=&#39;shap&#39;, </span>
<span class="sd">        ...                   background_dataset=background_dataset)</span>

<span class="sd">        &gt;&gt;&gt; explainer.plot_contributions(contrib_ds)</span>
<span class="sd">        </span>
<span class="sd">        .. image :: ../../images/feature_contribution_single.png</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>
        
        <span class="n">estimator_output</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">contrib</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
            
        <span class="c1"># initialize a plotting object</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotFeatureContributions</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_contributions</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">contrib</span><span class="p">,</span>
                                           <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">estimator_names</span><span class="p">,</span>
                                           <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                                           <span class="n">to_only_varname</span><span class="o">=</span><span class="n">to_only_varname</span><span class="p">,</span>
                                           <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                                           <span class="n">estimator_output</span><span class="o">=</span><span class="n">estimator_output</span><span class="p">,</span>
                                           <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.shap"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.shap">[docs]</a>    <span class="k">def</span> <span class="nf">shap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">background_dataset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the SHapley Additive Explanations (SHAP) values [13]_ [14]_ [15]_. The calculations starts</span>
<span class="sd">        with the Tree-based explainer and then defaults to the Kernel-based explainer for</span>
<span class="sd">        non-tree based estimators. If using a non-tree based estimators, then you must provide a </span>
<span class="sd">        background dataset </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ------------------ </span>
<span class="sd">        background_dataset : array of shape (n_samples, n_features)</span>
<span class="sd">            A representative (often a K-means or random sample) subset of the</span>
<span class="sd">            data used to train the ML estimator. Used for the background dataset</span>
<span class="sd">            to compute the expected values for the SHAP calculations.</span>
<span class="sd">            Only required for non-tree based methods.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------------------</span>
<span class="sd">        </span>
<span class="sd">        results : dict</span>
<span class="sd">            Dictionary where the keys represent estimator names, and the</span>
<span class="sd">            values represent a tuple of SHAP values and the bias.</span>
<span class="sd">            shap_values is of type numpy.array (n_samples, n_features)</span>
<span class="sd">            bias is of type numpy.array (1, n_features)</span>
<span class="sd">       </span>
<span class="sd">       </span>
<span class="sd">        References</span>
<span class="sd">        ------------</span>
<span class="sd">        .. [13] https://christophm.github.io/interpretable-ml-book/shap.html</span>
<span class="sd">        .. [14] Lundberg, S. M., G. G. Erion, and S.-I. Lee, 2018: Consistent Individualized </span>
<span class="sd">                Feature Attribution for Tree Ensembles. Arxiv,.</span>
<span class="sd">        .. [15] Lundberg, S. M., and Coauthors, 2020: From local explanations to global understanding </span>
<span class="sd">                with explainable AI for trees. Nat Mach Intell, 2, 56â€“67, https://doi.org/10.1038/s42256-019-0138-9.</span>
<span class="sd">       </span>
<span class="sd">       </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; shap_results = explainer.shap(background_dataset)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="o">.</span><span class="n">background_dataset</span> <span class="o">=</span> <span class="n">background_dataset</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">estimator_name</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">shap_values</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="o">.</span><span class="n">_get_shap_values</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                                                 <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,)</span>
            <span class="n">results</span><span class="p">[</span><span class="n">estimator_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">results</span></div>


<div class="viewcode-block" id="InterpretToolkit.plot_shap"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.plot_shap">[docs]</a>    <span class="k">def</span> <span class="nf">plot_shap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                  <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;summary&#39;</span><span class="p">,</span>
                  <span class="n">shap_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                  <span class="n">display_feature_names</span><span class="o">=</span><span class="p">{},</span>
                  <span class="n">display_units</span><span class="o">=</span><span class="p">{},</span>
                  <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the SHapley Additive Explanations (SHAP) [13]_ [14]_ [15]_ summary plot or dependence </span>
<span class="sd">        plots for various features.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        -----------</span>

<span class="sd">        plot_type : ``&#39;summary&#39;`` or ``&#39;dependence&#39;`` </span>
<span class="sd">            if &#39;summary&#39;, plots a feature importance-style plot </span>
<span class="sd">            if &#39;dependence&#39;, plots a partial depedence style plot </span>

<span class="sd">        shap_values : array of shape (n_samples, n_features) </span>
<span class="sd">        </span>
<span class="sd">            SHAP values </span>
<span class="sd">        </span>
<span class="sd">        features : string or list of strings (default=None)</span>
<span class="sd">            features to plots if plot_type is &#39;dependence&#39;.</span>
<span class="sd">        </span>
<span class="sd">        display_feature_names : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names </span>
<span class="sd">            in the pandas.DataFrame to display-friendly versions.</span>
<span class="sd">            E.g., ``display_feature_names = { &#39;dwpt2m&#39; : &#39;$T_{d}$&#39;, }``</span>
<span class="sd">            The plotting code can handle latex-style formatting. </span>
<span class="sd">        </span>
<span class="sd">        display_units : dict </span>
<span class="sd">            For plotting purposes. Dictionary that maps the feature names</span>
<span class="sd">            to their units. </span>
<span class="sd">            E.g., ``display_units = { &#39;dwpt2m&#39; : &#39;$^\circ$C&#39;, }``</span>
<span class="sd">        </span>
<span class="sd">        to_probability : boolean</span>
<span class="sd">            if True, values are multiplied by 100. </span>

<span class="sd">        Returns</span>
<span class="sd">        -----------------------</span>
<span class="sd">        fig: matplotlib figure instance</span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; import shap</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; # Create a background dataset; randomly sample 100 X</span>
<span class="sd">        &gt;&gt;&gt; background_dataset = shap.sample(X, 100)</span>
<span class="sd">        &gt;&gt;&gt; shap_results = explainer.shap(background_dataset)</span>
<span class="sd">        &gt;&gt;&gt; print(estimator_names)</span>
<span class="sd">        ... [&#39;Random Forest&#39;, ]</span>
<span class="sd">        &gt;&gt;&gt; shap_values, bias = shap_results[estimator_names[0]]</span>
<span class="sd">        &gt;&gt;&gt; # Plot the SHAP-summary style plot </span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_shap(plot_type=&#39;summary&#39;,shap_values=shap_values,)</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; # Plot the SHAP-dependence style plot </span>
<span class="sd">        &gt;&gt;&gt; important_vars = [&#39;sfc_temp&#39;, &#39;temp2m&#39;, &#39;sfcT_hrs_bl_frez&#39;, &#39;tmp2m_hrs_bl_frez&#39;,&#39;uplwav_flux&#39;]</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_shap(plot_type=&#39;dependence&#39;,</span>
<span class="sd">        ...            shap_values=shap_values, features=important_vars)</span>

<span class="sd">        .. image :: ../../images/shap_dependence.png</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">to_probability</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span> <span class="o">==</span> <span class="s1">&#39;probability&#39;</span> <span class="k">else</span> <span class="kc">False</span> 
        <span class="k">if</span> <span class="n">to_probability</span><span class="p">:</span>
            <span class="n">shap_values_copy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
            <span class="n">shap_values_copy</span> <span class="o">*=</span> <span class="mf">100.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shap_values_copy</span> <span class="o">=</span> <span class="n">shap_values</span>
            
        <span class="c1"># initialize a plotting object</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotFeatureContributions</span><span class="p">()</span>
        <span class="n">plot_obj</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span>
        <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_shap</span><span class="p">(</span><span class="n">shap_values</span><span class="o">=</span><span class="n">shap_values_copy</span><span class="p">,</span>
                           <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                           <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                           <span class="n">plot_type</span><span class="o">=</span><span class="n">plot_type</span><span class="p">,</span>
                           <span class="n">display_feature_names</span><span class="o">=</span><span class="n">display_feature_names</span><span class="p">,</span>
                           <span class="n">display_units</span><span class="o">=</span><span class="n">display_units</span><span class="p">,</span>
                           <span class="o">**</span><span class="n">kwargs</span>
                          <span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.plot_importance"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.plot_importance">[docs]</a>    <span class="k">def</span> <span class="nf">plot_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;multipass&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">xlabels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ylabels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics_used</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                        <span class="n">estimator_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">plot_correlated_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method for plotting the permutation importance and other ranking-based results.</span>

<span class="sd">        Parameters</span>
<span class="sd">        -------------</span>
<span class="sd">        method: &#39;multipass&#39;, &#39;singlepass&#39;, &#39;perm_based&#39;, &#39;ale_variance&#39;, or &#39;ale_variance_interactions&#39;</span>
<span class="sd">            Method used to compute the feature rankings. </span>
<span class="sd">                </span>
<span class="sd">        data : xarray.Dataset or list of xarray.Datasets</span>
<span class="sd">            Results from </span>
<span class="sd">            </span>
<span class="sd">            - :func:`~InterpretToolkit.permutation_importance`</span>
<span class="sd">            - :func:`~InterpretToolkit.ale_variance`</span>
<span class="sd">            - :func:`~InterpretToolkit.friedman_h_stat`</span>
<span class="sd">            - :func:`~InterpretToolkit.perm_based_interaction`</span>
<span class="sd">            </span>
<span class="sd">        xlabels : list of strings</span>
<span class="sd">            X-axis label </span>
<span class="sd">        </span>
<span class="sd">        ylabels : list of strings</span>
<span class="sd">            Y-axis label or multiple labels for each row in a multi-panel plot. </span>
<span class="sd">        </span>
<span class="sd">        metrics_used : list of strings </span>
<span class="sd">            Determined internally if possible. </span>
<span class="sd">        </span>
<span class="sd">        plot_correlated_features : boolean</span>
<span class="sd">            If True, pairs of features with a linear correlation coefficient &gt; 0.8 </span>
<span class="sd">            are annotate/paired by bars or color-coding. This is useful for identifying</span>
<span class="sd">            spurious rankings due to the correlations. </span>
<span class="sd">        </span>
<span class="sd">        kwargs : keyword arguments</span>
<span class="sd">        </span>
<span class="sd">        num_vars_to_plot : integer</span>
<span class="sd">            Number of features to plot from permutation importance calculation.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        fig: matplotlib figure instance</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.permutation_importance( </span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20, </span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_importance(data=perm_imp_results, method=&#39;multipass&#39;)</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; #If we want to annonate pairs of highly correlated feature pairs</span>
<span class="sd">        &gt;&gt;&gt; explainer.plot_importance(data=perm_imp_results, method=&#39;multipass&#39;, </span>
<span class="sd">        ...                     plot_correlated_features=True)</span>
<span class="sd">        </span>
<span class="sd">        .. image :: ../../images/multi_pass_perm_imp.png</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ale_variance&#39;</span><span class="p">:</span>
            <span class="n">metrics_used</span> <span class="o">=</span> <span class="s1">&#39;$\sigma$(ALE)&#39;</span>
        
        <span class="n">estimator_output</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_output</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># initialize a plotting object</span>
        <span class="n">plot_obj</span> <span class="o">=</span> <span class="n">PlotImportance</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">metrics_used</span><span class="p">):</span>
            <span class="n">metrics_used</span><span class="o">=</span><span class="p">[</span><span class="n">metrics_used</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="n">xlabels</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">metrics_used</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ylabels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metrics_used</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;evaluation_fn&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">xlabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="n">estimator_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_str</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>            
        <span class="k">else</span><span class="p">:</span>
            <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span>
            
        <span class="k">if</span> <span class="n">plot_correlated_features</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>

        <span class="k">return</span> <span class="n">plot_obj</span><span class="o">.</span><span class="n">plot_variable_importance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                                                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> 
                                                <span class="n">estimator_output</span><span class="o">=</span><span class="n">estimator_output</span><span class="p">,</span>
                                                <span class="n">estimator_names</span><span class="o">=</span><span class="n">estimator_names</span><span class="p">,</span>
                                                <span class="n">metrics_used</span> <span class="o">=</span> <span class="n">metrics_used</span><span class="p">,</span>
                                                <span class="n">xlabels</span> <span class="o">=</span> <span class="n">xlabels</span><span class="p">,</span>
                                                <span class="n">ylabels</span><span class="o">=</span><span class="n">ylabels</span><span class="p">,</span>
                                                <span class="n">plot_correlated_features</span><span class="o">=</span><span class="n">plot_correlated_features</span><span class="p">,</span>
                                                 <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.get_important_vars"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.get_important_vars">[docs]</a>    <span class="k">def</span> <span class="nf">get_important_vars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">perm_imp_data</span><span class="p">,</span> <span class="n">multipass</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">combine</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve the most important variables from permutation importance.</span>
<span class="sd">        Can combine rankings from different estimators and only keep those variables that</span>
<span class="sd">        occur in more than one estimator. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ------------</span>
<span class="sd">        </span>
<span class="sd">        perm_imp_data : xarray.Dataset</span>
<span class="sd">            Permutation importance result dataset</span>

<span class="sd">        multipass : boolean (defaults to True)</span>
<span class="sd">        </span>
<span class="sd">            if True, return the multipass rankings else returns the singlepass rankings</span>

<span class="sd">        n_vars : integer (default=10)</span>
<span class="sd">            Number of variables to retrieve if multipass=True.</span>

<span class="sd">        combine : boolean  (default=False)</span>
<span class="sd">            If combine=True, n_vars can be set such that you only include a certain amount of</span>
<span class="sd">            top features from each estimator. E.g., n_vars=5 and combine=True means to combine</span>
<span class="sd">            the top 5 features from each estimator into a single list.</span>

<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">            if combine=True</span>
<span class="sd">                results : list </span>
<span class="sd">                    List of top features from a different estimators.</span>
<span class="sd">            if combine=False</span>
<span class="sd">                results : dict</span>
<span class="sd">                    keys are the estimator names and items are the</span>
<span class="sd">                    top features.</span>
<span class="sd">                    </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() </span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_data = explainer.permutation_importance( </span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20, </span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; important_vars = explainer.get_important_vars(perm_imp_data, </span>
<span class="sd">        ...        multipass=True, n_vars=5, combine=False)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # set combine=True</span>
<span class="sd">        &gt;&gt;&gt; important_vars = explainer.get_important_vars(perm_imp_data, </span>
<span class="sd">        ...        multipass=True, n_vars=5, combine=True)       </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">retrieve_important_vars</span><span class="p">(</span><span class="n">perm_imp_data</span><span class="p">,</span> 
                                          <span class="n">estimator_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator_names</span><span class="p">,</span> 
                                          <span class="n">multipass</span><span class="o">=</span><span class="n">multipass</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">combine</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">results</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">combine_top_features</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">n_vars</span><span class="o">=</span><span class="n">n_vars</span><span class="p">)</span></div>

<div class="viewcode-block" id="InterpretToolkit.load"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.load">[docs]</a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fnames</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;dataset&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load results of a computation (permutation importance, calc_ale, calc_pd, etc)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fnames : string or list of strings</span>
<span class="sd">            File names of dataframes or datasets to load. </span>
<span class="sd">            </span>
<span class="sd">        dtype : &#39;dataset&#39; or &#39;dataframe&#39;</span>
<span class="sd">            Indicate whether you are loading a set of xarray.Datasets </span>
<span class="sd">            or pandas.DataFrames</span>
<span class="sd">           </span>
<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        </span>
<span class="sd">        results : xarray.DataSet or pandas.DataFrame</span>
<span class="sd">            data for plotting purposes</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        ---------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit()</span>
<span class="sd">        &gt;&gt;&gt; fname = &#39;path/to/your/perm_imp_results&#39;</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_data = explainer.load(fnames=fname, dtype=&#39;dataset&#39;)     </span>
<span class="sd">            </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;dataset&#39;</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">load_netcdf</span><span class="p">(</span><span class="n">fnames</span><span class="o">=</span><span class="n">fnames</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s1">&#39;dataframe&#39;</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">load_dataframe</span><span class="p">(</span><span class="n">fnames</span><span class="o">=</span><span class="n">fnames</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dtype must be &quot;dataset&quot; or &quot;dataframe&quot;!&#39;</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_obj</span><span class="p">]:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s1">&#39;estimator_output&#39;</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimator_output&#39;</span><span class="p">])</span>
            <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;estimators used&#39;</span><span class="p">]]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_list</span><span class="p">(</span><span class="n">estimator_names</span><span class="p">):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">estimator_names</span><span class="p">]</span>

            <span class="k">if</span> <span class="p">(</span><span class="nb">any</span><span class="p">(</span><span class="n">is_list</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">estimator_names</span><span class="p">)):</span>
                <span class="n">estimator_names</span> <span class="o">=</span> <span class="n">estimator_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
            
            <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s1">&#39;estimator_names&#39;</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s1">&#39;estimators used&#39;</span><span class="p">,</span> <span class="n">estimator_names</span><span class="p">)</span> 
            
        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="InterpretToolkit.save"><a class="viewcode-back" href="../../../index.html#pymint.main.interpret_toolkit.InterpretToolkit.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fname</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save results of a computation (permutation importance, calc_ale, calc_pd, etc)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fname : string </span>
<span class="sd">            filename to store the results in (including path)</span>
<span class="sd">        data : InterpretToolkit results</span>
<span class="sd">            the results of a InterpretToolkit calculation. Can be a dataframe or dataset.</span>

<span class="sd">        Examples</span>
<span class="sd">        -------</span>
<span class="sd">        &gt;&gt;&gt; import pymint</span>
<span class="sd">        &gt;&gt;&gt; estimator_objs, estimator_names = pymint.load_models() # pre-fit estimators within pymint</span>
<span class="sd">        &gt;&gt;&gt; X, y = pymint.load_data() # training data </span>
<span class="sd">        &gt;&gt;&gt; explainer = pymint.InterpretToolkit(estimators=estimator_objs,</span>
<span class="sd">        ...                            estimator_names=estimator_names,</span>
<span class="sd">        ...                             X=X,</span>
<span class="sd">        ...                             y=y,</span>
<span class="sd">        ...                            )</span>
<span class="sd">        &gt;&gt;&gt; perm_imp_results = explainer.calc_permutation_importance( </span>
<span class="sd">        ...                       n_vars=10,</span>
<span class="sd">        ...                       evaluation_fn = &#39;norm_aupdc&#39;,</span>
<span class="sd">        ...                       direction = &#39;backward&#39;,</span>
<span class="sd">        ...                       subsample=0.5,</span>
<span class="sd">        ...                       n_bootstrap=20, </span>
<span class="sd">        ...                       )</span>
<span class="sd">        &gt;&gt;&gt; fname = &#39;path/to/save/the/file&#39;</span>
<span class="sd">        &gt;&gt;&gt; explainer.save(fname, perm_imp_results) </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">save_netcdf</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fname</span><span class="p">,</span><span class="n">ds</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_dataframe</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">save_dataframe</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fname</span><span class="p">,</span> <span class="n">dframe</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;data is not a pandas.DataFrame or xarray.Dataset. The type is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span></div></div>

   
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div>
      
      
      
      
      
      
      
        <ul>
          <li><a href="http://data.pp.audeering.com">Data</a></li>
          <li><a href="http://devops.pp.audeering.com/sphinx/">Documentation</a></li>
          <li><a href="http://devops.pp.audeering.com">Infrastructure</a></li>
          <li><a href="http://models.pp.audeering.com">Models</a></li>
          <li><a href="http://devops.pp.audeering.com/python/">Python</a></li>
          <li><a href="http://tools.pp.audeering.com">Tools</a></li>
        </ul>
      
    <p>
        
        
        
          Built with <a href="https://www.sphinx-doc.org/en/master/">Sphinx</a> on 2021/04/10 using the <a href="https://github.com/audeering/sphinx-audeering-theme/">audEERING theme</a>
        
    </p>
  </div>

  <div role="contentinfo">
    <p>
        
      &copy; 2021, Montgomery Flora; Shawn Handler
    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  



  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>